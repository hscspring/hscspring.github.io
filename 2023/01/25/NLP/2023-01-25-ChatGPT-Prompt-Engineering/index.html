<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  
  <meta name="description" content="AI | NLP | 人工智能 | 哲学 | 自然语言处理 | 机器学习">
  

  
  
  
  
  
  <title>ChatGPT Prompt工程：设计、实践与思考 | 长琴</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="ChatGPT 火爆出圈了，有些人惊叹于它的能力，当然也有部分人觉得也就那样。这就不得不提 Prompt 了，据说【相关文献1】，ChatGPT 效果好不好完全取决于你的 Prompt，“看来 Propmt 也成一个技术活儿了”。当我这么想的时候，没想到国外居然已经有了成熟的售卖 Prompt 的网站，这玩意儿居然成了 NFT（Non-Fungible Token），真是世界变化太快，本人过于迟钝">
<meta name="keywords" content="AI,ChatGPT,NLP,Prompt,Instruct,In-Context Learning,Few-Shot,One-Shot,Zero-Shot">
<meta property="og:type" content="article">
<meta property="og:title" content="ChatGPT Prompt工程：设计、实践与思考">
<meta property="og:url" content="https://yam.gift/2023/01/25/NLP/2023-01-25-ChatGPT-Prompt-Engineering/index.html">
<meta property="og:site_name" content="长琴">
<meta property="og:description" content="ChatGPT 火爆出圈了，有些人惊叹于它的能力，当然也有部分人觉得也就那样。这就不得不提 Prompt 了，据说【相关文献1】，ChatGPT 效果好不好完全取决于你的 Prompt，“看来 Propmt 也成一个技术活儿了”。当我这么想的时候，没想到国外居然已经有了成熟的售卖 Prompt 的网站，这玩意儿居然成了 NFT（Non-Fungible Token），真是世界变化太快，本人过于迟钝">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://qnimg.lovevivian.cn/blog-chatgpt-prompt-2.jpg">
<meta property="og:image" content="https://qnimg.lovevivian.cn/blog-chatgpt-prompt-3.jpg">
<meta property="og:image" content="https://qnimg.lovevivian.cn/blog-chatgpt-prompt-4.jpg">
<meta property="og:image" content="https://qnimg.lovevivian.cn/blog-chatgpt-prompt-5.jpg">
<meta property="og:image" content="https://qnimg.lovevivian.cn/blog-chatgpt-prompt-6.jpg">
<meta property="og:image" content="https://qnimg.lovevivian.cn/blog-chatgpt-prompt-7.jpg">
<meta property="og:image" content="https://qnimg.lovevivian.cn/blog-chatgpt-prompt-8.jpg">
<meta property="og:image" content="https://qnimg.lovevivian.cn/blog-chatgpt-prompt-9.jpg">
<meta property="og:image" content="https://qnimg.lovevivian.cn/blog-chatgpt-prompt-10.jpg">
<meta property="og:updated_time" content="2024-06-12T02:06:43.536Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="ChatGPT Prompt工程：设计、实践与思考">
<meta name="twitter:description" content="ChatGPT 火爆出圈了，有些人惊叹于它的能力，当然也有部分人觉得也就那样。这就不得不提 Prompt 了，据说【相关文献1】，ChatGPT 效果好不好完全取决于你的 Prompt，“看来 Propmt 也成一个技术活儿了”。当我这么想的时候，没想到国外居然已经有了成熟的售卖 Prompt 的网站，这玩意儿居然成了 NFT（Non-Fungible Token），真是世界变化太快，本人过于迟钝">
<meta name="twitter:image" content="https://qnimg.lovevivian.cn/blog-chatgpt-prompt-2.jpg">
  
  
    <link rel="icon" href="/css/images/favicon.ico">
  
  <link rel="stylesheet" href="/css/style.css">
  

  
  <!-- baidu webmaster push -->
<link rel="alternate" href="/atom.xml" title="长琴" type="application/atom+xml">
<link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /><!-- hexo-inject:begin --><!-- hexo-inject:end --></head></html>
<body class="home blog custom-background custom-font-enabled single-author">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="page" class="hfeed site">
      <header id="masthead" class="site-header" role="banner">
    <hgroup>
      <h1 class="site-title">
        <a href="/" title="长琴" rel="home">长琴</a>
      </h1>
      
        <h2 class="site-description">
          <a href="/" id="subtitle">知乎：长琴 | 公众号：技术与人</a>
        </h2>
      
    </hgroup>

    <nav id="site-navigation" class="main-navigation" role="navigation">
            <button class="menu-toggle">菜单</button>
            <a class="assistive-text" href="/#content" title="跳至内容">跳至内容</a><!--TODO-->
            <div class="menu-main-container">
                <ul id="menu-main" class="nav-menu">
                
                    <li class="menu-item menu-item-type-post_type menu-item-object-page"><a href="/">Home</a></li>
                
                    <li class="menu-item menu-item-type-post_type menu-item-object-page"><a href="/series/">Series</a></li>
                
                    <li class="menu-item menu-item-type-post_type menu-item-object-page"><a href="/archives/">Archives</a></li>
                
                    <li class="menu-item menu-item-type-post_type menu-item-object-page"><a href="/about/">About</a></li>
                
                    <li class="menu-item menu-item-type-post_type menu-item-object-page"><a href="https://github.com/hscspring">Projects</a></li>
                
                </ul>
            </div>
    </nav>
</header>
      <div id="main" class="wrapper">
        <div id="primary" class="site-content"><div id="content" role="main"><article id="post-NLP/2023-01-25-ChatGPT-Prompt-Engineering" class="post-NLP/2023-01-25-ChatGPT-Prompt-Engineering post type-post status-publish format-standard hentry">
    <!---->

      <header class="entry-header">
        
        
  
    <h1 class="entry-title article-title">
      ChatGPT Prompt工程：设计、实践与思考
    </h1>
  

        
        <!-- <div class="comments-link">
            
            <a href="javascript:void(0);" data-url="https://yam.gift/2023/01/25/NLP/2023-01-25-ChatGPT-Prompt-Engineering/" data-id="cm5jp90bj005hvmbzx1i9y3s8" class="leave-reply bdsharebuttonbox" data-cmd="more"></a>
        </div> --><!-- .comments-link -->
      </header><!-- .entry-header -->

    <div class="entry-content">
      
            <!-- Table of Contents -->
              
        <p>ChatGPT 火爆出圈了，有些人惊叹于它的能力，当然也有部分人觉得也就那样。这就不得不提 Prompt 了，据说【相关文献1】，ChatGPT 效果好不好完全取决于你的 Prompt，“看来 Propmt 也成一个技术活儿了”。当我这么想的时候，没想到国外居然已经有了成熟的售卖 Prompt 的<a href="https://promptbase.com/" target="_blank" rel="noopener">网站</a>，这玩意儿居然成了 NFT（Non-Fungible Token），真是世界变化太快，本人过于迟钝。</p>
<p>其实，对于 ChatGPT 的能力，作为 NLPer 第一时间就领教过了，作为行业内人士，而且多年来一直关注文本生成领域，ChatGPT 带给我的冲击和震撼是非常大的，甚至那几天晚上连觉都睡不着，真是焦虑感爆棚。记得在 <a href="https://www.datawhale.club/" target="_blank" rel="noopener">DataWhale</a> 团队群里一次讨论 ChatGPT 时，我发过这样的消息，原话如下：</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">NLP真的考虑要转行了</span><br><span class="line">ChatGPT已经抹平了任务、行业、语言</span><br><span class="line">以后也不用分那么多task榜单了，不用管行业</span><br><span class="line">强大的一批，LM as SAAS 将统治一切</span><br></pre></td></tr></table></figure>
<blockquote>
<p>LM as SAAS，其实应该是 LMAS——Language Model as Service。</p>
</blockquote>
<p>过了几天看到这篇文章：<a href="https://mp.weixin.qq.com/s/1HZoNBovqn1FNlxghDXMFg" target="_blank" rel="noopener">ChatGPT 会对未来 5 年的 NLP 算法从业者带来怎样的冲击？</a>发现业内大家也是差不多的想法（虽然我发消息在这篇文章之后，但之前的确没看过），尤其是张俊林博士的观点个人比较认同，NLP 工程师的确不容乐观。这里不是说这个职业的职责不容乐观，而是说整个行业可能会受到冲击。</p>
<p>有点跑偏了，说回 Prompt，春节时就想用 ChatGPT 生成一些祝福语，突然发现自己掌握的 Prompt 出来的效果不太好了。Google 了一下结果就发现了 <a href="https://fka.gumroad.com/l/art-of-chatgpt-prompting" target="_blank" rel="noopener">The Art of ChatGPT Prompting: A Guide to Crafting Clear and Effective Prompts</a> 这本电子书，再一搜，发现这个领域居然已经发展到如斯境地。本着学习的心态，阅读整理了一些 Prompt 工程的资料（见《文献和参考——核心文献》），是有此文。本文主要介绍关于 ChatGPT Prompt 的方法，我会结合这些资料加上自己的理解写出来，同时会在中文环境下做相关试验。</p>
<a id="more"></a>
<h2 id="背景简介">背景简介</h2>
<p>首先，我们不妨自己先想一想，会怎么写 Prompt。随便一想就一大堆：</p>
<ul>
<li>简单日常对话。比如询问对方姓名，是否开心等等。</li>
<li>常识问答。比如问今天是周几，冬天如何取暖等等。</li>
<li>知识问答。比如热力学第二定律是什么，设计模式中的策略模式适用于哪些场景等等。</li>
<li>文本改写。比如给出一段话，让它改简单一些，或换个风格，同时给出要的风格是什么样子的。</li>
<li>所有的 NLP 任务，包括：文本分类、实体标注、信息抽取、翻译、生成、摘要、阅读理解、推理、问答、纠错、关键词提取、相似度计算等等。具体做法就是给出文本，然后告诉你要做什么任务就行，甚至可以指定输出格式。</li>
</ul>
<p>这里面大部分内容 ChatGPT 都可以完成的相当不错，至少读起来非常通顺流畅，具有逻辑性。当然，我们不排除其中有一些问题，尤其是知识类的（有时候真的是一本正经的在乱说），关于这方面可以阅读【相关文献2】和【3】。</p>
<p>Prompt 其实在 NLP 领域是一个比较成熟的东西，比如那篇 2021 年的<a href="https://yam.gift/2021/12/04/Paper/2021-12-04-Prompt/" target="_blank" rel="noopener">综述</a>，再比如 Google 的 <a href="https://yam.gift/2022/08/28/Paper/2022-08-28-FLAN/" target="_blank" rel="noopener">FLAN</a> 里面也提到了 T5、GPT3 和 FLAN Prompt 的区别，还有这篇<a href="https://yam.gift/2021/12/25/Paper/2021-12-25-MLT-Promote/" target="_blank" rel="noopener">多任务 Prompt</a> 提供了大量的 Prompt 示例（这篇 Paper 161 页，Prompt 就有 133 页）。那怎么到了 ChatGPT 这里 Prompt 一下就有如此地位呢？我觉得主要有两个原因：</p>
<ul>
<li>ChatGPT 强大的 In-Context 学习能力。在 <a href="https://yam.gift/2023/01/20/Paper/2023-01-20-GPT3/" target="_blank" rel="noopener">GPT3</a> 中提到，上下文长度为 2048，也就是说，Prompt 也可以这么长。而且 GPT3 本来就是生成模型，生成的内容和前面给出的提示是直接关联的。</li>
<li>ChatGPT 在训练时用了 Prompt（InstructGPT【相关文献4】和【5】），也就是说相比其他模型，它本身就在 Prompt 上下了不少功夫。他用的这个 Prompt 其实是 Instruct，用来引导和激发模型的 In-Context 能力。</li>
</ul>
<p>因此，从设计的角度来看，要想发挥 ChatGPT 的最大能力，不仅仅要靠它的 In-Context 能力，Prompt 也应该仔细设计，或者说尽量贴近训练时的样子。换句话说，它是遇强则强，遇弱则弱，遇傻逼则傻逼。。。</p>
<h2 id="prompt设计">Prompt设计</h2>
<p>ChatGPT 有不少特点，比如：跨语言、同时服务多人（伸缩性）、个性化（利用历史记录）等。但最值得一提的是定制化，也就是可以定制语气、风格、类型等，这个也可以包含在你的 Prompt 里。</p>
<p><strong>Prompt原则</strong></p>
<p>首先要说的是设计原则，主要包含以下几个：</p>
<ul>
<li>清晰，切忌复杂或歧义，如果有术语，应定义清楚。</li>
<li>具体，描述语言应尽量具体，不要抽象活模棱两可。</li>
<li>聚焦，问题避免太泛或开放。</li>
<li>简洁，避免不必要的描述。</li>
<li>相关，主要指主题相关，而且是整个对话期间，不要东一瓢西一瓤。</li>
</ul>
<p>举几个【核心文献1】中的例子（换成了中文）：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 有效 Prompt</span></span><br><span class="line">你能总结一下《锻炼的好处》一文的要点吗？  <span class="comment"># 聚焦、相关</span></span><br><span class="line">巴黎最好的素食餐厅有哪些？  <span class="comment"># 具体、相关</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 无效 Prompt</span></span><br><span class="line">你能告诉我关于这个世界的什么？  <span class="comment"># 宽泛、开放</span></span><br><span class="line">你能帮我做作业吗？  <span class="comment"># 开放</span></span><br><span class="line">你好  <span class="comment"># 无目的、不聚焦</span></span><br></pre></td></tr></table></figure>
<p>当然，这几个例子是站在「你要获得有效信息」的基础上说的。也就是说，这些原则是针对你想要通过 ChatGPT 获取到有用信息或完成特定任务。抛开这个前提，一些开放、宽泛的问题也无可厚非。一方面，可以了解模型在这类问题上的能力；另一方面，ChatGPT 本身并没有规定你必须问什么不问什么，这种问题也是一种信息。</p>
<p>事实上，ChatGPT（或者说，一个有追求的机器人）也是希望我们把它当做合作伙伴（助理）、导师（教育）、朋友（聊天、情感）、百科全书（信息获取）。我们甚至可以想象，以后一定会出现类似科幻电影《人工智能》中那个万事通博士（电影 1 分 26 秒），或者科幻小说《The IWM 1000》中的那个 IWM 1000 仪器（虽然这个，额，有点悲观色彩，但那是另一个话题了）。噢，我还问了 ChatGPT 大卫的问题，我认为他回答的不错，感兴趣的可以看后面《附录一》。</p>
<p><strong>Prompt步骤</strong></p>
<p>一般包括以下步骤【核心文献1】。</p>
<p>对话前：</p>
<ul>
<li>明确目的并始终聚焦目的。</li>
<li>使用清晰、具体、相关的语言简洁地描述你的目的。</li>
<li>避免使用开放式或过于宽泛的 Prompt。</li>
<li>查看和修改 Prompt。</li>
</ul>
<p>对话中：</p>
<ul>
<li>鼓励 ChatGPT 扩展内容。</li>
<li>注意对话中的语气和语言。</li>
<li>注意对话的方向，适时做出调整。</li>
<li>必要时可以使用「角色扮演」（如「假设你是XXX」）帮助 ChatGPT 理解它的角色。</li>
</ul>
<p>对话后：</p>
<ul>
<li>回顾整通对话，检查是否有违反原则或失误的地方。</li>
<li>注意不同 Prompt 下 ChatGPT 的反馈，了解其能力和局限。</li>
<li>梳理 Prompt 并在必要时重新测试。</li>
<li>如果问题没有得到解决，尝试使用更多不同种类的 Prompt 进行测试。</li>
</ul>
<p>再举个【核心文献1】中的例子，依然换成中文：</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">我希望你充当 JavaScript console。我将键入命令，您将回复 JavaScript console 应显示的内容。我希望你只回复一个唯一代码块中的终端输出，没有别的。不要写注释。除非我指示你这样做，否则不要键入命令。当我需要用英语告诉你一些事情时，我会通过将文本放在大括号内&#123;像这样&#125;来做到这一点。我的第一个命令是 console.log（“Hello World”）;</span><br></pre></td></tr></table></figure>
<p>来看看这个例子：</p>
<ul>
<li>“我希望你充当 JavaScript console。”这句话使用了「充当XX」这样的 Prompt 告诉 ChatGPT 的角色。</li>
<li>“我将键入命令，您将回复 JavaScript console 应显示的内容。”这句话解释了用户的角色，以及 ChatGPT 响应用户命令时的角色。</li>
<li>“我希望你只回复一个唯一代码块中的终端输出，没有别的。”这句话为 ChatGPT 提供了进一步的说明，指定它应该只在一个唯一的代码块内使用终端输出进行回复，并且在其回复中不包含任何其他内容或解释。</li>
<li>“不要写注释。”这句话是对上一句指令的重复，强调 ChatGPT 不应在其响应中写任何注释。</li>
<li>“除非我指示你这样做，否则不要输入命令。”这句话为 ChatGPT 提供了进一步的说明，指定它不应键入任何命令，除非用户指示这样做。</li>
<li>“当我需要用英语告诉你一些事情时，我会通过将文本放在大括号内{像这样}来做到这一点。”这句话通过将文本括在大括号中，为用户提供了如何用英语与 ChatGPT 进行交流的说明。</li>
<li>“我的第一个命令是 console.log(“Hello World”);”这句话提供了提示符的第一个命令，因此 ChatGPT 将首先运行。</li>
</ul>
<p>简单的执行效果如下：</p>
<p><img src="https://qnimg.lovevivian.cn/blog-chatgpt-prompt-2.jpg" alt></p>
<p>关于一些新手常见的错误，【核心文献 5】Rob Lennon 总结的非常到位：</p>
<ul>
<li>没有说明具体的输出目标。</li>
<li>在一次对话中混合多个主题。</li>
<li>让语言模型做数学题。比如我40岁，女儿4岁，什么时候她的年龄是我的一半。</li>
<li>没有给出想要什么的示例样本。</li>
<li>反向提示。也就是一些反面例子。</li>
<li>没有要求他减少输出。可以要求他减少、删除或重写。</li>
<li>要求他一次只做一件事。可以将步骤捆绑在一起，不要拆的太碎。比如我们上面这个例子，你可以把很多步骤一次说清。</li>
<li>不重复 Prompt 来获得更好的结果。尝试多调整试验几次以获得更好效果。</li>
</ul>
<p>不过与其说这些是错误，还不如说是 ChatGPT 不擅长某些情况。ChatGPT 拥有的是语言模型提供的 In-Context 能力，这是它的内核；Prompt 是一种引导和某种程度来说——限制（可以理解为某种规则）。关于这部分内容我们在后面的《多想一点》部分进一步探讨。</p>
<h2 id="case一瞥">Case一瞥</h2>
<p>看了上面的例子，我们来一个 NLP 命名实体任务的例子（来自一个朋友，稍作改编），材料是来自维基百科的一段刘亦菲简介。</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">请做一个实体抽取任务，从下面这段话中提取出人名和地名，并用json格式输出：</span><br><span class="line">刘亦菲（ Crystal Liu，1987 年 8 月 25 日－[1]）为 华裔美籍的女演员、歌手。出生于湖北武汉，后随母亲移居美国纽约，毕业于北京电影学院表演系 2002 级本科班。2002 年，主演电视剧《金粉世家》进入演艺圈；之后几年相继饰演了《天龙八部》的王语嫣、《仙剑奇侠传》的赵灵儿和《神雕侠侣》的小龙女等知名角色。2005 年签约唱片公司进军歌坛。2008 年凭借好莱坞电影《功夫之王》亮相国际银幕 [4]。2012 年主演电影《 铜雀台》，斩获第五届澳门国际电影节金莲花奖最佳女主角 [5]。2017 年从 迪士尼《花木兰》真人版电影试镜中脱颖而出，成为花木兰的饰演者[3]。</span><br></pre></td></tr></table></figure>
<p>结果展示如下：</p>
<p><img src="https://qnimg.lovevivian.cn/blog-chatgpt-prompt-3.jpg" alt></p>
<p>再来一个生成的例子，我们让他写一段年终总结，Prompt 如下：</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">今年我们团队主要做了以下几件事：第一件，提升业务点击率20%以上；第二件，提升运营效率50%以上；第三件，降低团队成本20%左右。请围绕上面几件事写一段300字左右的晋升材料，我是项目主要成员，务必要突出我本人的个人能力。</span><br></pre></td></tr></table></figure>
<p><img src="https://qnimg.lovevivian.cn/blog-chatgpt-prompt-4.jpg" alt></p>
<p>再来一个改写的例子：</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">下面是甄嬛体的几个例子：</span><br><span class="line">例子1：方才在正想来老朋友已多年不见，也必定会想念彼此，若请你来小聚，应允的话就是极好的。念初我俩同窗数年，不敝风雪，情比金坚，此真也宛若在心。</span><br><span class="line">例子2：方才见网店上一只皮质书包，模样颜色极是俏丽，私心想着若是给你用来，定衬肤色，必是极好的……</span><br><span class="line">例子3：今日天气清爽，本是极好的日子，若能踏踏青，逛逛西苑，便是再好不过了。却偏恼人午觉一睡睡到晚上 9 点，负了个大好光阴。</span><br><span class="line"></span><br><span class="line">请用甄嬛体写一段200字左右的情书，表达对心仪对象的思念之情。</span><br></pre></td></tr></table></figure>
<blockquote>
<p>这几个例子来自【相关文献6】。</p>
</blockquote>
<p><img src="https://qnimg.lovevivian.cn/blog-chatgpt-prompt-5.jpg" alt></p>
<p>写的不是很好，我们给多点提示继续：</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">刚刚写的不太算甄嬛体的风格。请注意，甄嬛体风格的要点如下：</span><br><span class="line"><span class="bullet">1. </span>言必称 “本宫”。</span><br><span class="line"><span class="bullet">2. </span>喜欢用双字及叠字描述事物。比如“方才”、“想来”、“极好”、“罢了”、“真真”。</span><br><span class="line"><span class="bullet">3. </span>经常使用短语、短句进行对话。如“若是…… 想必是极好的。”“我 愿……，虽……，倒也不负恩泽。”“…… 原是最好不过的了。”</span><br><span class="line"><span class="bullet">4. </span>故意将本来可以用简单的一句话表达的内容，偏要用非常文雅而又高深的几个短句表达出来，以达到其幽默效果。</span><br><span class="line"></span><br><span class="line">请用甄嬛体风格重新写一遍刚刚的情书。</span><br></pre></td></tr></table></figure>
<blockquote>
<p>风格要点参考自【相关文献7】。</p>
</blockquote>
<p><img src="https://qnimg.lovevivian.cn/blog-chatgpt-prompt-6.jpg" alt></p>
<p>哈哈，还行，倒数第二段有点拉胯，不过本宫比较满意，就不再继续调教了。</p>
<p>通过这几个例子我们不难看出，只要 Prompt 足够「到位」，ChatGPT 都能理解的相当不错，也能生成不错的结果。这看起来就好像你给一个人在布置任务一样，把你的要求清晰准确的告知对方，对方帮你把事情做完。【核心文献2】有大量的示例，感兴趣的读者不妨一试。</p>
<h2 id="更多case">更多Case</h2>
<p>刚刚的 Case 只是很少的一部分，这部分我们将整理一些【核心文献3】中的来自各方的最佳实践，进一步扩充视野。我们这里统一换成中文。</p>
<p><strong>来自 OpenAI 的示例</strong></p>
<p>例1：找代码 Bug</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">找到下面这段代码的 bug:</span><br><span class="line"></span><br><span class="line"><span class="code">```</span></span><br><span class="line"><span class="code">for (var i=0; i&lt;5; i++) &#123;</span></span><br><span class="line"><span class="code">  setTimeout (() =&gt; console.log (i), 1000)</span></span><br><span class="line"><span class="code">&#125;</span></span><br><span class="line"><span class="code">```</span></span><br></pre></td></tr></table></figure>
<p>结果反馈：</p>
<p><img src="https://qnimg.lovevivian.cn/blog-chatgpt-prompt-7.jpg" alt></p>
<p>例2：知识问答</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在LaTeX中，怎么表示一个微分方程式？</span><br></pre></td></tr></table></figure>
<p><img src="https://qnimg.lovevivian.cn/blog-chatgpt-prompt-8.jpg" alt></p>
<p>例3：代码生成问题，这里换了一个算法问题。</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">请用 Python 写一个快速排序算法。</span><br></pre></td></tr></table></figure>
<p><img src="https://qnimg.lovevivian.cn/blog-chatgpt-prompt-9.jpg" alt></p>
<p>还有部分有趣的例子包括：</p>
<ul>
<li>生成 AI 文字生成图片的Prompt</li>
<li>协作创意写作：【相关文献8】</li>
<li>解释正则表达式</li>
<li>利用缓冲区溢出</li>
<li>解释算法复杂性</li>
<li>……</li>
</ul>
<p>以上内容均来自【相关文献9】。</p>
<p><strong>来自 Syed Huq 的一些有趣使用场景</strong></p>
<ol>
<li>准备面试：让他给出面试常见的问题。</li>
<li>个人辅导：让他作为一个老师，解释数学问题、上一节历史课、如何在论文中加强一个论点等。</li>
<li>写演讲稿：让他帮我们集思广益，或查漏补缺。</li>
<li>头脑风暴：激发一些赚钱思路。</li>
<li>总结书籍：让他帮忙列出关键想法并总结书籍或文章。</li>
<li>生成 SQL：帮忙根据文本写 SQL 查询语言。</li>
<li>Debug 和修复代码。</li>
<li>获得个性化建议：任何主题（大到人生，小到三餐）。</li>
<li>执行计算：可以作为高级计算器。</li>
<li>学习语言：可以通过角色扮演学习语言，以后不用想方设法找外国朋友了。</li>
</ol>
<p>以上内容来自【相关文献10】，可以点击链接查看每一个场景的实际效果。</p>
<p><strong>来自 Rob Lennon 的建议</strong></p>
<ol>
<li>
<p>模拟专家，让其扮演某些角色，然后与其对话。这个小技巧在【核心文献1】里也有提及（“act as” hack），而且【核心文献2】中的 Case 几乎全是这种风格。示例：</p>
 <figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">你是一家顶级市场研究公司的才华横溢的分析师，毕业于哈佛商学院。指导我创建与 B2B SaaS 公司的 C 级高管联系的内容。我会问哪些开放式问题？优先考虑不常见的专家建议。</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>挑战传统叙事，询问与主流叙述矛盾的例子，生成挑战读者假设的内容。简言之，找个刁钻的角度挑衅读者。示例：</p>
 <figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">主题：发展电子邮件新闻稿</span><br><span class="line"></span><br><span class="line">对于上述主题，请举出与主流叙述相矛盾的例子。为挑战假设的发人深省的内容生成大纲。</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>使用非常规 Prompt，比如开放或抽象 Prompt，这样能获得独特和创造性的响应，通过一些奇怪的 Prompt，可以释放 ChatGPT 在寻找生动语言和意想不到的主题方面的创造潜力。这点我们之前其实已经提到过了，非常值得推荐。示例：</p>
 <figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">写一首关于文案的诗。</span><br><span class="line"></span><br><span class="line">用 10 个形容词形容自己像企业家的感觉。</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>超级头脑风暴，让 ChatGPT 提出新的角度或方法来生成潜在创意列表。示例：</p>
 <figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">主题：如何使广告素材产出翻倍。</span><br><span class="line"></span><br><span class="line">对于上面的主题，集思广益新的角度或方法。优先考虑不常见或新颖的想法。</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>捕捉自己的写作风格，让他为以后得输出创建风格指南。示例：</p>
 <figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">分析下面的文本的样式、语音和语气。使用 NLP，创建提示以相同的风格、语音和语气撰写新文章：</span><br><span class="line"></span><br><span class="line">（在此处插入您的文本）</span><br></pre></td></tr></table></figure>
<p>这里，我贴了一段自己之前的一篇文章：<a href="https://yam.gift/2023/01/21/Diary/2023-01-21-Life/" target="_blank" rel="noopener">人生随笔</a>，他给出这样的反馈：</p>
 <figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">样式：深思熟虑的，带有哲理的。</span><br><span class="line">语音：沉着，深沉，平静。</span><br><span class="line">语气：深思熟虑，带有一些沮喪和机会成本的感觉。</span><br></pre></td></tr></table></figure>
<p>而且用这种风格作为 Prompt 给出一段重写后的示例，感兴趣的读者可以进行尝试。</p>
</li>
<li>
<p>添加人工编写的技巧，让他根据我们给出的一些好的建议工作（比如上面的「甄嬛体」例子）。示例：</p>
 <figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">写一篇简短的文章，说明为什么文案写作是 2023 年的一项基本技能。</span><br><span class="line"></span><br><span class="line">使用这些策略：</span><br><span class="line"><span class="bullet">- </span>使用具有说服力的语言</span><br><span class="line"><span class="bullet">- </span>提出问题以在段落之间过渡</span><br><span class="line"><span class="bullet">- </span>用证据和例子支持要点</span><br><span class="line"><span class="bullet">- </span>直接与读者对话</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>从不同的角度让 ChatGPT 协作，比如从一组具有不同背景或观点的人物的角度来写作。探索新的想法和观点，并增加写作的深度。示例：</p>
 <figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">主题：企业家的生产力</span><br><span class="line"></span><br><span class="line">对于上述主题，从具有不同观点的组中编写多个观点。对于每个观点，用自己的声音写，使用那个人会使用的短语。</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>以不同的风格或语气写作，如讽刺或反讽。通过尝试不同的声音和观点，使用 ChatGPT 创建更多动态和多样化的内容。示例：</p>
 <figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">就使用 ChatGPT 创建更有效的内容提供最讽刺、嘲讽的建议。</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>使用 ChatGPT 以不同格式书写，要求其改变输出：大纲；思维导图；要点；有说服力的文章；少于 280 个字符的文本块；使用结构：1）什么，2）为什么，3）如何做。示例：</p>
 <figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">创建关于使用 Notion 作为内容创建者保持井井有条的主题的思维导图，列出中心思想、主要分支和子分支。</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>生成具有特定目的或目标的内容，告诉 ChatGPT 受众是谁，以及希望通过内容实现什么目标。一定不要忘记告诉他你是谁或你想要什么的上下文。示例：</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">主题：如何发展您的教练业务</span><br><span class="line">适用对象：商务教练</span><br><span class="line">内容目标：激励观众在教他们一个技巧的同时对发展他们的业务感到兴奋。</span><br><span class="line">写作风格：清晰、简洁、对话、脚踏实地、谦虚、经验丰富</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>以上内容来自【核心文献4】，个人感觉非常值得一试，强烈推荐。</p>
<p>另外，该作者还开发了一个 AI 写作系统：<a href="https://aicontentreactor.com/" target="_blank" rel="noopener">AI Content Reactor</a>，感兴趣可以一试。</p>
<p>对写作或 Prompt 感兴趣也可以加入他的邮件推送列表：<a href="https://pages.roblennon.xyz/newsletter" target="_blank" rel="noopener">Join 5,082+ creators, solopreneurs, and founders</a>。这里再补充一个邮件推送的如何写好 Prompt 的小结：</p>
<ul>
<li>描述 AI 扮演的角色</li>
<li>提供要执行的任务</li>
<li>给出完成任务的步骤</li>
<li>围绕任务提供上下文</li>
<li>如果需要，陈述一个具体的目标</li>
<li>要求格式化输出</li>
</ul>
<h2 id="多想一点">多想一点</h2>
<p>关于 ChatGPT 的 Prompt 我们已经有了一定程度的理解，这部分内容主要想务虚地探讨一下为什么效果好，以及为什么需要 Prompt，而且效果那么依赖 Prompt？</p>
<p>首先是大模型的超能力——这个的确是自己以前没意识到的，只知道 BERT 这么大的模型比 TextCNN 这类效果好，也知道更大会更好；但确实没有一个具体的概念——到底多好。从 T5 统一所有 NLP 的输入、GPT3 的 In-Context，到后面 Prompt 和 MTL 的大发展，好像都没有感受到那种大突破——直到现在，我们都知道了。我记得之前看过一篇研究 BERT 究竟学到了什么的 Paper：<a href="https://yam.gift/2021/05/22/Paper/2021-05-22-BERTology/" target="_blank" rel="noopener">A Primer in BERTology: What we know about how BERT works</a>，这篇 Paper 的结果是在理解范围内的：能学到一些句法和语义知识，在推理和常识方面不太理想。其实，ChatGPT 依然如此，但没想到却出彩了。另外，也是我一直以来对大模型不太感冒，感觉有点无脑，所以会对类似 <a href="https://yam.gift/2021/08/18/Paper/2021-08-18-R-Drop/" target="_blank" rel="noopener">R-Drop</a> 这类 Paper 比较感兴趣，还会在小模型上做一些<a href="https://yam.gift/2021/08/31/AI/2021-08-31-SL-CL-Dropout/" target="_blank" rel="noopener">实验</a>。但大模型一直都比较关注其设计，比如 <a href="https://yam.gift/2021/07/31/Paper/2021-07-31-UniLM/" target="_blank" rel="noopener">UniLM</a>、<a href="https://yam.gift/2022/03/05/Paper/2022-03-05-T5/" target="_blank" rel="noopener">T5</a> 、<a href="https://yam.gift/2020/06/27/Paper/2020-06-27-DeBERTa/" target="_blank" rel="noopener">DeBERTa</a> 等，尤其是 T5 以及后面的 ExT5 对任务的统一，UniLM 对模型架构的统一，这种 Unified 做法实在是太吸引人了，让人拍案叫绝。这期间其实对 GPT 系列关注不太多，<a href="https://yam.gift/2020/04/07/Paper/2020-04-07-GPT2/" target="_blank" rel="noopener">GPT2</a> 的 Paper 和代码精读过，但主要是当时有生成的业务需要。<a href="https://yam.gift/2023/01/20/NLP/2023-01-20-GPT3/" target="_blank" rel="noopener">GPT3</a> 就一直没仔细读，直到前几天才带着重新学习的心态读了一下，收获很大，有点后悔当时没有认真研读了。对于 In-Context 方面的关注源于 FaceBook 的 <a href="https://yam.gift/2021/11/01/Paper/2021-11-01-MetaICL/" target="_blank" rel="noopener">MetaICL</a>，主要是看到了 Meta Learning 这个东西，这也是一种 Unify，而且更加抽象——个人很喜欢。总的来说，在语言大模型方面，其实大家研究的都差不多，都在慢慢关注到 In-Context 能力（T5 不是也可以这么理解么）。不过 OpenAI 是一条路走到底，这个只能佩服了。如果说从一开始就有这种前瞻的认识和理解，那只能说太太太牛逼格拉斯了。这可不是写写文章自己随便研究研究，每年多少亿资金砸进去啊，真有魄力。</p>
<p>那么，为什么是 ChatGPT？这就不得不说接下来的强化学习了。关于强化学习在 AI 中的作用我在很久以前在 <a href="https://yam.gift/2018/07/22/NLP/2018-07-22-NLP-and-AI/" target="_blank" rel="noopener">NLP与AI</a> 这篇文章中就提到过了，这些年也在关注这个领域的进展。在 ChatGPT 前关注到的最新的研究是 Allen AI 的那篇 <a href="https://arxiv.org/abs/2210.01241" target="_blank" rel="noopener">Is Reinforcement Learning (Not) for Natural Language Processing?: Benchmarks, Baselines, and Building Blocks for Natural Language Policy Optimization</a>，额，这么长的标题。当时正好是某个工作日上午，当日常刷论文刷到这篇并快速浏览完后，激动的恨不得在工位上大吼几声。如果说深度学习是在学习表征的话，强化学习就是在学习规则。我们知道，强化学习一般是在一个发散的空间内探索，所以这里必须要有个东西把规则限制到特定区域内。怎么做呢？要么，我们已经搞清楚语言及背后的意识和思维的奥秘，直接编码规则；要么，直接给出结果，把过程当做黑盒，我就要这个结果，给我往这个方向靠，有点类似于早期控制论那一套人工智能的思路。这就是 Instruct + HF（Human Feedback）的作用了——也是 ChatGPT 之所以成功的一个非常重要的设计。Instruct 引导模型的 In-Context 能力，同时把结果限制在一个范围内，HF 则给出结果反馈，让这个结果往期望的方向上靠。刚刚我们提到强化学习是学习规则，但是这个规则可不是那么容易学的，而 Instruct + HF 就是一个不错的范式。训练完成后，Instruct + 语言模型就可以做到在「用户满意规则」下完成任务了。不能不说，这真的是一个极其精（鸡）巧（贼）的设计。</p>
<p>另外，Instruct 还有个非常重要的点，就是通过 Instruct 可以忽略各种不同的任务，因为什么任务都可以通过 Instruct 给它转成语言模型的生成过程。这点也在 GPT3 Paper 的 Introduction 里解释为什么要这种 In-Context 能力时有提到，简单总结就是 “预训练-微调范式每个任务需要新数据，而且两个阶段数据分布相差太大，可能导致泛化很差”，这非常不够 Human-like，人类往往将多个任务和技能无缝混合或自由切换。再想想 Instruct 对强化学习规则的作用，再想想 Instruct 同时还使得 ChatGPT 具备了一定的可解释性。无论是有意设计还是无意为之，不得不说，和 T5 以及我们之前认知范围内的 Prompt 真的是看似相似，其实完全在两个不同的维度。再次感慨一句：真牛逼——既为这样的设计，也为他们的坚持和执着。</p>
<p>关于设计就说这么多，不过还有一点我觉得也值得一提：和之前不一样的是，ChatGPT 并不是一个算法，更像是一套方案。也就是综合了多种方法的一个有机系统。这也是我个人一直以来的观点，也符合大部分写过复杂工程工程师的认知——没有银弹。我始终相信，没有一个算法是“一招鲜，吃遍天”，我不确定是否会产生真正的强 AI，但即便有，那也一定是一个整合而成的有机系统。这是人类几千万年进化史告诉我们的结论——一个有机整体的系统更加鲁棒、更加具有反脆弱性。一个系统可以犯错，甚至不断犯错，但只要他具备一定学习能力，就总是会不断变得强大。</p>
<p>最后，是关于 ChatGPT 的不足，关于这点本文《Prompt设计》最后部分其实已经涉及一些；<a href="https://yam.gift/2023/01/20/NLP/2023-01-20-GPT3/" target="_blank" rel="noopener">GPT3</a>《局限和影响》部分也有部分提及。当然，简单来说，最突出的还是常识和推理方面。关于常识，我们可以依靠知识图谱（Knowledge Graph）、世界知识（Commonsense World Model），甚至是与环境交互（Embodied AI）；而关于推理，也许 Model Cascades、CoT（Chain-of-Thought）等会发力，但我觉得也不能排除符号 AI 的再度兴起，说实话，自从几年前读了西蒙的<a href="https://yam.gift/2018/09/30/AI/2018-09-30-The-Science-of-Artificial/" target="_blank" rel="noopener">《人工科学》</a>我就在期待这一天了。值得一提的是，在这两个点上，Google 非常有竞争力，真是期待呀。</p>
<blockquote>
<p>本想继续谈谈关于 ChatGPT 对 NLP 行业甚至 AI 领域的影响，以及是否马上就会出现强 AI，以及与此相关的影响等，由于与本文主旨关系不大，我将择文再议。</p>
</blockquote>
<h2 id="文献参考">文献参考</h2>
<p><strong>核心文献</strong></p>
<ul>
<li>【1】<a href="https://fka.gumroad.com/l/art-of-chatgpt-prompting" target="_blank" rel="noopener">The Art of ChatGPT Prompting: A Guide to Crafting Clear and Effective Prompts</a></li>
<li>【2】<a href="https://github.com/f/awesome-chatgpt-prompts" target="_blank" rel="noopener">f/awesome-chatgpt-prompts: This repo includes ChatGPT prompt curation to use ChatGPT better.</a></li>
<li>【3】<a href="https://island-stretch-3e4.notion.site/Best-Chat-GPT-Resources-b54f0284c7644583b59dd9a332f46af8" target="_blank" rel="noopener">Best Chat GPT Resources</a></li>
<li>【4】<a href="https://twitter.com/thatroblennon/status/1610316022174683136" target="_blank" rel="noopener">Rob Lennon 🗯 | Audience Growth on Twitter: “Everyone’s using ChatGPT. But almost everyone’s STUCK in beginner mode. 10 techniques to get massively ahead with AI: (cut-and-paste these prompts👇)” / Twitter</a></li>
<li>【5】<a href="https://twitter.com/thatroblennon/status/1610975391291695105" target="_blank" rel="noopener">Rob Lennon 🗯 | Audience Growth on Twitter: “Most new ChatGPT users are making simple mistakes. (And they don’t realize results could be TWICE as good.) 8 problems with your AI prompts to stop right now:” / Twitter</a></li>
</ul>
<p><strong>相关文献</strong></p>
<ul>
<li>【1】<a href="https://www.forbes.com/sites/tjmccue/2023/01/19/chatgpt-success-completely-depends-on-your-prompt/?sh=dfcdbc41a169" target="_blank" rel="noopener">ChatGPT Success Completely Depends On Your Prompt</a></li>
<li>【2】<a href="https://arxiv.org/abs/2301.08155" target="_blank" rel="noopener">[2301.08155] AI Insights into Theoretical Physics and the Swampland Program: A Journey Through the Cosmos with ChatGPT</a></li>
<li>【3】<a href="https://arxiv.org/abs/2301.07597" target="_blank" rel="noopener">[2301.07597] How Close is ChatGPT to Human Experts? Comparison Corpus, Evaluation, and Detection</a></li>
<li>【4】<a href="https://openai.com/blog/chatgpt/" target="_blank" rel="noopener">ChatGPT: Optimizing Language Models for Dialogue</a></li>
<li>【5】<a href="https://arxiv.org/abs/2203.02155" target="_blank" rel="noopener">[2203.02155] Training language models to follow instructions with human feedback</a></li>
<li>【6】<a href="https://www.jgdq.org/youmeijuzi/143341.html" target="_blank" rel="noopener">甄嬛体的造句样式</a></li>
<li>【7】<a href="http://cangkan.net/wxlw/35823.html" target="_blank" rel="noopener">“甄嬛体” 的句式、语体、修辞 - 藏刊网</a></li>
<li>【8】<a href="https://andrewmayneblog.wordpress.com/2022/11/30/collaborative-creative-writing-with-openais-chatgpt/" target="_blank" rel="noopener">Collaborative Creative Writing with OpenAI’s ChatGPT – @AndrewMayne</a></li>
<li>【9】<a href="https://twitter.com/bentossell/status/1598269692082151424" target="_blank" rel="noopener">Ben Tossell on Twitter: “All the best examples of ChatGPT, from OpenAI:” / Twitter</a></li>
<li>【10】<a href="https://twitter.com/thesyedhuq/status/1610321340338434054" target="_blank" rel="noopener">Syed Huq 🎮 on Twitter: “ChatGPT broke the internet and crossed 1 million users in only 5 days. But most people still don’t know how to unlock its full potential. Here’s 10 mind-blowing things you can do with ChatGPT (I promise):” / Twitter</a></li>
</ul>
<h2 id="附录">附录</h2>
<p><strong>附录一</strong>：《人工智能》大卫问万事通博士的问题。</p>
<p>大卫：Where is Blue Fairy?</p>
<p>万事通：In the Garden. Vascostylis Blue Fairy. Blooms twice annually with bright blue flowers on a branched inflorescence. A hybrid between “Ascola” meda Arnold.</p>
<p>ChatGPT：I’m sorry, I’m not sure which “Blue Fairy” you are referring to. Could you provide more context or specify where you would like to find this Blue Fairy?</p>
<p>大卫：Who is Blue Fairy?</p>
<p>万事通：Are you sad, lonely, looking for a friend? Blue Fairy Escort Service will find a meta for you.</p>
<p>ChatGPT：The Blue Fairy is a fictional character from the story “The Adventures of Pinocchio” written by Carlo Collodi in 1883. In the story, the Blue Fairy is a fairy who grants Pinocchio’s wish to become a real boy. She serves as a guiding force and moral compass throughout the story, helping Pinocchio to learn valuable life lessons and ultimately become a real boy.</p>
<p><em>切换到 Fairy tale.</em></p>
<p>大卫：What is Blue Fairy?</p>
<p>万事通：Pinocchio, by Carlo Collodi. At this signal, there was a rustling as of flapping of wings and a large falcon flew to the windowsill. What are your orders, beautiful fairy? For you must know that the child with blue hair was no other than the good-hearted fairy who had lived in that wood for more than a thousand …</p>
<p>ChatGPT：In the Fairy tale The Adventures of Pinocchio written by Carlo Collodi in 1883, The Blue Fairy is a fairy who grants Pinocchio’s wish to become a real boy. She serves as a guiding force and moral compass throughout the story, helping Pinocchio to learn valuable life lessons and ultimately become a real boy. She is also known as the “Fairy with Turquoise Hair” and “The Fairy of the Coming of Age”</p>
<p><em>结合 fact with fairy tale.</em></p>
<p>大卫：How can the Blue Fairy make a robot into a real live boy?</p>
<p>万事通：Come away O human child, to the waters and the wild with a fairy hand in hand, for the world’s more full of weeping than you can understand. Your quest will be perilous yet the reward is beyond price. In his book, &lt;HOW CAN A ROBOT BECOME HUMAN?&gt; professor Allen Hobby writes of the power which will transform Mecha into Orga.</p>
<p>ChatGPT：In the fairy tale “The Adventures of Pinocchio,” the Blue Fairy grants Pinocchio’s wish to become a real boy. However, in reality, it is not possible to turn a robot into a real live boy using fairy magic or any other means currently known to science. The story of Pinocchio is a fictional tale and the transformation of a robot into a real boy is a metaphor for the character’s moral and personal growth throughout the story.</p>
<p>大卫：Will you tell me how to find her?</p>
<p>万事通：Discovery is quite possible. Our Blue Fairy does exist in one place, and in one place only. At the end of the world where the lions weep. Here is the place dreams are born.</p>
<p>ChatGPT：As the Blue Fairy is a fictional character from the story “The Adventures of Pinocchio” written by Carlo Collodi in 1883, it is not possible to find her in the real world. You can find her in the pages of the book and in the various adaptations and versions of the story, such as films, TV shows, and stage plays. You can also find her in the imagination of people that read or watch the story.</p>
<p><img src="https://qnimg.lovevivian.cn/blog-chatgpt-prompt-10.jpg" alt></p>

      
    </div><!-- .entry-content -->

    <footer class="entry-meta">
    <a href="/2023/01/25/NLP/2023-01-25-ChatGPT-Prompt-Engineering/">
    <time datetime="2023-01-25T15:30:00.000Z" class="entry-date">
        2023-01-25
    </time>
</a>
    
  <span class="article-delim">&#8226;</span>
  <div class="article-category">
  <a class="article-category-link" href="/categories/Thinking/">Thinking</a>
  </div>

    
  <span class="article-delim">&#8226;</span>
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/AI/">AI</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ChatGPT/">ChatGPT</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Few-Shot/">Few-Shot</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/In-Context-Learning/">In-Context Learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Instruct/">Instruct</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NLP/">NLP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/One-Shot/">One-Shot</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Prompt/">Prompt</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Zero-Shot/">Zero-Shot</a></li></ul>

    </footer>
</article>


    
<nav class="nav-single">
    <h3 class="assistive-text">文章导航</h3>
    
        <span class="nav-previous"><a href="/2023/01/27/Paper/2023-01-27-Language-Model-Cascades/" rel="prev"><span class="meta-nav">←</span> 语言模型级联</a></span>
    
    
        <span class="nav-next"><a href="/2023/01/21/Paper/2023-01-21-Human-in-Loop/" rel="next">Put Human in NLP Loop <span class="meta-nav">→</span></a></span>
    
</nav><!-- .nav-single -->







<div class="bdsharebuttonbox"><a href="#" class="bds_more" data-cmd="more"></a><a href="#" class="bds_fbook" data-cmd="fbook" title="分享到Facebook"></a><a href="#" class="bds_twi" data-cmd="twi" title="分享到Twitter"></a><a href="#" class="bds_linkedin" data-cmd="linkedin" title="分享到linkedin"></a><a href="#" class="bds_qzone" data-cmd="qzone" title="分享到QQ空间"></a><a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a><a href="#" class="bds_douban" data-cmd="douban" title="分享到豆瓣网"></a><a href="#" class="bds_weixin" data-cmd="weixin" title="分享到微信"></a><a href="#" class="bds_evernotecn" data-cmd="evernotecn" title="分享到印象笔记"></a></div>
<script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"1","bdSize":"24"},"share":{},"image":{"viewList":["fbook","twi","linkedin","qzone","tsina","douban","weixin","evernotecn"],"viewText":"分享到：","viewSize":"16"}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='/static/api/js/share.js?v=89860593.js?'];</script>

<section id="comment">
  <!-- 评论代码 -->
  <div id="gitalk-container"></div>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
  <script src="https://cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
  <script>
  const gitalk = new Gitalk({
    clientID: '0eb512031083d6e7edfb',
    clientSecret: 'e830808995dd813ca26fed50573760963457da37',
    repo: 'hscspring.github.io',
    owner: 'hscspring',
    admin: ['hscspring'],
    id: md5(location.pathname),
    distractionFreeMode: false
  })
  gitalk.render('gitalk-container')
  </script>
  <!-- 评论代码已完成 -->
</section>

</div></div>
        <div id="secondary" class="widget-area" role="complementary">
  
    
  <aside class="widget">
    <h3 class="widget-title">Categories</h3>
    <div class="widget-content">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Coding/">Coding</a><span class="category-list-count">74</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Feeling/">Feeling</a><span class="category-list-count">153</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Thinking/">Thinking</a><span class="category-list-count">40</span></li></ul>
    </div>
  </aside>

  
    
  <aside class="widget">
    <h3 class="widget-title">Music</h3>
    <div class="widget-content">
      <iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=541131&auto=0&height=66"></iframe>
      <!-- 评论代码 -->
      <!-- <audio src="http://qnimg.lovevivian.cn/miss.mp3" controls="controls"
             style="width:100%">
        您的浏览器不支持 audio 标签。
      </audio> -->
    </div>
  </aside>

  
    
  <aside class="widget">
    <h3 class="widget-title">Recents</h3>
    <div class="widget-content">
      <ul>
        
          <li>
            <a href="/2025/10/25/AI/2025-10-25-Think-about-AGI-and-Human/">子非我，安知我不知鱼之乐——AI、人类与意识的边界</a>
          </li>
        
          <li>
            <a href="/2025/10/24/NLP/LLM-Training/2025-10-24-ReinforcePP/">Reinforce++和它的KL Loss选择</a>
          </li>
        
          <li>
            <a href="/2025/09/25/NLP/LLM/2025-09-25-Hybrid-Gated-Attention/">Hybrid LLM 之 Gated Attention</a>
          </li>
        
          <li>
            <a href="/2025/09/21/Python/2025-09-21-FD-Leak/">记一次诡异的 FD 泄露：躲在暗处的猴子补丁</a>
          </li>
        
          <li>
            <a href="/2025/09/12/NLP/LLM-Training/2025-09-12-GRPO-Clip/">GRPO“又一背锅侠”：Clip的各种拉扯</a>
          </li>
        
      </ul>
    </div>
  </aside>

  
    
  <aside class="widget">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget-content tagcloud">
      <a href="/tags/AE/" style="font-size: 10px;">AE</a> <a href="/tags/AGI/" style="font-size: 10px;">AGI</a> <a href="/tags/AI/" style="font-size: 19.33px;">AI</a> <a href="/tags/AIGC/" style="font-size: 10.67px;">AIGC</a> <a href="/tags/ALBERT/" style="font-size: 10px;">ALBERT</a> <a href="/tags/AR/" style="font-size: 10px;">AR</a> <a href="/tags/AUC/" style="font-size: 10px;">AUC</a> <a href="/tags/Accuracy/" style="font-size: 10px;">Accuracy</a> <a href="/tags/Activation/" style="font-size: 10px;">Activation</a> <a href="/tags/Activation-Steering/" style="font-size: 10px;">Activation Steering</a> <a href="/tags/Agent/" style="font-size: 10px;">Agent</a> <a href="/tags/Aha/" style="font-size: 10px;">Aha</a> <a href="/tags/Algorithm/" style="font-size: 12.67px;">Algorithm</a> <a href="/tags/Array/" style="font-size: 10px;">Array</a> <a href="/tags/Arrow/" style="font-size: 10px;">Arrow</a> <a href="/tags/Attention/" style="font-size: 12px;">Attention</a> <a href="/tags/Automatic-Speech-Processing/" style="font-size: 10px;">Automatic Speech Processing</a> <a href="/tags/Automation/" style="font-size: 10px;">Automation</a> <a href="/tags/BERT/" style="font-size: 16.67px;">BERT</a> <a href="/tags/BIO/" style="font-size: 10.67px;">BIO</a> <a href="/tags/BIOHD/" style="font-size: 10.67px;">BIOHD</a> <a href="/tags/BM25/" style="font-size: 10px;">BM25</a> <a href="/tags/BPE/" style="font-size: 10px;">BPE</a> <a href="/tags/BabyGrow/" style="font-size: 10px;">BabyGrow</a> <a href="/tags/Backtracking/" style="font-size: 10px;">Backtracking</a> <a href="/tags/Backward/" style="font-size: 10px;">Backward</a> <a href="/tags/Bahdanau-Attention/" style="font-size: 10px;">Bahdanau Attention</a> <a href="/tags/Bart/" style="font-size: 10px;">Bart</a> <a href="/tags/Bayes/" style="font-size: 10px;">Bayes</a> <a href="/tags/Beam-Search/" style="font-size: 10px;">Beam Search</a> <a href="/tags/Bert-Flow/" style="font-size: 10px;">Bert-Flow</a> <a href="/tags/Bi-LSTM/" style="font-size: 10px;">Bi-LSTM</a> <a href="/tags/Biasing/" style="font-size: 10px;">Biasing</a> <a href="/tags/BigCodec/" style="font-size: 10px;">BigCodec</a> <a href="/tags/Binary-Search/" style="font-size: 11.33px;">Binary Search</a> <a href="/tags/Blending/" style="font-size: 10px;">Blending</a> <a href="/tags/Brain/" style="font-size: 10px;">Brain</a> <a href="/tags/Brain-Decoding/" style="font-size: 10px;">Brain Decoding</a> <a href="/tags/Bridge/" style="font-size: 10px;">Bridge</a> <a href="/tags/Business/" style="font-size: 12px;">Business</a> <a href="/tags/C/" style="font-size: 10.67px;">C</a> <a href="/tags/C4/" style="font-size: 10px;">C4</a> <a href="/tags/CCG/" style="font-size: 10.67px;">CCG</a> <a href="/tags/CE-BERT/" style="font-size: 10px;">CE BERT</a> <a href="/tags/CFG/" style="font-size: 10px;">CFG</a> <a href="/tags/CISPO/" style="font-size: 10px;">CISPO</a> <a href="/tags/CKY/" style="font-size: 10px;">CKY</a> <a href="/tags/CNN/" style="font-size: 10px;">CNN</a> <a href="/tags/CRF/" style="font-size: 10px;">CRF</a> <a href="/tags/CS/" style="font-size: 10px;">CS</a> <a href="/tags/CYK/" style="font-size: 10px;">CYK</a> <a href="/tags/Calculus/" style="font-size: 10px;">Calculus</a> <a href="/tags/Camera/" style="font-size: 10px;">Camera</a> <a href="/tags/Cascades/" style="font-size: 10px;">Cascades</a> <a href="/tags/Catalan/" style="font-size: 10px;">Catalan</a> <a href="/tags/ChatBot/" style="font-size: 10px;">ChatBot</a> <a href="/tags/ChatGPT/" style="font-size: 15.33px;">ChatGPT</a> <a href="/tags/Chi2/" style="font-size: 10px;">Chi2</a> <a href="/tags/Chunking/" style="font-size: 10px;">Chunking</a> <a href="/tags/Class-Imbalance-Loss/" style="font-size: 10px;">Class Imbalance Loss</a> <a href="/tags/Classification/" style="font-size: 10.67px;">Classification</a> <a href="/tags/Clip/" style="font-size: 10px;">Clip</a> <a href="/tags/CoT/" style="font-size: 10px;">CoT</a> <a href="/tags/Codec/" style="font-size: 12px;">Codec</a> <a href="/tags/Cognition/" style="font-size: 10.67px;">Cognition</a> <a href="/tags/Collaborative-Filtering/" style="font-size: 10px;">Collaborative Filtering</a> <a href="/tags/Collins-Parser/" style="font-size: 10px;">Collins Parser</a> <a href="/tags/Computational-Linguistics/" style="font-size: 10px;">Computational Linguistics</a> <a href="/tags/Computer/" style="font-size: 10px;">Computer</a> <a href="/tags/Computer-Science/" style="font-size: 12px;">Computer Science</a> <a href="/tags/Confusing-Labels/" style="font-size: 10px;">Confusing Labels</a> <a href="/tags/Context-Engineering/" style="font-size: 10px;">Context Engineering</a> <a href="/tags/Context-Free-Grammars/" style="font-size: 10px;">Context-Free Grammars</a> <a href="/tags/Continual-Pre-training/" style="font-size: 14px;">Continual Pre-training</a> <a href="/tags/Continual-Pretraining/" style="font-size: 10.67px;">Continual Pretraining</a> <a href="/tags/Contrastive-Learning/" style="font-size: 10px;">Contrastive-Learning</a> <a href="/tags/Coordinate-Ascent/" style="font-size: 10px;">Coordinate Ascent</a> <a href="/tags/Cosine/" style="font-size: 10.67px;">Cosine</a> <a href="/tags/Cosine-Similarity/" style="font-size: 10px;">Cosine Similarity</a> <a href="/tags/Cross-Entropy/" style="font-size: 10px;">Cross Entropy</a> <a href="/tags/Cross-brackets/" style="font-size: 10px;">Cross-brackets</a> <a href="/tags/Cross-view/" style="font-size: 10px;">Cross-view</a> <a href="/tags/Ctrl/" style="font-size: 10px;">Ctrl</a> <a href="/tags/Culture/" style="font-size: 10px;">Culture</a> <a href="/tags/DA/" style="font-size: 10px;">DA</a> <a href="/tags/DAC/" style="font-size: 10px;">DAC</a> <a href="/tags/DAPO/" style="font-size: 14px;">DAPO</a> <a href="/tags/DB/" style="font-size: 10.67px;">DB</a> <a href="/tags/DCPO/" style="font-size: 10px;">DCPO</a> <a href="/tags/DNN/" style="font-size: 10px;">DNN</a> <a href="/tags/DP/" style="font-size: 10px;">DP</a> <a href="/tags/DPO/" style="font-size: 10px;">DPO</a> <a href="/tags/Data-Augmentation/" style="font-size: 10px;">Data Augmentation</a> <a href="/tags/Data-Clearing/" style="font-size: 10px;">Data Clearing</a> <a href="/tags/Data-Enhancement/" style="font-size: 10px;">Data Enhancement</a> <a href="/tags/Data-Preprocess/" style="font-size: 10px;">Data Preprocess</a> <a href="/tags/Data-Science/" style="font-size: 14px;">Data Science</a> <a href="/tags/Data-Structure/" style="font-size: 15.33px;">Data Structure</a> <a href="/tags/DataManagement/" style="font-size: 10.67px;">DataManagement</a> <a href="/tags/Database/" style="font-size: 10px;">Database</a> <a href="/tags/DeBERTa/" style="font-size: 10px;">DeBERTa</a> <a href="/tags/Debiasing/" style="font-size: 10px;">Debiasing</a> <a href="/tags/Decoder/" style="font-size: 10px;">Decoder</a> <a href="/tags/Decoding/" style="font-size: 10.67px;">Decoding</a> <a href="/tags/Deep/" style="font-size: 10px;">Deep</a> <a href="/tags/DeepGen/" style="font-size: 10px;">DeepGen</a> <a href="/tags/DeepGraph/" style="font-size: 10px;">DeepGraph</a> <a href="/tags/DeepLearning/" style="font-size: 12px;">DeepLearning</a> <a href="/tags/DeepScaleR/" style="font-size: 10.67px;">DeepScaleR</a> <a href="/tags/DeepSeek/" style="font-size: 10px;">DeepSeek</a> <a href="/tags/DeepSeek-GRM/" style="font-size: 10px;">DeepSeek-GRM</a> <a href="/tags/Dependence/" style="font-size: 10px;">Dependence</a> <a href="/tags/Diary/" style="font-size: 15.33px;">Diary</a> <a href="/tags/Disentangled-Attention/" style="font-size: 10px;">Disentangled Attention</a> <a href="/tags/DistilBERT/" style="font-size: 10px;">DistilBERT</a> <a href="/tags/Distillation/" style="font-size: 10.67px;">Distillation</a> <a href="/tags/Django/" style="font-size: 10px;">Django</a> <a href="/tags/Docker/" style="font-size: 10px;">Docker</a> <a href="/tags/Docker-Compose/" style="font-size: 10px;">Docker-Compose</a> <a href="/tags/Dockerfile/" style="font-size: 10px;">Dockerfile</a> <a href="/tags/Dr-GRPO/" style="font-size: 10px;">Dr GRPO</a> <a href="/tags/DrDAPO/" style="font-size: 10px;">DrDAPO</a> <a href="/tags/DrGRPO/" style="font-size: 10px;">DrGRPO</a> <a href="/tags/Dream/" style="font-size: 10.67px;">Dream</a> <a href="/tags/Dropout/" style="font-size: 10.67px;">Dropout</a> <a href="/tags/Dynamic-Mask/" style="font-size: 10px;">Dynamic-Mask</a> <a href="/tags/EDA/" style="font-size: 10px;">EDA</a> <a href="/tags/EMD/" style="font-size: 10px;">EMD</a> <a href="/tags/ERNIE/" style="font-size: 10px;">ERNIE</a> <a href="/tags/Economics/" style="font-size: 10px;">Economics</a> <a href="/tags/Edit-Distance/" style="font-size: 10px;">Edit Distance</a> <a href="/tags/Efficient-DeepLearning/" style="font-size: 10px;">Efficient-DeepLearning</a> <a href="/tags/Elasticsearch/" style="font-size: 10px;">Elasticsearch</a> <a href="/tags/Electra/" style="font-size: 10px;">Electra</a> <a href="/tags/Elixir/" style="font-size: 10.67px;">Elixir</a> <a href="/tags/Ellipsis/" style="font-size: 10px;">Ellipsis</a> <a href="/tags/Embedding/" style="font-size: 11.33px;">Embedding</a> <a href="/tags/Embeddings/" style="font-size: 10.67px;">Embeddings</a> <a href="/tags/Embodied-AI/" style="font-size: 10px;">Embodied AI</a> <a href="/tags/Encoder/" style="font-size: 10px;">Encoder</a> <a href="/tags/Entropy/" style="font-size: 11.33px;">Entropy</a> <a href="/tags/Evaluation/" style="font-size: 10.67px;">Evaluation</a> <a href="/tags/Eventlet/" style="font-size: 10px;">Eventlet</a> <a href="/tags/ExT5/" style="font-size: 10px;">ExT5</a> <a href="/tags/Exam/" style="font-size: 10px;">Exam</a> <a href="/tags/F1/" style="font-size: 10px;">F1</a> <a href="/tags/FD-Leak/" style="font-size: 10px;">FD Leak</a> <a href="/tags/FDW/" style="font-size: 10px;">FDW</a> <a href="/tags/FLAN/" style="font-size: 10px;">FLAN</a> <a href="/tags/FSM/" style="font-size: 10px;">FSM</a> <a href="/tags/Faith/" style="font-size: 10px;">Faith</a> <a href="/tags/FastCuRL/" style="font-size: 10px;">FastCuRL</a> <a href="/tags/Feature-Engineering/" style="font-size: 10px;">Feature Engineering</a> <a href="/tags/Feature-based/" style="font-size: 10px;">Feature-based</a> <a href="/tags/Few-Shot/" style="font-size: 11.33px;">Few-Shot</a> <a href="/tags/Few-shot-Prompting/" style="font-size: 10px;">Few-shot Prompting</a> <a href="/tags/Fine-tuning/" style="font-size: 10px;">Fine-tuning</a> <a href="/tags/Formal-Grammars/" style="font-size: 11.33px;">Formal Grammars</a> <a href="/tags/Forward/" style="font-size: 10px;">Forward</a> <a href="/tags/Full-Text-Search/" style="font-size: 10px;">Full-Text-Search</a> <a href="/tags/Function-Syntax/" style="font-size: 10px;">Function Syntax</a> <a href="/tags/Funk-MF/" style="font-size: 10px;">Funk MF</a> <a href="/tags/Funnel-Transformer/" style="font-size: 10px;">Funnel Transformer</a> <a href="/tags/GAE/" style="font-size: 10px;">GAE</a> <a href="/tags/GBTD/" style="font-size: 10px;">GBTD</a> <a href="/tags/GELU/" style="font-size: 10px;">GELU</a> <a href="/tags/GLU/" style="font-size: 10px;">GLU</a> <a href="/tags/GMPO/" style="font-size: 10.67px;">GMPO</a> <a href="/tags/GP/" style="font-size: 10px;">GP</a> <a href="/tags/GPT-1/" style="font-size: 10px;">GPT-1</a> <a href="/tags/GPT-2/" style="font-size: 10.67px;">GPT-2</a> <a href="/tags/GPT-3/" style="font-size: 10px;">GPT-3</a> <a href="/tags/GPT3/" style="font-size: 10px;">GPT3</a> <a href="/tags/GPU/" style="font-size: 10px;">GPU</a> <a href="/tags/GRM/" style="font-size: 10px;">GRM</a> <a href="/tags/GRPO/" style="font-size: 15.33px;">GRPO</a> <a href="/tags/GRU/" style="font-size: 10px;">GRU</a> <a href="/tags/GSG/" style="font-size: 10px;">GSG</a> <a href="/tags/GSPO/" style="font-size: 10px;">GSPO</a> <a href="/tags/GTPO/" style="font-size: 10px;">GTPO</a> <a href="/tags/GTPO-S/" style="font-size: 10px;">GTPO-S</a> <a href="/tags/Gan/" style="font-size: 10px;">Gan</a> <a href="/tags/Garden-path/" style="font-size: 10px;">Garden-path</a> <a href="/tags/GiGPO/" style="font-size: 10px;">GiGPO</a> <a href="/tags/Git/" style="font-size: 10px;">Git</a> <a href="/tags/Global-Pointer/" style="font-size: 10px;">Global Pointer</a> <a href="/tags/Glow/" style="font-size: 10px;">Glow</a> <a href="/tags/Graceful-Shutdown/" style="font-size: 10px;">Graceful Shutdown</a> <a href="/tags/Gradient-Descent/" style="font-size: 10px;">Gradient Descent</a> <a href="/tags/Graph/" style="font-size: 10.67px;">Graph</a> <a href="/tags/GraphQL/" style="font-size: 10.67px;">GraphQL</a> <a href="/tags/Grid-Grammar/" style="font-size: 10px;">Grid Grammar</a> <a href="/tags/Growth/" style="font-size: 12.67px;">Growth</a> <a href="/tags/H2O-Danube/" style="font-size: 10px;">H2O-Danube</a> <a href="/tags/HMM/" style="font-size: 10.67px;">HMM</a> <a href="/tags/Hard-SVM/" style="font-size: 10px;">Hard-SVM</a> <a href="/tags/Hinge-Loss/" style="font-size: 10px;">Hinge Loss</a> <a href="/tags/Hope/" style="font-size: 10px;">Hope</a> <a href="/tags/Host-only/" style="font-size: 10px;">Host-only</a> <a href="/tags/HuggingLLM/" style="font-size: 10px;">HuggingLLM</a> <a href="/tags/Human-in-Loop/" style="font-size: 10px;">Human-in-Loop</a> <a href="/tags/Human-in-the-Loop/" style="font-size: 10px;">Human-in-the-Loop</a> <a href="/tags/IDE/" style="font-size: 10px;">IDE</a> <a href="/tags/IE/" style="font-size: 10px;">IE</a> <a href="/tags/IQR/" style="font-size: 10px;">IQR</a> <a href="/tags/Imbalance-Data/" style="font-size: 10px;">Imbalance Data</a> <a href="/tags/Impossible-Triangle/" style="font-size: 10px;">Impossible-Triangle</a> <a href="/tags/In-Context-Learning/" style="font-size: 10.67px;">In-Context Learning</a> <a href="/tags/Industry/" style="font-size: 10px;">Industry</a> <a href="/tags/Inference-Scaling/" style="font-size: 11.33px;">Inference Scaling</a> <a href="/tags/Information-Extraction/" style="font-size: 10px;">Information Extraction</a> <a href="/tags/Information-Theory/" style="font-size: 10px;">Information Theory</a> <a href="/tags/Instruct/" style="font-size: 10px;">Instruct</a> <a href="/tags/InstructGPT/" style="font-size: 10.67px;">InstructGPT</a> <a href="/tags/Instruction-Following/" style="font-size: 12px;">Instruction Following</a> <a href="/tags/Instruction-Inference/" style="font-size: 10px;">Instruction Inference</a> <a href="/tags/Isolation-Forest/" style="font-size: 10px;">Isolation Forest</a> <a href="/tags/ItemCF/" style="font-size: 10px;">ItemCF</a> <a href="/tags/Jaccard/" style="font-size: 10px;">Jaccard</a> <a href="/tags/Java/" style="font-size: 10px;">Java</a> <a href="/tags/Jax/" style="font-size: 10px;">Jax</a> <a href="/tags/Job/" style="font-size: 10px;">Job</a> <a href="/tags/Jupyter/" style="font-size: 10px;">Jupyter</a> <a href="/tags/K2/" style="font-size: 10px;">K2</a> <a href="/tags/KKT/" style="font-size: 10px;">KKT</a> <a href="/tags/KL/" style="font-size: 10.67px;">KL</a> <a href="/tags/KS/" style="font-size: 10px;">KS</a> <a href="/tags/Kernel/" style="font-size: 10px;">Kernel</a> <a href="/tags/Kernel-Function/" style="font-size: 10px;">Kernel Function</a> <a href="/tags/Kernel-Method/" style="font-size: 10px;">Kernel Method</a> <a href="/tags/Keyword/" style="font-size: 10px;">Keyword</a> <a href="/tags/Knowledge-Graph/" style="font-size: 10.67px;">Knowledge Graph</a> <a href="/tags/L1/" style="font-size: 10px;">L1</a> <a href="/tags/LCPO/" style="font-size: 10px;">LCPO</a> <a href="/tags/LIMD/" style="font-size: 10.67px;">LIMD</a> <a href="/tags/LIMO/" style="font-size: 11.33px;">LIMO</a> <a href="/tags/LIMR/" style="font-size: 10.67px;">LIMR</a> <a href="/tags/LLM/" style="font-size: 18.67px;">LLM</a> <a href="/tags/LLM-Colosseum/" style="font-size: 10px;">LLM-Colosseum</a> <a href="/tags/LM/" style="font-size: 12px;">LM</a> <a href="/tags/LOF/" style="font-size: 10px;">LOF</a> <a href="/tags/LR/" style="font-size: 10px;">LR</a> <a href="/tags/LSTM/" style="font-size: 10px;">LSTM</a> <a href="/tags/Labeling/" style="font-size: 10px;">Labeling</a> <a href="/tags/Language-Model/" style="font-size: 10.67px;">Language Model</a> <a href="/tags/Lexical-Semantics/" style="font-size: 10px;">Lexical Semantics</a> <a href="/tags/Lexicalism/" style="font-size: 10px;">Lexicalism</a> <a href="/tags/Lexicalized-CFG/" style="font-size: 10px;">Lexicalized CFG</a> <a href="/tags/Lexicalized-Grammars/" style="font-size: 10px;">Lexicalized Grammars</a> <a href="/tags/Life/" style="font-size: 12px;">Life</a> <a href="/tags/Linear-Algebra/" style="font-size: 10px;">Linear Algebra</a> <a href="/tags/Linear-Sturcture/" style="font-size: 10px;">Linear Sturcture</a> <a href="/tags/Linked-List/" style="font-size: 10px;">Linked List</a> <a href="/tags/LinkedList/" style="font-size: 10.67px;">LinkedList</a> <a href="/tags/Linux/" style="font-size: 10px;">Linux</a> <a href="/tags/Llama/" style="font-size: 10px;">Llama</a> <a href="/tags/Logistic-Regression/" style="font-size: 10px;">Logistic Regression</a> <a href="/tags/Lucene/" style="font-size: 10px;">Lucene</a> <a href="/tags/Luong-Attention/" style="font-size: 10px;">Luong Attention</a> <a href="/tags/MEMM/" style="font-size: 10px;">MEMM</a> <a href="/tags/MF/" style="font-size: 10px;">MF</a> <a href="/tags/MIO/" style="font-size: 10px;">MIO</a> <a href="/tags/MM-Fusion/" style="font-size: 10px;">MM Fusion</a> <a href="/tags/MTL/" style="font-size: 11.33px;">MTL</a> <a href="/tags/Machine/" style="font-size: 10px;">Machine</a> <a href="/tags/Machine-Learning/" style="font-size: 14px;">Machine Learning</a> <a href="/tags/Machine-Translation/" style="font-size: 10px;">Machine Translation</a> <a href="/tags/Manacher/" style="font-size: 10px;">Manacher</a> <a href="/tags/Managemnt/" style="font-size: 11.33px;">Managemnt</a> <a href="/tags/MarkBERT/" style="font-size: 10px;">MarkBERT</a> <a href="/tags/Markov/" style="font-size: 10px;">Markov</a> <a href="/tags/Materialized-Views/" style="font-size: 10px;">Materialized Views</a> <a href="/tags/Math/" style="font-size: 10.67px;">Math</a> <a href="/tags/Matplotlib/" style="font-size: 10px;">Matplotlib</a> <a href="/tags/Matrix-Factorization/" style="font-size: 10px;">Matrix Factorization</a> <a href="/tags/Median/" style="font-size: 10px;">Median</a> <a href="/tags/Meta-Learning/" style="font-size: 10px;">Meta Learning</a> <a href="/tags/Metric/" style="font-size: 10px;">Metric</a> <a href="/tags/Minimum-Edit-Distance/" style="font-size: 10px;">Minimum Edit Distance</a> <a href="/tags/Minkowski/" style="font-size: 10px;">Minkowski</a> <a href="/tags/Model-Evaluation/" style="font-size: 10px;">Model Evaluation</a> <a href="/tags/Module/" style="font-size: 10px;">Module</a> <a href="/tags/Monkey-Patch/" style="font-size: 10px;">Monkey Patch</a> <a href="/tags/Multi-Head-Attention/" style="font-size: 10px;">Multi-Head Attention</a> <a href="/tags/Multi-Modal/" style="font-size: 10px;">Multi-Modal</a> <a href="/tags/MultiModal/" style="font-size: 10px;">MultiModal</a> <a href="/tags/Multitask/" style="font-size: 10px;">Multitask</a> <a href="/tags/Multiway-Tree/" style="font-size: 10px;">Multiway Tree</a> <a href="/tags/NAT/" style="font-size: 10px;">NAT</a> <a href="/tags/NER/" style="font-size: 14px;">NER</a> <a href="/tags/NLG/" style="font-size: 11.33px;">NLG</a> <a href="/tags/NLM/" style="font-size: 10.67px;">NLM</a> <a href="/tags/NLP/" style="font-size: 20px;">NLP</a> <a href="/tags/NLU/" style="font-size: 10px;">NLU</a> <a href="/tags/NMT/" style="font-size: 10px;">NMT</a> <a href="/tags/NNW/" style="font-size: 11.33px;">NNW</a> <a href="/tags/NTP/" style="font-size: 10px;">NTP</a> <a href="/tags/Naive-Bayes/" style="font-size: 10px;">Naive Bayes</a> <a href="/tags/Neo4j/" style="font-size: 10px;">Neo4j</a> <a href="/tags/Network/" style="font-size: 10px;">Network</a> <a href="/tags/Ngram/" style="font-size: 10.67px;">Ngram</a> <a href="/tags/NodeJS/" style="font-size: 10px;">NodeJS</a> <a href="/tags/Normalizing-Flow/" style="font-size: 10px;">Normalizing Flow</a> <a href="/tags/NumPy/" style="font-size: 10px;">NumPy</a> <a href="/tags/Numba/" style="font-size: 10px;">Numba</a> <a href="/tags/Numpy/" style="font-size: 10px;">Numpy</a> <a href="/tags/OMNI/" style="font-size: 11.33px;">OMNI</a> <a href="/tags/ORZ/" style="font-size: 10px;">ORZ</a> <a href="/tags/Occupation/" style="font-size: 10px;">Occupation</a> <a href="/tags/One-Shot/" style="font-size: 10.67px;">One-Shot</a> <a href="/tags/Online-Learning/" style="font-size: 10px;">Online Learning</a> <a href="/tags/Online-DPO-R1/" style="font-size: 10.67px;">Online-DPO-R1</a> <a href="/tags/OpenAI/" style="font-size: 10px;">OpenAI</a> <a href="/tags/OpenSource/" style="font-size: 10px;">OpenSource</a> <a href="/tags/Orientation/" style="font-size: 10px;">Orientation</a> <a href="/tags/P-R/" style="font-size: 10px;">P-R</a> <a href="/tags/PCCG/" style="font-size: 10px;">PCCG</a> <a href="/tags/PCFG/" style="font-size: 10px;">PCFG</a> <a href="/tags/PEGASUS/" style="font-size: 10px;">PEGASUS</a> <a href="/tags/PLM/" style="font-size: 10.67px;">PLM</a> <a href="/tags/PPMI/" style="font-size: 10px;">PPMI</a> <a href="/tags/PPO/" style="font-size: 10px;">PPO</a> <a href="/tags/PTM/" style="font-size: 10px;">PTM</a> <a href="/tags/PageRank/" style="font-size: 10px;">PageRank</a> <a href="/tags/Palindromic/" style="font-size: 10px;">Palindromic</a> <a href="/tags/Pandarallel/" style="font-size: 10px;">Pandarallel</a> <a href="/tags/Pandas/" style="font-size: 10.67px;">Pandas</a> <a href="/tags/Partial-Parsing/" style="font-size: 10px;">Partial Parsing</a> <a href="/tags/Passion/" style="font-size: 10px;">Passion</a> <a href="/tags/Pearson/" style="font-size: 10px;">Pearson</a> <a href="/tags/Philosophy/" style="font-size: 10.67px;">Philosophy</a> <a href="/tags/Phrase-Structure-Grammar/" style="font-size: 10px;">Phrase Structure Grammar</a> <a href="/tags/Phrase-Structure-Grammars/" style="font-size: 10px;">Phrase Structure Grammars</a> <a href="/tags/PoS/" style="font-size: 10px;">PoS</a> <a href="/tags/Polars/" style="font-size: 10px;">Polars</a> <a href="/tags/Pooling/" style="font-size: 10px;">Pooling</a> <a href="/tags/Position-Encoding/" style="font-size: 10px;">Position-Encoding</a> <a href="/tags/Post-training/" style="font-size: 16px;">Post-training</a> <a href="/tags/Postgres/" style="font-size: 10.67px;">Postgres</a> <a href="/tags/Pragmatic-Automatic-Processing/" style="font-size: 10px;">Pragmatic Automatic Processing</a> <a href="/tags/Pre-Trained/" style="font-size: 10px;">Pre-Trained</a> <a href="/tags/Pre-Training/" style="font-size: 10px;">Pre-Training</a> <a href="/tags/Pre-training/" style="font-size: 14.67px;">Pre-training</a> <a href="/tags/Precision/" style="font-size: 10px;">Precision</a> <a href="/tags/Pretrain/" style="font-size: 10.67px;">Pretrain</a> <a href="/tags/Pretrained/" style="font-size: 10px;">Pretrained</a> <a href="/tags/Pretraining/" style="font-size: 10.67px;">Pretraining</a> <a href="/tags/Probabilistic-Grammar/" style="font-size: 10px;">Probabilistic Grammar</a> <a href="/tags/Probabilistic-Model/" style="font-size: 10px;">Probabilistic Model</a> <a href="/tags/Promote/" style="font-size: 10px;">Promote</a> <a href="/tags/Prompt/" style="font-size: 12.67px;">Prompt</a> <a href="/tags/ProtoBERT/" style="font-size: 10px;">ProtoBERT</a> <a href="/tags/Pruning/" style="font-size: 10px;">Pruning</a> <a href="/tags/Psychology/" style="font-size: 10.67px;">Psychology</a> <a href="/tags/PyPI/" style="font-size: 10px;">PyPI</a> <a href="/tags/Python/" style="font-size: 18px;">Python</a> <a href="/tags/QA/" style="font-size: 10px;">QA</a> <a href="/tags/Quant/" style="font-size: 10px;">Quant</a> <a href="/tags/Quantization/" style="font-size: 10px;">Quantization</a> <a href="/tags/Query/" style="font-size: 10px;">Query</a> <a href="/tags/Queue/" style="font-size: 10px;">Queue</a> <a href="/tags/Qwen3/" style="font-size: 10px;">Qwen3</a> <a href="/tags/Qwen3-Next/" style="font-size: 10px;">Qwen3-Next</a> <a href="/tags/R-Drop/" style="font-size: 10.67px;">R-Drop</a> <a href="/tags/R1/" style="font-size: 11.33px;">R1</a> <a href="/tags/R1-Zero/" style="font-size: 13.33px;">R1-Zero</a> <a href="/tags/RAG/" style="font-size: 10px;">RAG</a> <a href="/tags/RELU/" style="font-size: 10px;">RELU</a> <a href="/tags/RFE/" style="font-size: 10px;">RFE</a> <a href="/tags/RHO/" style="font-size: 10px;">RHO</a> <a href="/tags/RHO-1/" style="font-size: 10px;">RHO-1</a> <a href="/tags/RL/" style="font-size: 13.33px;">RL</a> <a href="/tags/RLHF/" style="font-size: 10px;">RLHF</a> <a href="/tags/RM/" style="font-size: 10.67px;">RM</a> <a href="/tags/RM-R1/" style="font-size: 10px;">RM-R1</a> <a href="/tags/RMSE/" style="font-size: 10px;">RMSE</a> <a href="/tags/RNN/" style="font-size: 10px;">RNN</a> <a href="/tags/ROC/" style="font-size: 10px;">ROC</a> <a href="/tags/RWD/" style="font-size: 10px;">RWD</a> <a href="/tags/Rank/" style="font-size: 10px;">Rank</a> <a href="/tags/RaspberryPi/" style="font-size: 10.67px;">RaspberryPi</a> <a href="/tags/Raspberrypi/" style="font-size: 10px;">Raspberrypi</a> <a href="/tags/Reasoning/" style="font-size: 10px;">Reasoning</a> <a href="/tags/Recall/" style="font-size: 10px;">Recall</a> <a href="/tags/Recommendation/" style="font-size: 12.67px;">Recommendation</a> <a href="/tags/Recursion/" style="font-size: 10.67px;">Recursion</a> <a href="/tags/Reformer/" style="font-size: 10px;">Reformer</a> <a href="/tags/Regex/" style="font-size: 10px;">Regex</a> <a href="/tags/Regular-Expression/" style="font-size: 10px;">Regular Expression</a> <a href="/tags/Reinforce/" style="font-size: 10px;">Reinforce++</a> <a href="/tags/Reinforcement-Learning/" style="font-size: 10px;">Reinforcement Learning</a> <a href="/tags/Relationship-Extraction/" style="font-size: 10px;">Relationship Extraction</a> <a href="/tags/Representation/" style="font-size: 10.67px;">Representation</a> <a href="/tags/Reqular-Expressions/" style="font-size: 10px;">Reqular Expressions</a> <a href="/tags/Retrieving/" style="font-size: 10px;">Retrieving</a> <a href="/tags/Reward/" style="font-size: 10px;">Reward</a> <a href="/tags/RoBERTa/" style="font-size: 10px;">RoBERTa</a> <a href="/tags/Rotated-Sorted-Array/" style="font-size: 10px;">Rotated Sorted Array</a> <a href="/tags/Rust/" style="font-size: 16px;">Rust</a> <a href="/tags/SCFG/" style="font-size: 10px;">SCFG</a> <a href="/tags/SGD/" style="font-size: 10px;">SGD</a> <a href="/tags/SLM/" style="font-size: 10.67px;">SLM</a> <a href="/tags/SMO/" style="font-size: 10px;">SMO</a> <a href="/tags/SQL/" style="font-size: 10.67px;">SQL</a> <a href="/tags/SRN/" style="font-size: 10px;">SRN</a> <a href="/tags/STaR/" style="font-size: 10px;">STaR</a> <a href="/tags/SVD/" style="font-size: 10px;">SVD++</a> <a href="/tags/SVM/" style="font-size: 10.67px;">SVM</a> <a href="/tags/Scaling/" style="font-size: 10px;">Scaling</a> <a href="/tags/Scaling-Law/" style="font-size: 10px;">Scaling Law</a> <a href="/tags/Seaborn/" style="font-size: 10px;">Seaborn</a> <a href="/tags/Search/" style="font-size: 10.67px;">Search</a> <a href="/tags/Seed-Thinking/" style="font-size: 10px;">Seed-Thinking</a> <a href="/tags/Segmentation/" style="font-size: 10px;">Segmentation</a> <a href="/tags/Selection-Inference/" style="font-size: 10px;">Selection-Inference</a> <a href="/tags/Self-Attention/" style="font-size: 11.33px;">Self-Attention</a> <a href="/tags/Semantic-Automatic-Processing/" style="font-size: 10px;">Semantic Automatic Processing</a> <a href="/tags/Semantic-Similarity/" style="font-size: 10px;">Semantic Similarity</a> <a href="/tags/Senta/" style="font-size: 10px;">Senta</a> <a href="/tags/Sentence-Representation/" style="font-size: 10px;">Sentence Representation</a> <a href="/tags/Sentence-Similarity/" style="font-size: 10px;">Sentence Similarity</a> <a href="/tags/Sentence-BERT/" style="font-size: 10px;">Sentence-BERT</a> <a href="/tags/Sentiment-Classification/" style="font-size: 10px;">Sentiment Classification</a> <a href="/tags/SentimentAnalysis/" style="font-size: 10px;">SentimentAnalysis</a> <a href="/tags/Sentry/" style="font-size: 10px;">Sentry</a> <a href="/tags/Siamese/" style="font-size: 10px;">Siamese</a> <a href="/tags/Sigmoid/" style="font-size: 10px;">Sigmoid</a> <a href="/tags/SimCSE/" style="font-size: 10.67px;">SimCSE</a> <a href="/tags/Similarity/" style="font-size: 10px;">Similarity</a> <a href="/tags/Simon/" style="font-size: 10px;">Simon</a> <a href="/tags/Simple-Zoo/" style="font-size: 10px;">Simple-Zoo</a> <a href="/tags/Simpson-Paradox/" style="font-size: 10px;">Simpson Paradox</a> <a href="/tags/Skill/" style="font-size: 10px;">Skill</a> <a href="/tags/Skywork-Reward/" style="font-size: 10px;">Skywork Reward</a> <a href="/tags/Slide/" style="font-size: 10px;">Slide</a> <a href="/tags/Smoothing/" style="font-size: 10.67px;">Smoothing</a> <a href="/tags/Soft-SVM/" style="font-size: 10px;">Soft-SVM</a> <a href="/tags/Softmax/" style="font-size: 10px;">Softmax</a> <a href="/tags/Sort/" style="font-size: 10.67px;">Sort</a> <a href="/tags/Span/" style="font-size: 11.33px;">Span</a> <a href="/tags/Sparse-Attention/" style="font-size: 10px;">Sparse Attention</a> <a href="/tags/Spell-Check/" style="font-size: 10px;">Spell Check</a> <a href="/tags/Spurious-Reward/" style="font-size: 10px;">Spurious Reward</a> <a href="/tags/SqueezeBERT/" style="font-size: 10px;">SqueezeBERT</a> <a href="/tags/Stable-LM/" style="font-size: 10px;">Stable LM</a> <a href="/tags/Stack/" style="font-size: 10px;">Stack</a> <a href="/tags/Stacking/" style="font-size: 10px;">Stacking</a> <a href="/tags/Statistics/" style="font-size: 10px;">Statistics</a> <a href="/tags/Stirling/" style="font-size: 10px;">Stirling</a> <a href="/tags/Strategic/" style="font-size: 10px;">Strategic</a> <a href="/tags/StratifiedKFold/" style="font-size: 10px;">StratifiedKFold</a> <a href="/tags/String/" style="font-size: 10.67px;">String</a> <a href="/tags/Style/" style="font-size: 10px;">Style</a> <a href="/tags/Substring/" style="font-size: 10px;">Substring</a> <a href="/tags/Summarization/" style="font-size: 10.67px;">Summarization</a> <a href="/tags/Supertagging/" style="font-size: 10px;">Supertagging</a> <a href="/tags/Swap/" style="font-size: 10px;">Swap</a> <a href="/tags/System/" style="font-size: 10.67px;">System</a> <a href="/tags/T5/" style="font-size: 10.67px;">T5</a> <a href="/tags/TF-IDF/" style="font-size: 10px;">TF-IDF</a> <a href="/tags/THW/" style="font-size: 11.33px;">THW</a> <a href="/tags/TS3-Codec/" style="font-size: 10px;">TS3-Codec</a> <a href="/tags/TTRL/" style="font-size: 10px;">TTRL</a> <a href="/tags/TTS/" style="font-size: 14px;">TTS</a> <a href="/tags/Tagging/" style="font-size: 10px;">Tagging</a> <a href="/tags/TanH/" style="font-size: 10px;">TanH</a> <a href="/tags/TensorBay/" style="font-size: 10px;">TensorBay</a> <a href="/tags/Tensorflow/" style="font-size: 10px;">Tensorflow</a> <a href="/tags/Test/" style="font-size: 10px;">Test</a> <a href="/tags/Text-Classification/" style="font-size: 10px;">Text Classification</a> <a href="/tags/Text-Generation/" style="font-size: 10px;">Text Generation</a> <a href="/tags/Text-Normalization/" style="font-size: 10px;">Text Normalization</a> <a href="/tags/TextCNN/" style="font-size: 10.67px;">TextCNN</a> <a href="/tags/TextRank/" style="font-size: 10px;">TextRank</a> <a href="/tags/Thought/" style="font-size: 10.67px;">Thought</a> <a href="/tags/Transformer/" style="font-size: 17.33px;">Transformer</a> <a href="/tags/Transformer-XL/" style="font-size: 10px;">Transformer-XL</a> <a href="/tags/Tree/" style="font-size: 10px;">Tree</a> <a href="/tags/Treebank/" style="font-size: 10px;">Treebank</a> <a href="/tags/Tuning/" style="font-size: 10px;">Tuning</a> <a href="/tags/Tutorial/" style="font-size: 10px;">Tutorial</a> <a href="/tags/Ubuntu/" style="font-size: 10px;">Ubuntu</a> <a href="/tags/UniLM/" style="font-size: 10px;">UniLM</a> <a href="/tags/Unity-Operation/" style="font-size: 10px;">Unity Operation</a> <a href="/tags/Unix/" style="font-size: 10px;">Unix</a> <a href="/tags/Unsupervised-Elicitation/" style="font-size: 10px;">Unsupervised Elicitation</a> <a href="/tags/UserCF/" style="font-size: 10px;">UserCF</a> <a href="/tags/VAPO/" style="font-size: 10px;">VAPO</a> <a href="/tags/VITS/" style="font-size: 10px;">VITS</a> <a href="/tags/Vagrant/" style="font-size: 10px;">Vagrant</a> <a href="/tags/Valence/" style="font-size: 10px;">Valence</a> <a href="/tags/Vector-Semantics/" style="font-size: 10px;">Vector Semantics</a> <a href="/tags/Verifier/" style="font-size: 10px;">Verifier</a> <a href="/tags/Virtual-Network/" style="font-size: 10px;">Virtual Network</a> <a href="/tags/VirtualBox/" style="font-size: 10px;">VirtualBox</a> <a href="/tags/Visualization/" style="font-size: 10px;">Visualization</a> <a href="/tags/Viterbi/" style="font-size: 10.67px;">Viterbi</a> <a href="/tags/Vocabulary-Learning/" style="font-size: 10px;">Vocabulary Learning</a> <a href="/tags/VoiceAgent/" style="font-size: 10px;">VoiceAgent</a> <a href="/tags/Voila/" style="font-size: 10px;">Voila</a> <a href="/tags/Voting/" style="font-size: 10px;">Voting</a> <a href="/tags/W2NER/" style="font-size: 11.33px;">W2NER</a> <a href="/tags/WOE/" style="font-size: 10px;">WOE</a> <a href="/tags/Web-Server-Multithreaded-Server/" style="font-size: 10px;">Web Server Multithreaded Server</a> <a href="/tags/Wide/" style="font-size: 10px;">Wide</a> <a href="/tags/Word2vec/" style="font-size: 10px;">Word2vec</a> <a href="/tags/Work/" style="font-size: 10px;">Work</a> <a href="/tags/World-Model/" style="font-size: 10px;">World Model</a> <a href="/tags/XLNet/" style="font-size: 10px;">XLNet</a> <a href="/tags/XTTS/" style="font-size: 10px;">XTTS</a> <a href="/tags/Z-Score/" style="font-size: 10px;">Z-Score</a> <a href="/tags/Zero-Short/" style="font-size: 10px;">Zero-Short</a> <a href="/tags/Zero-Shot/" style="font-size: 11.33px;">Zero-Shot</a> <a href="/tags/Zero-shot/" style="font-size: 10px;">Zero-shot</a> <a href="/tags/ZhouZhihua/" style="font-size: 10px;">ZhouZhihua</a> <a href="/tags/Zipf/" style="font-size: 10px;">Zipf</a> <a href="/tags/Ziya/" style="font-size: 10.67px;">Ziya</a> <a href="/tags/attention-sink/" style="font-size: 10.67px;">attention sink</a> <a href="/tags/bias/" style="font-size: 10px;">bias</a> <a href="/tags/binning/" style="font-size: 10px;">binning</a> <a href="/tags/emacs/" style="font-size: 10px;">emacs</a> <a href="/tags/few-shot/" style="font-size: 10px;">few-shot</a> <a href="/tags/ffmpeg/" style="font-size: 10px;">ffmpeg</a> <a href="/tags/gated-attention/" style="font-size: 10px;">gated attention</a> <a href="/tags/gpt-oss/" style="font-size: 10px;">gpt-oss</a> <a href="/tags/harmony-format/" style="font-size: 10px;">harmony format</a> <a href="/tags/jpype/" style="font-size: 10px;">jpype</a> <a href="/tags/knowledge-Graph/" style="font-size: 10px;">knowledge Graph</a> <a href="/tags/motion/" style="font-size: 10px;">motion</a> <a href="/tags/node2vec/" style="font-size: 10px;">node2vec</a> <a href="/tags/oat-zero/" style="font-size: 10.67px;">oat-zero</a> <a href="/tags/off-by-one-attention/" style="font-size: 10px;">off-by-one attention</a> <a href="/tags/orz/" style="font-size: 10px;">orz</a> <a href="/tags/s1/" style="font-size: 11.33px;">s1</a> <a href="/tags/ssh/" style="font-size: 10px;">ssh</a> <a href="/tags/str/" style="font-size: 10px;">str</a> <a href="/tags/vim/" style="font-size: 10px;">vim</a> <a href="/tags/vlc/" style="font-size: 10px;">vlc</a>
    </div>
  </aside>

  
</div>
      </div>
      <footer id="colophon" role="contentinfo">
    <p>&copy; 2025 hscspring
    All rights reserved.</p>
    <p>Powered by <a href="https://hexo.io/" target="_blank">Hexo</a></p>
    
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <!-- <span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_site_pv"></span>次</span> -->
    <!-- <span id="busuanzi_container_page_pv">本文总阅读量<span id="busuanzi_value_page_pv"></span>次</span> -->
    <!-- <span id="busuanzi_container_site_uv">本站访客数<span id="busuanzi_value_site_uv"></span>人次</span> -->

</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

<script src="/js/navigation.js"></script>

<div id="bg"></div>

  </div><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>