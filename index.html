<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  
  <meta name="description" content="AI | NLP | 人工智能 | 哲学 | 自然语言处理 | 机器学习">
  

  
  
  
  
  
  <title>长琴</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="AI | NLP | 人工智能 | 哲学 | 自然语言处理 | 机器学习">
<meta property="og:type" content="website">
<meta property="og:title" content="长琴">
<meta property="og:url" content="https://yam.gift/index.html">
<meta property="og:site_name" content="长琴">
<meta property="og:description" content="AI | NLP | 人工智能 | 哲学 | 自然语言处理 | 机器学习">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="长琴">
<meta name="twitter:description" content="AI | NLP | 人工智能 | 哲学 | 自然语言处理 | 机器学习">
  
  
    <link rel="icon" href="/css/images/favicon.ico">
  
  <link rel="stylesheet" href="/css/style.css">
  

  
  <!-- baidu webmaster push -->
<link rel="alternate" href="/atom.xml" title="长琴" type="application/atom+xml">
<link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /><!-- hexo-inject:begin --><!-- hexo-inject:end --></head></html>
<body class="home blog custom-background custom-font-enabled single-author">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="page" class="hfeed site">
      <header id="masthead" class="site-header" role="banner">
    <hgroup>
      <h1 class="site-title">
        <a href="/" title="长琴" rel="home">长琴</a>
      </h1>
      
        <h2 class="site-description">
          <a href="/" id="subtitle">知乎：长琴 | 公众号：技术与人</a>
        </h2>
      
    </hgroup>

    <nav id="site-navigation" class="main-navigation" role="navigation">
            <button class="menu-toggle">菜单</button>
            <a class="assistive-text" href="/#content" title="跳至内容">跳至内容</a><!--TODO-->
            <div class="menu-main-container">
                <ul id="menu-main" class="nav-menu">
                
                    <li class="menu-item menu-item-type-post_type menu-item-object-page"><a href="/">Home</a></li>
                
                    <li class="menu-item menu-item-type-post_type menu-item-object-page"><a href="/series/">Series</a></li>
                
                    <li class="menu-item menu-item-type-post_type menu-item-object-page"><a href="/archives/">Archives</a></li>
                
                    <li class="menu-item menu-item-type-post_type menu-item-object-page"><a href="/about/">About</a></li>
                
                    <li class="menu-item menu-item-type-post_type menu-item-object-page"><a href="/fun/">Fun</a></li>
                
                    <li class="menu-item menu-item-type-post_type menu-item-object-page"><a href="/leading/">BigHuge</a></li>
                
                    <li class="menu-item menu-item-type-post_type menu-item-object-page"><a href="https://github.com/hscspring">Projects</a></li>
                
                </ul>
            </div>
    </nav>
</header>
      <div id="main" class="wrapper">
        <div id="primary" class="site-content"><div id="content" role="main">
  
    <article id="post-ListenGlimmer/001" class="post-ListenGlimmer/001 post type-post status-publish format-standard hentry">
    <!---->

      <header class="entry-header">
        
        
  
    <h1 class="entry-title">
      <a class="article-title" href="/2026/01/03/ListenGlimmer/001/">聆听·微光 001：一位研究生在读的”reward hacker“关于学习的困惑</a>
    </h1>
  

        
        <!-- <div class="comments-link">
            
            <a href="javascript:void(0);" data-url="https://yam.gift/2026/01/03/ListenGlimmer/001/" data-id="cmjx4b11c0000sfbz7otxhobj" class="leave-reply bdsharebuttonbox" data-cmd="more"></a>
        </div> --><!-- .comments-link -->
      </header><!-- .entry-header -->

    <div class="entry-content">
      
        <p>【来访者个人档案】</p>
<ul>
<li><strong>身份：</strong> 研究生在读，大模型方向实习生。</li>
<li><strong>自述：</strong> “我是个 Reward Hacker，为了面试通过，我刷题、背八股，但我心里慌。</li>
</ul>
<hr>
<p>2025 年 1 月 2 日，昨天发完小红书后，今天迎来了第一位小伙伴。</p>
<p>第一位小伙伴（我们后面称他为 F 同学）就和我想象中的不一样，我本来以为他会问关于大模型和相关工作的问题，没想到他更加关注的居然是 ”学习“ 问题。他看的博客是《<a href="https://yam.gift/2025/11/18/NLP/LLM/2025-11-18-Hybrid-Gated-DeltaNet/">Hybrid LLM 之 Gated DeltaNet | 长琴</a>》。</p>
        
          <p class="article-more-link">
            <a href="/2026/01/03/ListenGlimmer/001/#more" class="more-link">More <span class="meta-nav">→</span></a>
          </p>
        
      
    </div><!-- .entry-content -->

    <footer class="entry-meta">
    <a href="/2026/01/03/ListenGlimmer/001/">
    <time datetime="2026-01-03T03:00:00.000Z" class="entry-date">
        2026-01-03
    </time>
</a>
    
  <span class="article-delim">&#8226;</span>
  <div class="article-category">
  <a class="article-category-link" href="/categories/Feeling/">Feeling</a>
  </div>

    
  <span class="article-delim">&#8226;</span>
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Growth/">Growth</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Study/">Study</a></li></ul>

    </footer>
</article>





  
    <article id="post-ListenGlimmer/000" class="post-ListenGlimmer/000 post type-post status-publish format-standard hentry">
    <!---->

      <header class="entry-header">
        
        
  
    <h1 class="entry-title">
      <a class="article-title" href="/2026/01/03/ListenGlimmer/000/">聆听·微光</a>
    </h1>
  

        
        <!-- <div class="comments-link">
            
            <a href="javascript:void(0);" data-url="https://yam.gift/2026/01/03/ListenGlimmer/000/" data-id="cmjx4b11l0001sfbznhlwjcan" class="leave-reply bdsharebuttonbox" data-cmd="more"></a>
        </div> --><!-- .comments-link -->
      </header><!-- .entry-header -->

    <div class="entry-content">
      
            <!-- Table of Contents -->
              
        <h2 id="一段比较长的背景">一段比较长的背景</h2>
<h3 id="那些没被技术替代的-才是-人">那些没被技术替代的，才是“人”</h3>
<p>我的公众号叫《技术与人》，技术是因为自己热爱技术，喜欢探索技术；而“人”则是重要的另一面，所有的技术，最后总归须落到人身上。</p>
<p>“技术”方向的文章很好写，毕竟写了快 10 年了，虽然现在 AI 发展迅猛，但个人写作能力和每次瞄准的写作方向也不太是 AI 能替代的（可以参考我在<a href="https://yam.gift/2026/01/01/AI/2026-01-01-From-AI-Coding-Watch-World-Future/">这里</a>的观点）。</p>
<p>“人”这个方向却一直没有找到合适的创作内容。其实我是老早就想写这块内容了，但一方面是没找到合适的内容，另一方面也是因为自己的技术还在快速积累，时间和精力也不允许。</p>
<p>不过“人”这个方向的“方向”应该是老早就明确的——给他人更多的帮助和温暖。现在知乎草稿箱里还躺着一句 2020 年写的话：“<strong>为这个人人自危的时代注入一丝温暖</strong>”，对应的标题是《孤独》。可能那会儿一个人又学到瓶颈了，并且对职业和人生又有点迷茫了。但后面又慢慢想清楚了。</p>
<p><img src="https://qnimg.lovevivian.cn/blog_general/ghat.jpg" alt></p>
<h3 id="既然退无可退-就没什么好怕的">既然退无可退，就没什么好怕的</h3>
<p>我的职业经历是非典型的，如我个人博客简介所言：“从经济学研究、到组织管理、再到全面转型算法，完成跨界进化。”在不同公司曾任 NLP 负责人与 CTO（大概六七十人的团队），但比起管理，我很显然更喜欢写代码和搞模型。我还清晰记得当我从 CTO 那家公司离职时老板的挽留和不解——因为我在下一家公司又是一线技术岗位。</p>
<p>有人可能会问，就不担心年纪大了失业吗？怎么会不担心呢，随着年纪过了 35，再慢慢逼近 40，怎么能不担心呢？但我想，无论如何，还不至于山穷水尽到那种程度。</p>
<p>这可能和我小时候的生活环境有关：太苦了，很多我同龄人都无法理解，更不用说现在的年轻人了。小时候印象非常深的两件事：经常停电点煤油灯、经常吃不饱饭很饿。不到 10 岁就得去地里干活，拉一车化肥爬坡，背上勒的全是血。在地里一干一整天，后背的皮晒的掉了一层又一层。不过比起后面的变故，这些就真的微不足道了。</p>
<p>好了，总之，这么多年过来，日子是一直在变好的，我是打心底不信日子再回退还能退到那会儿那样？2022 年大模型出现后，虽然出现过短暂的迷茫，为此还专门写了一本书：《ChatGPT 原理与应用开发》，质量只能说一般，但当时心情还是挺悲壮的，感觉 NLP 算法已经到头了。写作背景和动机可以阅读<a href="https://yam.gift/2023/04/22/NLP/2023-04-22-ChatGPT-Development/">这篇文章</a>。</p>
<p><img src="https://qnimg.lovevivian.cn/blog_general/lamp.jpeg" alt></p>
<h3 id="真正的稳定-是随时离开的能力">真正的稳定，是随时离开的能力</h3>
<p>不过，很快我就发现借助 AI，自己的工作效率反而更高了。在 AI Coding 质量比较差的时候，我常用 ChatGPT 对话窗口辅助写代码，当时就感觉效率至少提升 1-2 倍。现在 AI 能力更强了，效率提升何止翻几倍啊，可以参考我最近的体验：《<a href="https://yam.gift/2026/01/01/AI/2026-01-01-From-AI-Coding-Watch-World-Future/">以 AI Coding 之管窥探世界之变 | 长琴</a>》。在 AI 变强的时代，“老” 程序员，有足够项目实战经历、有足够复杂项目的认知背景，其实效率是非常恐怖的。而且，我之前本来就是写过小一阵子前后端的（刚转行算法，公司活儿不多的时候）。所以，我相信找个工作养活自己应该还是可以的。</p>
<p>有人可能会问，就没有想过“上岸”或者去一个稳定的公司，比如国企？当然想过，但我本来就是从国企转行出来的，对国企本身就没那么向往了。另外，我一直也有这么个观点：“真正的稳定应该是任何时候都能找到工作，而不是在一个固定的工作岗位上待着不动”。在某个稳定的环境下呆久了，我觉得反而是一种巨大的不稳定。我很清楚地记得自己从国企转行出来的时候下的决心有多大。</p>
<p><img src="https://qnimg.lovevivian.cn/blog_general/coding.jpg" alt></p>
<h2 id="想做一件小事">想做一件小事</h2>
<h3 id="ask-me-anything-的后续">Ask Me Anything 的后续</h3>
<p>好了，铺垫的有点多了。但相信有了这些背景，大家能更容易理解我接下来要做的事情。</p>
<p>2025 年 9 月，小红书搞过一个《Ask Me Anything》的活动，我本来是被拖过去的，但没想到居然有不少人留言咨询。这让我惊讶的同时，也想到了我一直那个对“人”的念想。我本来想就在这个话题上展开，一直回复下去，没想到没多久活动过去了就没有什么流量了，事情自然也就没下文了。</p>
<p>于是，我就想，我是不是可以把这个话题延续下去，因为那些疑惑依然是存在着的啊，依然可能没有被听见、看见和重视。而我的经历和意愿其实还挺适合做这事儿，且这又与我的念想和理想直接相关。</p>
<h3 id="以我之路-助你前行">以我之路，助你前行</h3>
<p>我出身普通、甚至比较差，半路从跨度超大的方向转行，所有东西全靠自学，前进路线曲折多变，至今仍在一线冲；</p>
<p>我从 2006 年开始思考人生使命和理想，整整十年，2016 年下决心转行，转行后依然面临过许多诱惑和选择，依然持续寻找；</p>
<p>我多年每天快乐地从家去上班，高兴地下班回家，爱情、家庭和事业哪个背后没有苦痛和泪水，哪个不需要持续用心的经营；</p>
<p>我的使命是“用技术改善世界，用认知重塑思维”，这句话是一条从技术开始落到人的长期追求，也是一个普通人近乎 20 年的打磨。</p>
<blockquote>
<p>朋友们，请允许我稍稍张扬一回（其实背后很多苦），仅此一次。；）</p>
</blockquote>
<p>我的这些过往也许非常普通，也许不适合所有人，但我相信能给很多人带来新的思考和感悟，尤其是当下的年轻人，我相信多多少少会对他们有一些帮助。</p>
<h3 id="我想陪你-走一段窄路">我想陪你，走一段窄路</h3>
<p>所以，我想延续关于“年轻的困惑”这个话题。</p>
<p>所以，我创办了《聆听·微光》这个栏目。</p>
<p>如果你愿意，我想听听你的想法和困惑，我想看看能否尝试帮你做一些解答。我们以技术为主，但你想聊其他的我也非常欢迎。</p>
<p>每一位来访者我都会亲自去聊，我希望我可以多多听你说，顺带看看能否用我的经历和认知帮到你些许。这样的做法显然是一种“笨办法”，但这么多年我早已习惯了“笨办法”，无论是学习也好、事业也好、爱情也好、家庭也好，哪儿有什么捷径可言。在算法追求全局最优解的时代，我依然想用这种最原始、最没效率的“笨办法”，去链接每一个真实的灵魂。</p>
<p>我希望这件小事能像微光一样，虽然微小、微弱，但能给需要的人带去哪怕一点点的温暖和光亮，如此便足矣。</p>

      
    </div><!-- .entry-content -->

    <footer class="entry-meta">
    <a href="/2026/01/03/ListenGlimmer/000/">
    <time datetime="2026-01-03T02:00:00.000Z" class="entry-date">
        2026-01-03
    </time>
</a>
    
  <span class="article-delim">&#8226;</span>
  <div class="article-category">
  <a class="article-category-link" href="/categories/Feeling/">Feeling</a>
  </div>

    
  <span class="article-delim">&#8226;</span>
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Growth/">Growth</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Listen/">Listen</a></li></ul>

    </footer>
</article>





  
    <article id="post-AI/2026-01-01-From-AI-Coding-Watch-World-Future" class="post-AI/2026-01-01-From-AI-Coding-Watch-World-Future post type-post status-publish format-standard hentry">
    <!---->

      <header class="entry-header">
        
        
  
    <h1 class="entry-title">
      <a class="article-title" href="/2026/01/01/AI/2026-01-01-From-AI-Coding-Watch-World-Future/">以 AI Coding 之管窥探世界之变</a>
    </h1>
  

        
        <!-- <div class="comments-link">
            
            <a href="javascript:void(0);" data-url="https://yam.gift/2026/01/01/AI/2026-01-01-From-AI-Coding-Watch-World-Future/" data-id="cmjutw2y90001kybzd9hmz2l4" class="leave-reply bdsharebuttonbox" data-cmd="more"></a>
        </div> --><!-- .comments-link -->
      </header><!-- .entry-header -->

    <div class="entry-content">
      
        <p>TL;DR</p>
<ul>
<li>过去三周，我用 AI Coding 在零碎时间完成了 7 个真实项目，其中多个已开源并投入实际使用。</li>
<li>AI 已经不再只是“辅助写代码”，而是在<strong>架构清晰、决策明确的前提下，实质性替代了大量中级开发工作</strong>。</li>
<li>AI Coding 的上限不在模型，而在使用者：是否会设计、会 review、会做关键决策。</li>
<li>由 AI Coding 的跃迁可以窥见更大的变化：世界正在进入“超级个体”时代，个人能力被放大，但分化会更剧烈。</li>
<li>算法层面，基础模型、RL、多模态会继续变得更强大、更智能。</li>
<li>产品层面，具身智能、虚拟世界不再遥远，AIGC 将攻占互联网。</li>
<li>面对不可逆的技术浪潮，我选择“批判地接受”：积极参与，同时保留理性与属于自己的私有空间。</li>
</ul>
<hr>
<p>2025 年最后一天，2026 年第一天，之际，很想聊聊 AI 编程。我记得 2024 年底的时候，AI 编程还不怎么好用，当时用 MetaGPT 写了一个贪吃蛇，结果有个 bug 半天怎么都没弄好，最后还是我自己手动改了两处代码。</p>
<p>万万没想到啊，这才一年不到的时间，AI 编程居然到了如斯地步。年初的时候听说 cursor 比较好用，下载后随便玩了一下感觉没有想象中那么强。也尝试过 VSCode 的插件 Cline，用它做了个 Code review，怎么说呢，感觉没有达到自己的预期。</p>
<p>其实，我一直是重度 AI 使用者，Code 也在用，只是没有在一个 IDE 里用，大部分时候都是在 ChatGPT 的对话框里完成。常见的任务包括：完成某个功能的脚本、对已有代码进行改造（比如改多线程、异步等）、写单元测试等。</p>
<p>直到最近，突然看到 Trae 发布了 Solo 模式，想着试一试，于是在 2025 年 12 月初一下子开启了全面的 AI Coding。</p>
        
          <p class="article-more-link">
            <a href="/2026/01/01/AI/2026-01-01-From-AI-Coding-Watch-World-Future/#more" class="more-link">More <span class="meta-nav">→</span></a>
          </p>
        
      
    </div><!-- .entry-content -->

    <footer class="entry-meta">
    <a href="/2026/01/01/AI/2026-01-01-From-AI-Coding-Watch-World-Future/">
    <time datetime="2026-01-01T01:30:00.000Z" class="entry-date">
        2026-01-01
    </time>
</a>
    
  <span class="article-delim">&#8226;</span>
  <div class="article-category">
  <a class="article-category-link" href="/categories/Thinking/">Thinking</a>
  </div>

    
  <span class="article-delim">&#8226;</span>
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/AGI/">AGI</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/AI/">AI</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/AI-Coding/">AI-Coding</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Future/">Future</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/LLM/">LLM</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/antigravity/">antigravity</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/lightinfer/">lightinfer</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/pararun/">pararun</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/promptlog/">promptlog</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/trae/">trae</a></li></ul>

    </footer>
</article>





  
    <article id="post-Diary/2026-01-01-30to40" class="post-Diary/2026-01-01-30to40 post type-post status-publish format-standard hentry">
    <!---->

      <header class="entry-header">
        
        
  
    <h1 class="entry-title">
      <a class="article-title" href="/2026/01/01/Diary/2026-01-01-30to40/">站在 30-40 岁的档口</a>
    </h1>
  

        
        <!-- <div class="comments-link">
            
            <a href="javascript:void(0);" data-url="https://yam.gift/2026/01/01/Diary/2026-01-01-30to40/" data-id="cmjutw2y10000kybzpt5i6vyo" class="leave-reply bdsharebuttonbox" data-cmd="more"></a>
        </div> --><!-- .comments-link -->
      </header><!-- .entry-header -->

    <div class="entry-content">
      
            <!-- Table of Contents -->
              
        <p>人都说 30 而立，40 知天命。以前也懂，但毕竟不如亲自体验来的真实。这不，在快要进入“知天命”的路上，这种感觉愈发的真实。根据平时网上看到的一些文字，我知道，这种体会和感受应该是普遍的。</p>
<hr>
<p>我不知道这是关键时间点还是就是一个普普通通的成长过程，但现实就是如此：</p>
<p>慢慢地越来越不愿取悦他人，任何人。</p>
<p>很多事情上比较随意，感觉怎么样都行。</p>
<p>越来越讨厌虚伪的人和事，厌恶明明很假还看着一派和谐的样子。</p>
<p>懒，朋友圈懒得看、懒得发，自己的公众号懒得宣传，微信都经常懒得看。对所有社交失去耐心，连解释自己都觉得多余。</p>
<p>越来越回归家庭，发自内心觉得家庭最重要。</p>
<p>比原来更加注重身体健康。</p>
<p>老人肉眼可见的一天天变老、腿脚不太灵活、脑子不太好使，看着莫名发堵。</p>
<p>孩子尚小，每天吃睡玩是主题，好在不甚调皮，也能沟通。</p>
<p>孩子比什么都重要。</p>
<p>工作谁知道呢，谁也不知道能干到啥时候。对确定性已不再抱有幻想，只求可持续。</p>
<p>心中依然有理想，但上面好像打了一层蒙版。</p>
<p>不是对生活的妥协，而是自然而然就到了这么一种状态。</p>
<p>更加渴望稳定，但又想拥抱变化。</p>
<p>有时候想逃避某些事情。</p>
<p>变得越来越沉默。</p>
<hr>
<p>我一直以为人可以在某些方面一辈子保持不变，比如自己的性格。但随着年纪的增长，慢慢发现性格有没有改变不知道，但心态绝对在发生变化。</p>
<p>你依然可能不服输，但却少了许多锋芒；你依然可能有热爱，但却多了许多考量；你依然可能有渴望，但却多了许多克制。</p>
<p>以前看网上说 45 岁的男人怎样怎样，只觉得难以想象，无法理解。现在还没到这年龄呢，风向已经开始变了。噢噢，还有，变得越来越信玄学，以前虽说也信但其实没那么信，现在看起来没那么信，但内心深处貌似比较信。</p>
<p>其实，我都不知道为什么会这样。可能是性格本来就比较顺其自然，也可能经历过太多事和人，也有可能是真的因为年纪增长。</p>
<hr>
<p>难道这就是所谓“中年男人”？不知不觉、消无声息就这么变成了一个中年大叔……</p>
<p>固然成熟沉稳、技能精湛、心态稳定，但为啥总感觉不太一样呢？是缺了那股无知无畏的冲劲？还是什么其他东西？我不知道答案。</p>
<p>“人到中年”这个主题可能有很多聊不完的话题，但话到嘴边又想，说些啥呢，要说啥呢，要怎么开始说呢。最后化为三个字：“算了吧”。有啥好说的呢，懂得人他本来就懂，不需要多说；不懂的人你说再多他也体会不来，又有什么好说的。</p>
<p>嗯啊，就这样，“算了吧”。</p>
<hr>
<p>30-40，人生才过了一小截，想想退休年龄，还要工作将近 30 年呢。</p>
<p>有没有什么不一样的走法呢？</p>

      
    </div><!-- .entry-content -->

    <footer class="entry-meta">
    <a href="/2026/01/01/Diary/2026-01-01-30to40/">
    <time datetime="2026-01-01T00:00:00.000Z" class="entry-date">
        2026-01-01
    </time>
</a>
    
  <span class="article-delim">&#8226;</span>
  <div class="article-category">
  <a class="article-category-link" href="/categories/Thinking/">Thinking</a>
  </div>

    
  <span class="article-delim">&#8226;</span>
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Age/">Age</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Diary/">Diary</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Growth/">Growth</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Life/">Life</a></li></ul>

    </footer>
</article>





  
    <article id="post-NLP/LLM-Training/2025-12-31-RL-Are-You-OK" class="post-NLP/LLM-Training/2025-12-31-RL-Are-You-OK post type-post status-publish format-standard hentry">
    <!---->

      <header class="entry-header">
        
        
  
    <h1 class="entry-title">
      <a class="article-title" href="/2025/12/31/NLP/LLM-Training/2025-12-31-RL-Are-You-OK/">RL究竟能不能突破Base边界——关于推理能力外推、稳定性与训练条件的系统分析</a>
    </h1>
  

        
        <!-- <div class="comments-link">
            
            <a href="javascript:void(0);" data-url="https://yam.gift/2025/12/31/NLP/LLM-Training/2025-12-31-RL-Are-You-OK/" data-id="cmjtaa6mj0000dybzyulhntdb" class="leave-reply bdsharebuttonbox" data-cmd="more"></a>
        </div> --><!-- .comments-link -->
      </header><!-- .entry-header -->

    <div class="entry-content">
      
        <p>在 DeepSeek R1 之后，GRPO 几乎成了后训练的默认选项。它确实“好用”——在很多任务上，模型的 pass@1 明显提高了。但一个更根本的问题始终没有被真正回答：<strong>我们是在把模型“教得更会想”，还是只是在把它“已有的正确想法更容易采出来”？</strong></p>
<p>如果答案只是后者，那么强化学习更像是一种采样精炼器；而如果答案是前者，那就意味着模型的推理能力可以被系统性地“向外推”。</p>
<p>这两种理解对应着不同的训练目标，也自然导向了不同的训练策略。与之相关的研究结论之所以看似分化，往往源于训练设定与任务分布的差异：在某些工作中，RL 被观察到伴随能力跃迁；而在另一些设定下，其作用则始终未超出 Base 模型的能力边界。</p>
<p>本文并不试图在“RL 是否能够突破 Base”这一争论中选边站队，而是系统梳理已有工作的结论与假设，试图澄清一个更关键的问题：</p>
<p><strong>在什么条件下，RL 才可能表现为能力外推？而在什么情况下，它更合理地被理解为一种采样与抛光机制？</strong></p>
        
          <p class="article-more-link">
            <a href="/2025/12/31/NLP/LLM-Training/2025-12-31-RL-Are-You-OK/#more" class="more-link">More <span class="meta-nav">→</span></a>
          </p>
        
      
    </div><!-- .entry-content -->

    <footer class="entry-meta">
    <a href="/2025/12/31/NLP/LLM-Training/2025-12-31-RL-Are-You-OK/">
    <time datetime="2025-12-31T01:00:00.000Z" class="entry-date">
        2025-12-31
    </time>
</a>
    
  <span class="article-delim">&#8226;</span>
  <div class="article-category">
  <a class="article-category-link" href="/categories/Thinking/">Thinking</a>
  </div>

    
  <span class="article-delim">&#8226;</span>
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/AI/">AI</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/DELTA/">DELTA</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/GRPO/">GRPO</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/LLM/">LLM</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NLP/">NLP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/R1/">R1</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/RL/">RL</a></li></ul>

    </footer>
</article>





  
    <article id="post-Diary/2025-12-22-Love" class="post-Diary/2025-12-22-Love post type-post status-publish format-standard hentry">
    <!---->

      <header class="entry-header">
        
        
  
    <h1 class="entry-title">
      <a class="article-title" href="/2025/12/22/Diary/2025-12-22-Love/">所爱隔山海，山海亦可平</a>
    </h1>
  

        
        <!-- <div class="comments-link">
            
            <a href="javascript:void(0);" data-url="https://yam.gift/2025/12/22/Diary/2025-12-22-Love/" data-id="cmjhci9zu0000x2bz1fizdgkj" class="leave-reply bdsharebuttonbox" data-cmd="more"></a>
        </div> --><!-- .comments-link -->
      </header><!-- .entry-header -->

    <div class="entry-content">
      
            <!-- Table of Contents -->
              
        <p>前段时间空闲时间偶尔会想一个问题：“当历史的积累超越了人类学习的极限时会发生什么？”</p>
<p>其实不说以后，就现在已然出现知识爆炸的情况，研究方向越来越细，都不是“隔行如何山”了，稍微跨个方向可能都相差极大。是不是可以认为已经差不多到了“穷尽一生也学不完某个方向”的地步？</p>
<p>庄子曾说：“吾生也有涯，而知也无涯。以有涯随无涯，殆矣”。学无止境，古希腊哲学家芝诺也曾讲过一个“<a href="%5B%E8%8A%9D%E8%AF%BA%EF%BC%9A%E4%BA%BA%E7%9A%84%E7%9F%A5%E8%AF%86%E5%B0%B1%E5%A5%BD%E6%AF%94%E4%B8%80%E4%B8%AA%E5%9C%86%E5%9C%88%5D(http://www.qianyuangx.com/xyzj_con.aspx?pid=776)">知识圆圈说</a>”的故事。大概意思是，一个人的知识就好像一个圆圈，知识越多，圆圈越大，接触到的未知也越大。通俗来说就是：“知道的越多，不知道的越多”。</p>
<p>大哲学家尚且如此，我们普通人，怎么说呢，就是你越是热爱学习，越是努力学习，越发现知识的深不可测，以及自己的无知。我将之称为“知识黑洞”——当我们对一个方向钻研深入时，就好像误入黑洞——渺小、无助、但被吸引。</p>
<p>我是一名 AI 工程师，说到AI领域，那更是黑洞中的黑洞。文本、图像、视频、音频等不同模态算法，大模型、多模态、强化学习、推理部署等不同方向，这些还不算细分风向，比如大模型下的预训练、文本下的搜索、推理部署下的量化等等。另外，AI还属于计算机的分支，作为工程师你不能不懂编程、数据结构、计算机原理、网络、数据库等等。虽然很多方面可能并不需要掌握精深，但学习探索的时候也很容易扎下去，学到恍惚、迷惘。我时常会有这种无力感，不光是因为知识的无限，更是因为——我已经无法再像过去那样，相信“只要足够努力，就能覆盖足够多的世界”。很多时候我都会自问：努力之后呢？努力到什么时候呢？</p>
<p>面对这种情况，大概只有两种选择：不学和去学。</p>
<p>不学，很简单——维持现状，在现有位置上躺着即可。这种选择其实不见得不好。年轻的时候总觉得人就是得干出一番事业来，随着年纪的增长，逐渐认识到，平凡也是一种生活方式。幸福如人饮水，冷暖自知。很多时候“我”觉得人应该怎样其实只是“我”自己的观点，万不能强加到他人头上。</p>
<p>那去学呢？这就要考虑学什么、怎么学的问题。诚然，我们可以漫无目的地去学，这本身也是一种学习方式。但显然我们更看重有选择地去学，倒不一定有目的。这关键是机会成本，随着年纪增长，时间和精力越来越成为我们最宝贵的资源，我们当然希望能更有效力利用这些资源。这里的“有效”其实隐含了一个假设：我们需要有一个主线，说是理想也好、长期目标也罢，它的作用就是防止我们随波逐流，被这日益浮躁的社会冲跑。长期以往，即便速度慢，整体效率也不会低。在我看来，这个主线简单来说就是“所爱”——你所热爱的、挚爱的、永远为之着迷、为之充满热情的事物。找到它，一点一滴构建属于自己的体系，一砖一瓦筑造属于自己的框架。</p>
<p>“路虽远，行则将至”，心有所属，“不断前进，不断走向下一个目标”便是自然之事。这趟旅途可能永无终点，旅途路上可能日渐孤单，但我相信，“心之所向，身之所往”——“永远在路上”就是最好的修行。我不知道这样做是否能够获得世俗意义的成功，但它一定会让我们的心更加平静、祥和，这难道不也是一种成功？也许，人生本就没有所谓完美和圆满吧？</p>

      
    </div><!-- .entry-content -->

    <footer class="entry-meta">
    <a href="/2025/12/22/Diary/2025-12-22-Love/">
    <time datetime="2025-12-22T15:00:00.000Z" class="entry-date">
        2025-12-22
    </time>
</a>
    
  <span class="article-delim">&#8226;</span>
  <div class="article-category">
  <a class="article-category-link" href="/categories/Thinking/">Thinking</a>
  </div>

    
  <span class="article-delim">&#8226;</span>
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Diary/">Diary</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Growth/">Growth</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Life/">Life</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Study/">Study</a></li></ul>

    </footer>
</article>





  
    <article id="post-NLP/LLM-Training/2025-12-21-RM-New-Paradigm-Verify-Free-RL" class="post-NLP/LLM-Training/2025-12-21-RM-New-Paradigm-Verify-Free-RL post type-post status-publish format-standard hentry">
    <!---->

      <header class="entry-header">
        
        
  
    <h1 class="entry-title">
      <a class="article-title" href="/2025/12/21/NLP/LLM-Training/2025-12-21-RM-New-Paradigm-Verify-Free-RL/">Reward建模新范式：无验证RL——当模型只能相信自己，会发生什么？</a>
    </h1>
  

        
        <!-- <div class="comments-link">
            
            <a href="javascript:void(0);" data-url="https://yam.gift/2025/12/21/NLP/LLM-Training/2025-12-21-RM-New-Paradigm-Verify-Free-RL/" data-id="cmjfy0jse01cmhobzrrhlefls" class="leave-reply bdsharebuttonbox" data-cmd="more"></a>
        </div> --><!-- .comments-link -->
      </header><!-- .entry-header -->

    <div class="entry-content">
      
        <p>随着 GRPO 在后训练的不断应用和成熟，越来越多的任务都开始采用 RL 作为进一步提升效果的方案。但是对于那些缺乏明确标准答案的场景，除了人工标注外，还有没有其他比较高效、低成本的方案呢？</p>
<p>R1 之后出现了一种比较激进的方案：无验证 RL，模型不再依赖外部验证器，而是仅利用自身内部信号，如一致性、置信度或分布特征等来构造学习信号。</p>
<p>从最早的多数投票（TTRL、SRT），到基于熵与自确定性的强化学习，再到引入语义多样性与进化机制的最新方法，这个方向看似在不断取得进展，但其实这一类方法有个很严重的问题：“绝大多数内部反馈机制，本质上都在推动策略熵持续下降。”</p>
<p>这既解释了它们在训练初期或部分任务的有效性，同时也揭示了很多时候性能退化和探索崩塌的缘由。最新的工作从各个角度提出改进策略，如优势重塑、多样性奖励到进化式选择等等，但归根结底也都是在增加模型的探索能力，或者说平衡探索-利用。那么，对这种新的 RL 范式，你怎么看？</p>
<hr>
<p>TL;DR</p>
<ul>
<li>TTRL / SRT、EM / RENT、Intuitor、EMPO 等方法都在显式或隐式地最小化策略熵。</li>
<li>内部反馈奖励几乎必然导致策略熵单调下降，最终引发探索不足与性能退化。</li>
<li>ETTRL 通过高熵 token 分支 rollout 与基于熵的 advantage 重塑，缓解早期过度自信。</li>
<li>Darling 将语义多样性显式并入奖励，增加探索。</li>
<li>EVOL-RL 以“多数选择 + 新颖性变异”模拟进化过程，在稳定与探索之间取得更优平衡。</li>
<li>RESTRAIN 利用全部 rollout 信号，对低一致性与过度自信样本进行系统性惩罚。</li>
</ul>
<hr>
<table>
<thead>
<tr>
<th>方案</th>
<th>具体做法</th>
<th>特点</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://arxiv.org/abs/2504.16084" target="_blank" rel="noopener">TTRL 250422</a><sup>[1]</sup> / <a href="https://arxiv.org/abs/2505.21444" target="_blank" rel="noopener">SRT 250527</a><sup>[2]</sup></td>
<td>多数投票答案</td>
<td>部分领域（数学）使用</td>
</tr>
<tr>
<td><a href="https://arxiv.org/abs/2505.15134" target="_blank" rel="noopener">EM 250521</a><sup>[3]</sup> FT</td>
<td>直接最小化 token 级别熵（类似 SFT）</td>
<td>数学和编码任务中强</td>
</tr>
<tr>
<td><a href="https://arxiv.org/abs/2505.15134" target="_blank" rel="noopener">EM 250521</a><sup>[3]</sup> RL / <a href="https://arxiv.org/abs/2505.22660" target="_blank" rel="noopener">RENT 250528</a><sup>[4]</sup></td>
<td>熵作为奖励</td>
<td>能在大型数据集上收敛</td>
</tr>
<tr>
<td><a href="https://arxiv.org/abs/2505.15134" target="_blank" rel="noopener">EM 250521</a><sup>[3]</sup> INF</td>
<td>将 LLM 输出的 logits 视为可自由优化的参数</td>
<td>最小化输出分布的熵</td>
</tr>
<tr>
<td><a href="https://arxiv.org/abs/2504.05812" target="_blank" rel="noopener">EMPO 250408</a><sup>[5]</sup></td>
<td>将输出按语义聚类，语义簇熵作为奖励</td>
<td>增加一点多样性</td>
</tr>
<tr>
<td><a href="https://arxiv.org/abs/2505.19590" target="_blank" rel="noopener">Intuitor 250526</a><sup>[6]</sup></td>
<td>自确定性（输出分布与均匀分布的平均 KL 散度）作为奖励</td>
<td>对“更长文本偏好”偏差不敏感</td>
</tr>
<tr>
<td><a href="https://arxiv.org/abs/2508.11356" target="_blank" rel="noopener">ETTRL 250815</a><sup>[7]</sup></td>
<td>树状分支 rollout + Advantage clip</td>
<td>降低成本、缓解早期估计偏差</td>
</tr>
<tr>
<td><a href="https://arxiv.org/abs/2509.02534" target="_blank" rel="noopener">Darling 250902</a><sup>[8]</sup></td>
<td>奖励×多样性</td>
<td>增加回复的语义多样性</td>
</tr>
<tr>
<td><a href="https://arxiv.org/abs/2509.15194" target="_blank" rel="noopener">EVOL-RL 250918</a><sup>[9]</sup></td>
<td>模拟生物进化增加新颖性奖励</td>
<td>防止熵崩塌</td>
</tr>
<tr>
<td><a href="https://arxiv.org/abs/2510.02172" target="_blank" rel="noopener">RESTRAIN 251002</a><sup>[10]</sup></td>
<td>惩罚低一致性样本同时保留高潜力推理链</td>
<td>无监督自我改进</td>
</tr>
</tbody>
</table>
        
          <p class="article-more-link">
            <a href="/2025/12/21/NLP/LLM-Training/2025-12-21-RM-New-Paradigm-Verify-Free-RL/#more" class="more-link">More <span class="meta-nav">→</span></a>
          </p>
        
      
    </div><!-- .entry-content -->

    <footer class="entry-meta">
    <a href="/2025/12/21/NLP/LLM-Training/2025-12-21-RM-New-Paradigm-Verify-Free-RL/">
    <time datetime="2025-12-21T15:00:00.000Z" class="entry-date">
        2025-12-21
    </time>
</a>
    
  <span class="article-delim">&#8226;</span>
  <div class="article-category">
  <a class="article-category-link" href="/categories/Thinking/">Thinking</a>
  </div>

    
  <span class="article-delim">&#8226;</span>
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/AI/">AI</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Darling/">Darling</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/EM/">EM</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/EMPO/">EMPO</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ETTRL/">ETTRL</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/EVOL-RL/">EVOL-RL</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/GRPO/">GRPO</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Intuitor/">Intuitor</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/LLM/">LLM</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NLP/">NLP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/R1/">R1</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/RENT/">RENT</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/RESTRAIN/">RESTRAIN</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/RL/">RL</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/SRT/">SRT</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/TTRL/">TTRL</a></li></ul>

    </footer>
</article>





  
    <article id="post-NLP/LLM-Training/2025-12-03-DeepSeek-V32-PostTraining" class="post-NLP/LLM-Training/2025-12-03-DeepSeek-V32-PostTraining post type-post status-publish format-standard hentry">
    <!---->

      <header class="entry-header">
        
        
  
    <h1 class="entry-title">
      <a class="article-title" href="/2025/12/03/NLP/LLM-Training/2025-12-03-DeepSeek-V32-PostTraining/">DeepSeekV3.2后训练：稳定压倒一切</a>
    </h1>
  

        
        <!-- <div class="comments-link">
            
            <a href="javascript:void(0);" data-url="https://yam.gift/2025/12/03/NLP/LLM-Training/2025-12-03-DeepSeek-V32-PostTraining/" data-id="cmjfy0jsa01cbhobzm8k06iiz" class="leave-reply bdsharebuttonbox" data-cmd="more"></a>
        </div> --><!-- .comments-link -->
      </header><!-- .entry-header -->

    <div class="entry-content">
      
        <p>DeepSeek-V3.2 发布后，外界讨论大多集中在“新增了工具使用”、“是不是比某某更强”之类的话题。但如果你真正关心模型训练，会发现它最值得研究的地方根本不在模型能力，而是在 <strong>后训练（post-training）阶段的一系列稳定性工程</strong>。V3.2 不像 V3 带来结构性突破，更像是一次“工程师版本的 V3.2”：没什么光鲜亮丽的大新闻，但每一个小改动都在解决真实训练痛点。</p>
<p>TL;DR</p>
<p>DeepSeek-V3.2 的后训练重点不是“更强”，而是“更稳”。大量技巧围绕 <strong>GRPO 稳定性</strong> 展开。</p>
<ul>
<li>数据部分：多个领域专用专家 → 生成数据 → 蒸馏到统一模型。</li>
<li>GRPO 稳定性优化：
<ul>
<li><strong>Advantage 去标准差</strong>：消除难度偏差，提高样本权重的公平性。</li>
<li><strong>KL 的无偏修正</strong>：基于 K3 + 重要性采样，使 KL 梯度更稳定可靠。</li>
<li><strong>序列级 off-policy 掩码</strong>：屏蔽高偏差且优势为负的序列，显著提升稳定性。</li>
<li><strong>MoE 路由保持</strong>：固定专家路由，避免 off-policy 和训推框架不同导致的路由漂移。</li>
<li><strong>采样保持</strong>：保持 <code>π_old</code> 与 <code>π_θ</code> 的动作空间一致，避免采样截断可能带来的稳定性问题。</li>
</ul>
</li>
<li>工具使用部分提出<strong>更高效的思维轨迹管理方式</strong>：只有新用户消息进来才清空工具调用推理轨迹，工具调用历史则始终保留。</li>
</ul>
        
          <p class="article-more-link">
            <a href="/2025/12/03/NLP/LLM-Training/2025-12-03-DeepSeek-V32-PostTraining/#more" class="more-link">More <span class="meta-nav">→</span></a>
          </p>
        
      
    </div><!-- .entry-content -->

    <footer class="entry-meta">
    <a href="/2025/12/03/NLP/LLM-Training/2025-12-03-DeepSeek-V32-PostTraining/">
    <time datetime="2025-12-03T15:00:00.000Z" class="entry-date">
        2025-12-03
    </time>
</a>
    
  <span class="article-delim">&#8226;</span>
  <div class="article-category">
  <a class="article-category-link" href="/categories/Feeling/">Feeling</a>
  </div>

    
  <span class="article-delim">&#8226;</span>
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/AI/">AI</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/DeepSeek/">DeepSeek</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/DeepSeek-V3-2/">DeepSeek-V3.2</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/GRPO/">GRPO</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/KL/">KL</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/LLM/">LLM</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/MoE/">MoE</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NLP/">NLP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Post-Training/">Post-Training</a></li></ul>

    </footer>
</article>





  
    <article id="post-NLP/LLM-Training/2025-11-29-Reward-Data-Self-Verified" class="post-NLP/LLM-Training/2025-11-29-Reward-Data-Self-Verified post type-post status-publish format-standard hentry">
    <!---->

      <header class="entry-header">
        
        
  
    <h1 class="entry-title">
      <a class="article-title" href="/2025/11/29/NLP/LLM-Training/2025-11-29-Reward-Data-Self-Verified/">DeepSeekMath-V2自我验证：搞数据的风吹到了奖励模型</a>
    </h1>
  

        
        <!-- <div class="comments-link">
            
            <a href="javascript:void(0);" data-url="https://yam.gift/2025/11/29/NLP/LLM-Training/2025-11-29-Reward-Data-Self-Verified/" data-id="cmjfy0jrz01bqhobzk45b1z8e" class="leave-reply bdsharebuttonbox" data-cmd="more"></a>
        </div> --><!-- .comments-link -->
      </header><!-- .entry-header -->

    <div class="entry-content">
      
        <p>在开放性问题上，仅靠生成答案很容易出错。如何让模型不仅能写出证明，还能识别自身错误，从而形成闭环优化？答案是——<strong>自我验证</strong>。来看一下 DeepSeek 最新的论文：<a href="https://github.com/deepseek-ai/DeepSeek-Math-V2" target="_blank" rel="noopener">DeepSeekMath-V2: Towards Self-Verifiable Mathematical Reasoning</a><sup>[1]</sup>，看自我验证如何让 LLM 生成与评估协同来提升数学定理证明能力。</p>
<p>TL; DR</p>
<ul>
<li><strong>训练验证器</strong>：验证器不仅打分，还识别证明中的问题。</li>
<li><strong>引入元验证</strong>：通过二次评分机制防止验证器虚构问题，使验证分析更可靠。</li>
<li><strong>训练生成器</strong>：生成器在生成证明后进行自我分析，并根据验证器和元验证器的反馈优化输出。</li>
<li><strong>验证生成协同</strong>：生成器与验证器形成闭环，生成新的证明挑战验证器能力，同时扩大自动标注数据，提高整体系统可靠性。</li>
</ul>
<p>核心启示是：<strong>奖励模型不仅要给分数，更要建模评估分析过程</strong>，让生成与验证形成协同闭环，显著提升开放性问题的推理能力。</p>
<p><img src="https://qnimg.lovevivian.cn/paper-deepseekmath-v2-2.jpg" alt></p>
        
          <p class="article-more-link">
            <a href="/2025/11/29/NLP/LLM-Training/2025-11-29-Reward-Data-Self-Verified/#more" class="more-link">More <span class="meta-nav">→</span></a>
          </p>
        
      
    </div><!-- .entry-content -->

    <footer class="entry-meta">
    <a href="/2025/11/29/NLP/LLM-Training/2025-11-29-Reward-Data-Self-Verified/">
    <time datetime="2025-11-29T04:00:00.000Z" class="entry-date">
        2025-11-29
    </time>
</a>
    
  <span class="article-delim">&#8226;</span>
  <div class="article-category">
  <a class="article-category-link" href="/categories/Feeling/">Feeling</a>
  </div>

    
  <span class="article-delim">&#8226;</span>
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/AI/">AI</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/DeepSeek/">DeepSeek</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/DeepSeekMath-V2/">DeepSeekMath-V2</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/LLM/">LLM</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NLP/">NLP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/RM/">RM</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Reward/">Reward</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Self-Verified/">Self-Verified</a></li></ul>

    </footer>
</article>





  
    <article id="post-Python/2025-11-23-LLM-Message-Issue" class="post-Python/2025-11-23-LLM-Message-Issue post type-post status-publish format-standard hentry">
    <!---->

      <header class="entry-header">
        
        
  
    <h1 class="entry-title">
      <a class="article-title" href="/2025/11/23/Python/2025-11-23-LLM-Message-Issue/">两处容易踩的坑：LLM 消息数组与字典工具的隐藏副作用</a>
    </h1>
  

        
        <!-- <div class="comments-link">
            
            <a href="javascript:void(0);" data-url="https://yam.gift/2025/11/23/Python/2025-11-23-LLM-Message-Issue/" data-id="cmjfy0jgj00lmhobzfl9gw9ts" class="leave-reply bdsharebuttonbox" data-cmd="more"></a>
        </div> --><!-- .comments-link -->
      </header><!-- .entry-header -->

    <div class="entry-content">
      
        <p>在 LLM 应用开发里，我们经常需要处理多轮消息、对话历史等结构化内容。理论上，这些对象应该是简单、透明、可控的——但在 NumPy 和特定字典工具（如 <code>addict.Dict</code>）参与后，一些微妙的行为会悄悄改变数据结构，让输出变得诡异甚至完全不对。本篇记录我在实际开发（尤其是 verl 与 transformers）中遇到的两个“小问题”：一个来自 NumPy 的自动维度推断，另一个来自字典工具的默认属性行为。它们不是 bug，却可能让你花一阵子 debug。</p>
<p>TL;DR</p>
<ul>
<li><strong>NumPy 变长消息问题</strong>：当使用 <code>np.array(..., dtype=object)</code> 处理长度不一致的消息列表时，NumPy 可能返回不同维度的数组，导致后续处理出错。改用 <code>np.fromiter</code> 或预分配 object 数组并赋值，可确保输出结构统一。</li>
<li><strong>字典赋值工具干扰问题</strong>：使用 <code>addict.Dict</code> 等动态字典工具包装消息数据时，其默认行为会干扰 transformers 对消息结构的正确判断，导致模板生成错误。可换用 <code>OmegaConf</code> 或修改 <code>addict</code> 源码禁用自动建键功能以修复问题。</li>
</ul>
        
          <p class="article-more-link">
            <a href="/2025/11/23/Python/2025-11-23-LLM-Message-Issue/#more" class="more-link">More <span class="meta-nav">→</span></a>
          </p>
        
      
    </div><!-- .entry-content -->

    <footer class="entry-meta">
    <a href="/2025/11/23/Python/2025-11-23-LLM-Message-Issue/">
    <time datetime="2025-11-23T15:00:00.000Z" class="entry-date">
        2025-11-23
    </time>
</a>
    
  <span class="article-delim">&#8226;</span>
  <div class="article-category">
  <a class="article-category-link" href="/categories/Coding/">Coding</a>
  </div>

    
  <span class="article-delim">&#8226;</span>
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/AI/">AI</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/LLM/">LLM</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NLP/">NLP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NumPy/">NumPy</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Tokenizer/">Tokenizer</a></li></ul>

    </footer>
</article>





  
  
    <nav id="pagination">
      <nav id="page-nav">
        <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/28/">28</a><a class="extend next" rel="next" href="/page/2/">Next &raquo;</a>
      </nav>
    </nav>
  
</div></div>
        <div id="secondary" class="widget-area" role="complementary">
  
    
  <aside class="widget">
    <h3 class="widget-title">Categories</h3>
    <div class="widget-content">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Coding/">Coding</a><span class="category-list-count">75</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Feeling/">Feeling</a><span class="category-list-count">152</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Thinking/">Thinking</a><span class="category-list-count">52</span></li></ul>
    </div>
  </aside>

  
    
  <aside class="widget">
    <h3 class="widget-title">Music</h3>
    <div class="widget-content">
      <iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=541131&auto=0&height=66"></iframe>
      <!-- 评论代码 -->
      <!-- <audio src="http://qnimg.lovevivian.cn/miss.mp3" controls="controls"
             style="width:100%">
        您的浏览器不支持 audio 标签。
      </audio> -->
    </div>
  </aside>

  
    
  <aside class="widget">
    <h3 class="widget-title">Recents</h3>
    <div class="widget-content">
      <ul>
        
          <li>
            <a href="/2026/01/03/ListenGlimmer/001/">聆听·微光 001：一位研究生在读的”reward hacker“关于学习的困惑</a>
          </li>
        
          <li>
            <a href="/2026/01/03/ListenGlimmer/000/">聆听·微光</a>
          </li>
        
          <li>
            <a href="/2026/01/01/AI/2026-01-01-From-AI-Coding-Watch-World-Future/">以 AI Coding 之管窥探世界之变</a>
          </li>
        
          <li>
            <a href="/2026/01/01/Diary/2026-01-01-30to40/">站在 30-40 岁的档口</a>
          </li>
        
          <li>
            <a href="/2025/12/31/NLP/LLM-Training/2025-12-31-RL-Are-You-OK/">RL究竟能不能突破Base边界——关于推理能力外推、稳定性与训练条件的系统分析</a>
          </li>
        
      </ul>
    </div>
  </aside>

  
    
  <aside class="widget">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget-content tagcloud">
      <a href="/tags/AE/" style="font-size: 10px;">AE</a> <a href="/tags/AGI/" style="font-size: 10.67px;">AGI</a> <a href="/tags/AI/" style="font-size: 20px;">AI</a> <a href="/tags/AI-Coding/" style="font-size: 10px;">AI-Coding</a> <a href="/tags/AIGC/" style="font-size: 10.67px;">AIGC</a> <a href="/tags/ALBERT/" style="font-size: 10px;">ALBERT</a> <a href="/tags/AR/" style="font-size: 10px;">AR</a> <a href="/tags/AUC/" style="font-size: 10px;">AUC</a> <a href="/tags/Accuracy/" style="font-size: 10px;">Accuracy</a> <a href="/tags/Activation/" style="font-size: 10px;">Activation</a> <a href="/tags/Activation-Steering/" style="font-size: 10px;">Activation Steering</a> <a href="/tags/Age/" style="font-size: 10px;">Age</a> <a href="/tags/Agent/" style="font-size: 10px;">Agent</a> <a href="/tags/Aha/" style="font-size: 10px;">Aha</a> <a href="/tags/Algorithm/" style="font-size: 12.67px;">Algorithm</a> <a href="/tags/Array/" style="font-size: 10px;">Array</a> <a href="/tags/Arrow/" style="font-size: 10px;">Arrow</a> <a href="/tags/Attention/" style="font-size: 12px;">Attention</a> <a href="/tags/Automatic-Speech-Processing/" style="font-size: 10px;">Automatic Speech Processing</a> <a href="/tags/Automation/" style="font-size: 10px;">Automation</a> <a href="/tags/BERT/" style="font-size: 16.67px;">BERT</a> <a href="/tags/BIO/" style="font-size: 10.67px;">BIO</a> <a href="/tags/BIOHD/" style="font-size: 10.67px;">BIOHD</a> <a href="/tags/BM25/" style="font-size: 10px;">BM25</a> <a href="/tags/BPE/" style="font-size: 10px;">BPE</a> <a href="/tags/BabyGrow/" style="font-size: 10px;">BabyGrow</a> <a href="/tags/Backtracking/" style="font-size: 10px;">Backtracking</a> <a href="/tags/Backward/" style="font-size: 10px;">Backward</a> <a href="/tags/Bahdanau-Attention/" style="font-size: 10px;">Bahdanau Attention</a> <a href="/tags/Bart/" style="font-size: 10px;">Bart</a> <a href="/tags/Bayes/" style="font-size: 10px;">Bayes</a> <a href="/tags/Beam-Search/" style="font-size: 10px;">Beam Search</a> <a href="/tags/Bert-Flow/" style="font-size: 10px;">Bert-Flow</a> <a href="/tags/Bi-LSTM/" style="font-size: 10px;">Bi-LSTM</a> <a href="/tags/Biasing/" style="font-size: 10px;">Biasing</a> <a href="/tags/BigCodec/" style="font-size: 10px;">BigCodec</a> <a href="/tags/Binary-Search/" style="font-size: 11.33px;">Binary Search</a> <a href="/tags/Blending/" style="font-size: 10px;">Blending</a> <a href="/tags/Brain/" style="font-size: 10px;">Brain</a> <a href="/tags/Brain-Decoding/" style="font-size: 10px;">Brain Decoding</a> <a href="/tags/Bridge/" style="font-size: 10px;">Bridge</a> <a href="/tags/Business/" style="font-size: 12px;">Business</a> <a href="/tags/C/" style="font-size: 10.67px;">C</a> <a href="/tags/C4/" style="font-size: 10px;">C4</a> <a href="/tags/CCG/" style="font-size: 10.67px;">CCG</a> <a href="/tags/CE-BERT/" style="font-size: 10px;">CE BERT</a> <a href="/tags/CFG/" style="font-size: 10px;">CFG</a> <a href="/tags/CISPO/" style="font-size: 10px;">CISPO</a> <a href="/tags/CKY/" style="font-size: 10px;">CKY</a> <a href="/tags/CNN/" style="font-size: 10px;">CNN</a> <a href="/tags/CRF/" style="font-size: 10px;">CRF</a> <a href="/tags/CS/" style="font-size: 10px;">CS</a> <a href="/tags/CYK/" style="font-size: 10px;">CYK</a> <a href="/tags/Calculus/" style="font-size: 10px;">Calculus</a> <a href="/tags/Camera/" style="font-size: 10px;">Camera</a> <a href="/tags/Cascades/" style="font-size: 10px;">Cascades</a> <a href="/tags/Catalan/" style="font-size: 10px;">Catalan</a> <a href="/tags/ChatBot/" style="font-size: 10px;">ChatBot</a> <a href="/tags/ChatGPT/" style="font-size: 15.33px;">ChatGPT</a> <a href="/tags/Chi2/" style="font-size: 10px;">Chi2</a> <a href="/tags/Chunking/" style="font-size: 10px;">Chunking</a> <a href="/tags/Class-Imbalance-Loss/" style="font-size: 10px;">Class Imbalance Loss</a> <a href="/tags/Classification/" style="font-size: 10.67px;">Classification</a> <a href="/tags/Clip/" style="font-size: 10px;">Clip</a> <a href="/tags/CoT/" style="font-size: 10px;">CoT</a> <a href="/tags/Codec/" style="font-size: 12px;">Codec</a> <a href="/tags/Cognition/" style="font-size: 10.67px;">Cognition</a> <a href="/tags/Collaborative-Filtering/" style="font-size: 10px;">Collaborative Filtering</a> <a href="/tags/Collins-Parser/" style="font-size: 10px;">Collins Parser</a> <a href="/tags/Computational-Linguistics/" style="font-size: 10px;">Computational Linguistics</a> <a href="/tags/Computer/" style="font-size: 10px;">Computer</a> <a href="/tags/Computer-Science/" style="font-size: 12px;">Computer Science</a> <a href="/tags/Confusing-Labels/" style="font-size: 10px;">Confusing Labels</a> <a href="/tags/Context-Engineering/" style="font-size: 10px;">Context Engineering</a> <a href="/tags/Context-Free-Grammars/" style="font-size: 10px;">Context-Free Grammars</a> <a href="/tags/Continual-Pre-training/" style="font-size: 14px;">Continual Pre-training</a> <a href="/tags/Continual-Pretraining/" style="font-size: 10.67px;">Continual Pretraining</a> <a href="/tags/Contrastive-Learning/" style="font-size: 10px;">Contrastive-Learning</a> <a href="/tags/Coordinate-Ascent/" style="font-size: 10px;">Coordinate Ascent</a> <a href="/tags/Cosine/" style="font-size: 10.67px;">Cosine</a> <a href="/tags/Cosine-Similarity/" style="font-size: 10px;">Cosine Similarity</a> <a href="/tags/Cross-Entropy/" style="font-size: 10px;">Cross Entropy</a> <a href="/tags/Cross-brackets/" style="font-size: 10px;">Cross-brackets</a> <a href="/tags/Cross-view/" style="font-size: 10px;">Cross-view</a> <a href="/tags/Ctrl/" style="font-size: 10px;">Ctrl</a> <a href="/tags/Culture/" style="font-size: 10px;">Culture</a> <a href="/tags/DA/" style="font-size: 10px;">DA</a> <a href="/tags/DAC/" style="font-size: 10px;">DAC</a> <a href="/tags/DAPO/" style="font-size: 14px;">DAPO</a> <a href="/tags/DB/" style="font-size: 10.67px;">DB</a> <a href="/tags/DCPO/" style="font-size: 10px;">DCPO</a> <a href="/tags/DELTA/" style="font-size: 10px;">DELTA</a> <a href="/tags/DNN/" style="font-size: 10px;">DNN</a> <a href="/tags/DP/" style="font-size: 10px;">DP</a> <a href="/tags/DPO/" style="font-size: 10px;">DPO</a> <a href="/tags/Darling/" style="font-size: 10px;">Darling</a> <a href="/tags/Data-Augmentation/" style="font-size: 10px;">Data Augmentation</a> <a href="/tags/Data-Clearing/" style="font-size: 10px;">Data Clearing</a> <a href="/tags/Data-Enhancement/" style="font-size: 10px;">Data Enhancement</a> <a href="/tags/Data-Preprocess/" style="font-size: 10px;">Data Preprocess</a> <a href="/tags/Data-Science/" style="font-size: 14px;">Data Science</a> <a href="/tags/Data-Structure/" style="font-size: 15.33px;">Data Structure</a> <a href="/tags/DataManagement/" style="font-size: 10.67px;">DataManagement</a> <a href="/tags/Database/" style="font-size: 10px;">Database</a> <a href="/tags/DeBERTa/" style="font-size: 10px;">DeBERTa</a> <a href="/tags/Debiasing/" style="font-size: 10px;">Debiasing</a> <a href="/tags/Decoder/" style="font-size: 10px;">Decoder</a> <a href="/tags/Decoding/" style="font-size: 10.67px;">Decoding</a> <a href="/tags/Deep/" style="font-size: 10px;">Deep</a> <a href="/tags/DeepGen/" style="font-size: 10px;">DeepGen</a> <a href="/tags/DeepGraph/" style="font-size: 10px;">DeepGraph</a> <a href="/tags/DeepLearning/" style="font-size: 12px;">DeepLearning</a> <a href="/tags/DeepScaleR/" style="font-size: 10.67px;">DeepScaleR</a> <a href="/tags/DeepSeek/" style="font-size: 11.33px;">DeepSeek</a> <a href="/tags/DeepSeek-GRM/" style="font-size: 10px;">DeepSeek-GRM</a> <a href="/tags/DeepSeek-V3-2/" style="font-size: 10px;">DeepSeek-V3.2</a> <a href="/tags/DeepSeekMath-V2/" style="font-size: 10px;">DeepSeekMath-V2</a> <a href="/tags/DeltaNet/" style="font-size: 10px;">DeltaNet</a> <a href="/tags/Dependence/" style="font-size: 10px;">Dependence</a> <a href="/tags/Diary/" style="font-size: 16px;">Diary</a> <a href="/tags/Disentangled-Attention/" style="font-size: 10px;">Disentangled Attention</a> <a href="/tags/DistilBERT/" style="font-size: 10px;">DistilBERT</a> <a href="/tags/Distillation/" style="font-size: 10.67px;">Distillation</a> <a href="/tags/Django/" style="font-size: 10px;">Django</a> <a href="/tags/Docker/" style="font-size: 10px;">Docker</a> <a href="/tags/Docker-Compose/" style="font-size: 10px;">Docker-Compose</a> <a href="/tags/Dockerfile/" style="font-size: 10px;">Dockerfile</a> <a href="/tags/Dr-GRPO/" style="font-size: 10px;">Dr GRPO</a> <a href="/tags/DrDAPO/" style="font-size: 10px;">DrDAPO</a> <a href="/tags/DrGRPO/" style="font-size: 10px;">DrGRPO</a> <a href="/tags/Dream/" style="font-size: 10.67px;">Dream</a> <a href="/tags/Dropout/" style="font-size: 10.67px;">Dropout</a> <a href="/tags/Dynamic-Mask/" style="font-size: 10px;">Dynamic-Mask</a> <a href="/tags/EDA/" style="font-size: 10px;">EDA</a> <a href="/tags/EM/" style="font-size: 10px;">EM</a> <a href="/tags/EMD/" style="font-size: 10px;">EMD</a> <a href="/tags/EMPO/" style="font-size: 10px;">EMPO</a> <a href="/tags/ERNIE/" style="font-size: 10px;">ERNIE</a> <a href="/tags/ETTRL/" style="font-size: 10px;">ETTRL</a> <a href="/tags/EVOL-RL/" style="font-size: 10px;">EVOL-RL</a> <a href="/tags/Economics/" style="font-size: 10px;">Economics</a> <a href="/tags/Edit-Distance/" style="font-size: 10px;">Edit Distance</a> <a href="/tags/Efficient-DeepLearning/" style="font-size: 10px;">Efficient-DeepLearning</a> <a href="/tags/Elasticsearch/" style="font-size: 10px;">Elasticsearch</a> <a href="/tags/Electra/" style="font-size: 10px;">Electra</a> <a href="/tags/Elixir/" style="font-size: 10.67px;">Elixir</a> <a href="/tags/Ellipsis/" style="font-size: 10px;">Ellipsis</a> <a href="/tags/Embedding/" style="font-size: 11.33px;">Embedding</a> <a href="/tags/Embeddings/" style="font-size: 10.67px;">Embeddings</a> <a href="/tags/Embodied-AI/" style="font-size: 10px;">Embodied AI</a> <a href="/tags/Encoder/" style="font-size: 10px;">Encoder</a> <a href="/tags/Entropy/" style="font-size: 11.33px;">Entropy</a> <a href="/tags/Evaluation/" style="font-size: 10.67px;">Evaluation</a> <a href="/tags/Eventlet/" style="font-size: 10px;">Eventlet</a> <a href="/tags/ExT5/" style="font-size: 10px;">ExT5</a> <a href="/tags/Exam/" style="font-size: 10px;">Exam</a> <a href="/tags/F1/" style="font-size: 10px;">F1</a> <a href="/tags/FD-Leak/" style="font-size: 10px;">FD Leak</a> <a href="/tags/FDW/" style="font-size: 10px;">FDW</a> <a href="/tags/FLAN/" style="font-size: 10px;">FLAN</a> <a href="/tags/FSM/" style="font-size: 10px;">FSM</a> <a href="/tags/Faith/" style="font-size: 10px;">Faith</a> <a href="/tags/FastCuRL/" style="font-size: 10px;">FastCuRL</a> <a href="/tags/Feature-Engineering/" style="font-size: 10px;">Feature Engineering</a> <a href="/tags/Feature-based/" style="font-size: 10px;">Feature-based</a> <a href="/tags/Few-Shot/" style="font-size: 11.33px;">Few-Shot</a> <a href="/tags/Few-shot-Prompting/" style="font-size: 10px;">Few-shot Prompting</a> <a href="/tags/Fine-tuning/" style="font-size: 10px;">Fine-tuning</a> <a href="/tags/Formal-Grammars/" style="font-size: 11.33px;">Formal Grammars</a> <a href="/tags/Forward/" style="font-size: 10px;">Forward</a> <a href="/tags/Full-Text-Search/" style="font-size: 10px;">Full-Text-Search</a> <a href="/tags/Function-Syntax/" style="font-size: 10px;">Function Syntax</a> <a href="/tags/Funk-MF/" style="font-size: 10px;">Funk MF</a> <a href="/tags/Funnel-Transformer/" style="font-size: 10px;">Funnel Transformer</a> <a href="/tags/Future/" style="font-size: 10px;">Future</a> <a href="/tags/GAE/" style="font-size: 10px;">GAE</a> <a href="/tags/GBTD/" style="font-size: 10px;">GBTD</a> <a href="/tags/GELU/" style="font-size: 10px;">GELU</a> <a href="/tags/GLU/" style="font-size: 10px;">GLU</a> <a href="/tags/GMPO/" style="font-size: 10.67px;">GMPO</a> <a href="/tags/GP/" style="font-size: 10px;">GP</a> <a href="/tags/GPT-1/" style="font-size: 10px;">GPT-1</a> <a href="/tags/GPT-2/" style="font-size: 10.67px;">GPT-2</a> <a href="/tags/GPT-3/" style="font-size: 10px;">GPT-3</a> <a href="/tags/GPT3/" style="font-size: 10px;">GPT3</a> <a href="/tags/GPU/" style="font-size: 10px;">GPU</a> <a href="/tags/GRM/" style="font-size: 10px;">GRM</a> <a href="/tags/GRPO/" style="font-size: 16.67px;">GRPO</a> <a href="/tags/GRU/" style="font-size: 10px;">GRU</a> <a href="/tags/GSG/" style="font-size: 10px;">GSG</a> <a href="/tags/GSPO/" style="font-size: 10px;">GSPO</a> <a href="/tags/GTPO/" style="font-size: 10px;">GTPO</a> <a href="/tags/GTPO-S/" style="font-size: 10px;">GTPO-S</a> <a href="/tags/Gan/" style="font-size: 10px;">Gan</a> <a href="/tags/Garden-path/" style="font-size: 10px;">Garden-path</a> <a href="/tags/Gated-DeltaNet/" style="font-size: 10px;">Gated DeltaNet</a> <a href="/tags/GiGPO/" style="font-size: 10px;">GiGPO</a> <a href="/tags/Git/" style="font-size: 10px;">Git</a> <a href="/tags/Global-Pointer/" style="font-size: 10px;">Global Pointer</a> <a href="/tags/Glow/" style="font-size: 10px;">Glow</a> <a href="/tags/Graceful-Shutdown/" style="font-size: 10px;">Graceful Shutdown</a> <a href="/tags/Gradient-Descent/" style="font-size: 10px;">Gradient Descent</a> <a href="/tags/Graph/" style="font-size: 10.67px;">Graph</a> <a href="/tags/GraphQL/" style="font-size: 10.67px;">GraphQL</a> <a href="/tags/Grid-Grammar/" style="font-size: 10px;">Grid Grammar</a> <a href="/tags/Growth/" style="font-size: 15.33px;">Growth</a> <a href="/tags/H2O-Danube/" style="font-size: 10px;">H2O-Danube</a> <a href="/tags/HMM/" style="font-size: 10.67px;">HMM</a> <a href="/tags/Hard-SVM/" style="font-size: 10px;">Hard-SVM</a> <a href="/tags/Hinge-Loss/" style="font-size: 10px;">Hinge Loss</a> <a href="/tags/Hope/" style="font-size: 10px;">Hope</a> <a href="/tags/Host-only/" style="font-size: 10px;">Host-only</a> <a href="/tags/HuggingLLM/" style="font-size: 10px;">HuggingLLM</a> <a href="/tags/Human-in-Loop/" style="font-size: 10px;">Human-in-Loop</a> <a href="/tags/Human-in-the-Loop/" style="font-size: 10px;">Human-in-the-Loop</a> <a href="/tags/IDE/" style="font-size: 10px;">IDE</a> <a href="/tags/IE/" style="font-size: 10px;">IE</a> <a href="/tags/IQR/" style="font-size: 10px;">IQR</a> <a href="/tags/Imbalance-Data/" style="font-size: 10px;">Imbalance Data</a> <a href="/tags/Impossible-Triangle/" style="font-size: 10px;">Impossible-Triangle</a> <a href="/tags/In-Context-Learning/" style="font-size: 10.67px;">In-Context Learning</a> <a href="/tags/Industry/" style="font-size: 10px;">Industry</a> <a href="/tags/Inference-Scaling/" style="font-size: 11.33px;">Inference Scaling</a> <a href="/tags/Information-Extraction/" style="font-size: 10px;">Information Extraction</a> <a href="/tags/Information-Theory/" style="font-size: 10px;">Information Theory</a> <a href="/tags/Instruct/" style="font-size: 10px;">Instruct</a> <a href="/tags/InstructGPT/" style="font-size: 10.67px;">InstructGPT</a> <a href="/tags/Instruction-Following/" style="font-size: 12px;">Instruction Following</a> <a href="/tags/Instruction-Inference/" style="font-size: 10px;">Instruction Inference</a> <a href="/tags/Intuitor/" style="font-size: 10px;">Intuitor</a> <a href="/tags/Isolation-Forest/" style="font-size: 10px;">Isolation Forest</a> <a href="/tags/ItemCF/" style="font-size: 10px;">ItemCF</a> <a href="/tags/Jaccard/" style="font-size: 10px;">Jaccard</a> <a href="/tags/Java/" style="font-size: 10px;">Java</a> <a href="/tags/Jax/" style="font-size: 10px;">Jax</a> <a href="/tags/Job/" style="font-size: 10px;">Job</a> <a href="/tags/Jupyter/" style="font-size: 10px;">Jupyter</a> <a href="/tags/K2/" style="font-size: 10px;">K2</a> <a href="/tags/KKT/" style="font-size: 10px;">KKT</a> <a href="/tags/KL/" style="font-size: 11.33px;">KL</a> <a href="/tags/KS/" style="font-size: 10px;">KS</a> <a href="/tags/Kernel/" style="font-size: 10px;">Kernel</a> <a href="/tags/Kernel-Function/" style="font-size: 10px;">Kernel Function</a> <a href="/tags/Kernel-Method/" style="font-size: 10px;">Kernel Method</a> <a href="/tags/Keyword/" style="font-size: 10px;">Keyword</a> <a href="/tags/Knowledge-Graph/" style="font-size: 10.67px;">Knowledge Graph</a> <a href="/tags/L1/" style="font-size: 10px;">L1</a> <a href="/tags/LCPO/" style="font-size: 10px;">LCPO</a> <a href="/tags/LIMD/" style="font-size: 10.67px;">LIMD</a> <a href="/tags/LIMO/" style="font-size: 11.33px;">LIMO</a> <a href="/tags/LIMR/" style="font-size: 10.67px;">LIMR</a> <a href="/tags/LLM/" style="font-size: 18.67px;">LLM</a> <a href="/tags/LLM-Colosseum/" style="font-size: 10px;">LLM-Colosseum</a> <a href="/tags/LM/" style="font-size: 12px;">LM</a> <a href="/tags/LOF/" style="font-size: 10px;">LOF</a> <a href="/tags/LR/" style="font-size: 10px;">LR</a> <a href="/tags/LSTM/" style="font-size: 10px;">LSTM</a> <a href="/tags/Labeling/" style="font-size: 10px;">Labeling</a> <a href="/tags/Language-Model/" style="font-size: 10.67px;">Language Model</a> <a href="/tags/Lexical-Semantics/" style="font-size: 10px;">Lexical Semantics</a> <a href="/tags/Lexicalism/" style="font-size: 10px;">Lexicalism</a> <a href="/tags/Lexicalized-CFG/" style="font-size: 10px;">Lexicalized CFG</a> <a href="/tags/Lexicalized-Grammars/" style="font-size: 10px;">Lexicalized Grammars</a> <a href="/tags/Life/" style="font-size: 13.33px;">Life</a> <a href="/tags/Linear-Algebra/" style="font-size: 10px;">Linear Algebra</a> <a href="/tags/Linear-Sturcture/" style="font-size: 10px;">Linear Sturcture</a> <a href="/tags/Linked-List/" style="font-size: 10px;">Linked List</a> <a href="/tags/LinkedList/" style="font-size: 10.67px;">LinkedList</a> <a href="/tags/Linux/" style="font-size: 10px;">Linux</a> <a href="/tags/Listen/" style="font-size: 10px;">Listen</a> <a href="/tags/Llama/" style="font-size: 10px;">Llama</a> <a href="/tags/Logistic-Regression/" style="font-size: 10px;">Logistic Regression</a> <a href="/tags/Lucene/" style="font-size: 10px;">Lucene</a> <a href="/tags/Luong-Attention/" style="font-size: 10px;">Luong Attention</a> <a href="/tags/MEMM/" style="font-size: 10px;">MEMM</a> <a href="/tags/MF/" style="font-size: 10px;">MF</a> <a href="/tags/MIO/" style="font-size: 10px;">MIO</a> <a href="/tags/MM-Fusion/" style="font-size: 10px;">MM Fusion</a> <a href="/tags/MTL/" style="font-size: 11.33px;">MTL</a> <a href="/tags/Machine/" style="font-size: 10px;">Machine</a> <a href="/tags/Machine-Learning/" style="font-size: 14px;">Machine Learning</a> <a href="/tags/Machine-Translation/" style="font-size: 10px;">Machine Translation</a> <a href="/tags/Manacher/" style="font-size: 10px;">Manacher</a> <a href="/tags/Managemnt/" style="font-size: 11.33px;">Managemnt</a> <a href="/tags/MarkBERT/" style="font-size: 10px;">MarkBERT</a> <a href="/tags/Markov/" style="font-size: 10px;">Markov</a> <a href="/tags/Materialized-Views/" style="font-size: 10px;">Materialized Views</a> <a href="/tags/Math/" style="font-size: 10.67px;">Math</a> <a href="/tags/Matplotlib/" style="font-size: 10px;">Matplotlib</a> <a href="/tags/Matrix-Factorization/" style="font-size: 10px;">Matrix Factorization</a> <a href="/tags/Median/" style="font-size: 10px;">Median</a> <a href="/tags/Meta-Learning/" style="font-size: 10px;">Meta Learning</a> <a href="/tags/Metric/" style="font-size: 10px;">Metric</a> <a href="/tags/Minimum-Edit-Distance/" style="font-size: 10px;">Minimum Edit Distance</a> <a href="/tags/Minkowski/" style="font-size: 10px;">Minkowski</a> <a href="/tags/MoE/" style="font-size: 10px;">MoE</a> <a href="/tags/Model-Evaluation/" style="font-size: 10px;">Model Evaluation</a> <a href="/tags/Module/" style="font-size: 10px;">Module</a> <a href="/tags/Monkey-Patch/" style="font-size: 10px;">Monkey Patch</a> <a href="/tags/Multi-Head-Attention/" style="font-size: 10px;">Multi-Head Attention</a> <a href="/tags/Multi-Modal/" style="font-size: 10px;">Multi-Modal</a> <a href="/tags/MultiModal/" style="font-size: 10px;">MultiModal</a> <a href="/tags/Multitask/" style="font-size: 10px;">Multitask</a> <a href="/tags/Multiway-Tree/" style="font-size: 10px;">Multiway Tree</a> <a href="/tags/NAT/" style="font-size: 10px;">NAT</a> <a href="/tags/NER/" style="font-size: 14px;">NER</a> <a href="/tags/NLG/" style="font-size: 11.33px;">NLG</a> <a href="/tags/NLM/" style="font-size: 10.67px;">NLM</a> <a href="/tags/NLP/" style="font-size: 19.33px;">NLP</a> <a href="/tags/NLU/" style="font-size: 10px;">NLU</a> <a href="/tags/NMT/" style="font-size: 10px;">NMT</a> <a href="/tags/NNW/" style="font-size: 11.33px;">NNW</a> <a href="/tags/NOVER/" style="font-size: 10px;">NOVER</a> <a href="/tags/NTP/" style="font-size: 10px;">NTP</a> <a href="/tags/Naive-Bayes/" style="font-size: 10px;">Naive Bayes</a> <a href="/tags/Neo4j/" style="font-size: 10px;">Neo4j</a> <a href="/tags/Network/" style="font-size: 10px;">Network</a> <a href="/tags/Ngram/" style="font-size: 10.67px;">Ngram</a> <a href="/tags/NodeJS/" style="font-size: 10px;">NodeJS</a> <a href="/tags/Normalizing-Flow/" style="font-size: 10px;">Normalizing Flow</a> <a href="/tags/NumPy/" style="font-size: 10.67px;">NumPy</a> <a href="/tags/Numba/" style="font-size: 10px;">Numba</a> <a href="/tags/Numpy/" style="font-size: 10px;">Numpy</a> <a href="/tags/OMNI/" style="font-size: 11.33px;">OMNI</a> <a href="/tags/ORZ/" style="font-size: 10px;">ORZ</a> <a href="/tags/Occupation/" style="font-size: 10px;">Occupation</a> <a href="/tags/One-Shot/" style="font-size: 10.67px;">One-Shot</a> <a href="/tags/Online-Learning/" style="font-size: 10px;">Online Learning</a> <a href="/tags/Online-DPO-R1/" style="font-size: 10.67px;">Online-DPO-R1</a> <a href="/tags/OpenAI/" style="font-size: 10px;">OpenAI</a> <a href="/tags/OpenSource/" style="font-size: 10px;">OpenSource</a> <a href="/tags/Orientation/" style="font-size: 10px;">Orientation</a> <a href="/tags/P-R/" style="font-size: 10px;">P-R</a> <a href="/tags/PCCG/" style="font-size: 10px;">PCCG</a> <a href="/tags/PCFG/" style="font-size: 10px;">PCFG</a> <a href="/tags/PEGASUS/" style="font-size: 10px;">PEGASUS</a> <a href="/tags/PLM/" style="font-size: 10.67px;">PLM</a> <a href="/tags/PPMI/" style="font-size: 10px;">PPMI</a> <a href="/tags/PPO/" style="font-size: 10px;">PPO</a> <a href="/tags/PTM/" style="font-size: 10px;">PTM</a> <a href="/tags/PageRank/" style="font-size: 10px;">PageRank</a> <a href="/tags/Palindromic/" style="font-size: 10px;">Palindromic</a> <a href="/tags/Pandarallel/" style="font-size: 10px;">Pandarallel</a> <a href="/tags/Pandas/" style="font-size: 10.67px;">Pandas</a> <a href="/tags/Partial-Parsing/" style="font-size: 10px;">Partial Parsing</a> <a href="/tags/Passion/" style="font-size: 10px;">Passion</a> <a href="/tags/Pearson/" style="font-size: 10px;">Pearson</a> <a href="/tags/Philosophy/" style="font-size: 10.67px;">Philosophy</a> <a href="/tags/Phrase-Structure-Grammar/" style="font-size: 10px;">Phrase Structure Grammar</a> <a href="/tags/Phrase-Structure-Grammars/" style="font-size: 10px;">Phrase Structure Grammars</a> <a href="/tags/PoS/" style="font-size: 10px;">PoS</a> <a href="/tags/Polars/" style="font-size: 10px;">Polars</a> <a href="/tags/Pooling/" style="font-size: 10px;">Pooling</a> <a href="/tags/Position-Encoding/" style="font-size: 10px;">Position-Encoding</a> <a href="/tags/Post-Training/" style="font-size: 10px;">Post-Training</a> <a href="/tags/Post-training/" style="font-size: 16px;">Post-training</a> <a href="/tags/Postgres/" style="font-size: 10.67px;">Postgres</a> <a href="/tags/Pragmatic-Automatic-Processing/" style="font-size: 10px;">Pragmatic Automatic Processing</a> <a href="/tags/Pre-Trained/" style="font-size: 10px;">Pre-Trained</a> <a href="/tags/Pre-Training/" style="font-size: 10px;">Pre-Training</a> <a href="/tags/Pre-training/" style="font-size: 14.67px;">Pre-training</a> <a href="/tags/Precision/" style="font-size: 10px;">Precision</a> <a href="/tags/Pretrain/" style="font-size: 10.67px;">Pretrain</a> <a href="/tags/Pretrained/" style="font-size: 10px;">Pretrained</a> <a href="/tags/Pretraining/" style="font-size: 10.67px;">Pretraining</a> <a href="/tags/Probabilistic-Grammar/" style="font-size: 10px;">Probabilistic Grammar</a> <a href="/tags/Probabilistic-Model/" style="font-size: 10px;">Probabilistic Model</a> <a href="/tags/Promote/" style="font-size: 10px;">Promote</a> <a href="/tags/Prompt/" style="font-size: 12.67px;">Prompt</a> <a href="/tags/ProtoBERT/" style="font-size: 10px;">ProtoBERT</a> <a href="/tags/Pruning/" style="font-size: 10px;">Pruning</a> <a href="/tags/Psychology/" style="font-size: 10.67px;">Psychology</a> <a href="/tags/PyPI/" style="font-size: 10px;">PyPI</a> <a href="/tags/Python/" style="font-size: 18px;">Python</a> <a href="/tags/QA/" style="font-size: 10px;">QA</a> <a href="/tags/Quant/" style="font-size: 10px;">Quant</a> <a href="/tags/Quantization/" style="font-size: 10px;">Quantization</a> <a href="/tags/Query/" style="font-size: 10px;">Query</a> <a href="/tags/Queue/" style="font-size: 10px;">Queue</a> <a href="/tags/Qwen3/" style="font-size: 10px;">Qwen3</a> <a href="/tags/Qwen3-Next/" style="font-size: 10.67px;">Qwen3-Next</a> <a href="/tags/R-Drop/" style="font-size: 10.67px;">R-Drop</a> <a href="/tags/R1/" style="font-size: 13.33px;">R1</a> <a href="/tags/R1-Zero/" style="font-size: 13.33px;">R1-Zero</a> <a href="/tags/RAG/" style="font-size: 10px;">RAG</a> <a href="/tags/RAVR/" style="font-size: 10px;">RAVR</a> <a href="/tags/REER/" style="font-size: 10px;">REER</a> <a href="/tags/RELU/" style="font-size: 10px;">RELU</a> <a href="/tags/RENT/" style="font-size: 10px;">RENT</a> <a href="/tags/RESTRAIN/" style="font-size: 10px;">RESTRAIN</a> <a href="/tags/RFE/" style="font-size: 10px;">RFE</a> <a href="/tags/RGR/" style="font-size: 10px;">RGR</a> <a href="/tags/RHO/" style="font-size: 10px;">RHO</a> <a href="/tags/RHO-1/" style="font-size: 10px;">RHO-1</a> <a href="/tags/RL/" style="font-size: 15.33px;">RL</a> <a href="/tags/RLHF/" style="font-size: 10px;">RLHF</a> <a href="/tags/RM/" style="font-size: 12px;">RM</a> <a href="/tags/RM-R1/" style="font-size: 10px;">RM-R1</a> <a href="/tags/RMSE/" style="font-size: 10px;">RMSE</a> <a href="/tags/RNN/" style="font-size: 10px;">RNN</a> <a href="/tags/ROC/" style="font-size: 10px;">ROC</a> <a href="/tags/RWD/" style="font-size: 10px;">RWD</a> <a href="/tags/Rank/" style="font-size: 10px;">Rank</a> <a href="/tags/RaspberryPi/" style="font-size: 10.67px;">RaspberryPi</a> <a href="/tags/Raspberrypi/" style="font-size: 10px;">Raspberrypi</a> <a href="/tags/Reasoning/" style="font-size: 10px;">Reasoning</a> <a href="/tags/Recall/" style="font-size: 10px;">Recall</a> <a href="/tags/Recommendation/" style="font-size: 12.67px;">Recommendation</a> <a href="/tags/Recursion/" style="font-size: 10.67px;">Recursion</a> <a href="/tags/Reformer/" style="font-size: 10px;">Reformer</a> <a href="/tags/Regex/" style="font-size: 10px;">Regex</a> <a href="/tags/Regular-Expression/" style="font-size: 10px;">Regular Expression</a> <a href="/tags/Reinforce/" style="font-size: 10px;">Reinforce++</a> <a href="/tags/Reinforcement-Learning/" style="font-size: 10px;">Reinforcement Learning</a> <a href="/tags/Relationship-Extraction/" style="font-size: 10px;">Relationship Extraction</a> <a href="/tags/Representation/" style="font-size: 10.67px;">Representation</a> <a href="/tags/Reqular-Expressions/" style="font-size: 10px;">Reqular Expressions</a> <a href="/tags/Retrieving/" style="font-size: 10px;">Retrieving</a> <a href="/tags/Reward/" style="font-size: 10.67px;">Reward</a> <a href="/tags/RoBERTa/" style="font-size: 10px;">RoBERTa</a> <a href="/tags/Rotated-Sorted-Array/" style="font-size: 10px;">Rotated Sorted Array</a> <a href="/tags/Rust/" style="font-size: 16px;">Rust</a> <a href="/tags/SCFG/" style="font-size: 10px;">SCFG</a> <a href="/tags/SGD/" style="font-size: 10px;">SGD</a> <a href="/tags/SLM/" style="font-size: 10.67px;">SLM</a> <a href="/tags/SMO/" style="font-size: 10px;">SMO</a> <a href="/tags/SQL/" style="font-size: 10.67px;">SQL</a> <a href="/tags/SRN/" style="font-size: 10px;">SRN</a> <a href="/tags/SRT/" style="font-size: 10px;">SRT</a> <a href="/tags/STaR/" style="font-size: 10px;">STaR</a> <a href="/tags/SVD/" style="font-size: 10px;">SVD++</a> <a href="/tags/SVM/" style="font-size: 10.67px;">SVM</a> <a href="/tags/Scaling/" style="font-size: 10px;">Scaling</a> <a href="/tags/Scaling-Law/" style="font-size: 10px;">Scaling Law</a> <a href="/tags/Seaborn/" style="font-size: 10px;">Seaborn</a> <a href="/tags/Search/" style="font-size: 10.67px;">Search</a> <a href="/tags/Seed-Thinking/" style="font-size: 10px;">Seed-Thinking</a> <a href="/tags/Segmentation/" style="font-size: 10px;">Segmentation</a> <a href="/tags/Selection-Inference/" style="font-size: 10px;">Selection-Inference</a> <a href="/tags/Self-Attention/" style="font-size: 11.33px;">Self-Attention</a> <a href="/tags/Self-Verified/" style="font-size: 10px;">Self-Verified</a> <a href="/tags/Semantic-Automatic-Processing/" style="font-size: 10px;">Semantic Automatic Processing</a> <a href="/tags/Semantic-Similarity/" style="font-size: 10px;">Semantic Similarity</a> <a href="/tags/Senta/" style="font-size: 10px;">Senta</a> <a href="/tags/Sentence-Representation/" style="font-size: 10px;">Sentence Representation</a> <a href="/tags/Sentence-Similarity/" style="font-size: 10px;">Sentence Similarity</a> <a href="/tags/Sentence-BERT/" style="font-size: 10px;">Sentence-BERT</a> <a href="/tags/Sentiment-Classification/" style="font-size: 10px;">Sentiment Classification</a> <a href="/tags/SentimentAnalysis/" style="font-size: 10px;">SentimentAnalysis</a> <a href="/tags/Sentry/" style="font-size: 10px;">Sentry</a> <a href="/tags/Siamese/" style="font-size: 10px;">Siamese</a> <a href="/tags/Sigmoid/" style="font-size: 10px;">Sigmoid</a> <a href="/tags/SimCSE/" style="font-size: 10.67px;">SimCSE</a> <a href="/tags/Similarity/" style="font-size: 10px;">Similarity</a> <a href="/tags/Simon/" style="font-size: 10px;">Simon</a> <a href="/tags/Simple-Zoo/" style="font-size: 10px;">Simple-Zoo</a> <a href="/tags/Simpson-Paradox/" style="font-size: 10px;">Simpson Paradox</a> <a href="/tags/Skill/" style="font-size: 10px;">Skill</a> <a href="/tags/Skywork-Reward/" style="font-size: 10px;">Skywork Reward</a> <a href="/tags/Slide/" style="font-size: 10px;">Slide</a> <a href="/tags/Smoothing/" style="font-size: 10.67px;">Smoothing</a> <a href="/tags/Soft-SVM/" style="font-size: 10px;">Soft-SVM</a> <a href="/tags/Softmax/" style="font-size: 10px;">Softmax</a> <a href="/tags/Sort/" style="font-size: 10.67px;">Sort</a> <a href="/tags/Span/" style="font-size: 11.33px;">Span</a> <a href="/tags/Sparse-Attention/" style="font-size: 10px;">Sparse Attention</a> <a href="/tags/Spell-Check/" style="font-size: 10px;">Spell Check</a> <a href="/tags/Spurious-Reward/" style="font-size: 10px;">Spurious Reward</a> <a href="/tags/SqueezeBERT/" style="font-size: 10px;">SqueezeBERT</a> <a href="/tags/Stable-LM/" style="font-size: 10px;">Stable LM</a> <a href="/tags/Stack/" style="font-size: 10px;">Stack</a> <a href="/tags/Stacking/" style="font-size: 10px;">Stacking</a> <a href="/tags/Statistics/" style="font-size: 10px;">Statistics</a> <a href="/tags/Stirling/" style="font-size: 10px;">Stirling</a> <a href="/tags/Strategic/" style="font-size: 10px;">Strategic</a> <a href="/tags/StratifiedKFold/" style="font-size: 10px;">StratifiedKFold</a> <a href="/tags/String/" style="font-size: 10.67px;">String</a> <a href="/tags/Study/" style="font-size: 10.67px;">Study</a> <a href="/tags/Style/" style="font-size: 10px;">Style</a> <a href="/tags/Substring/" style="font-size: 10px;">Substring</a> <a href="/tags/Summarization/" style="font-size: 10.67px;">Summarization</a> <a href="/tags/Supertagging/" style="font-size: 10px;">Supertagging</a> <a href="/tags/Swap/" style="font-size: 10px;">Swap</a> <a href="/tags/System/" style="font-size: 10.67px;">System</a> <a href="/tags/T5/" style="font-size: 10.67px;">T5</a> <a href="/tags/TF-IDF/" style="font-size: 10px;">TF-IDF</a> <a href="/tags/THW/" style="font-size: 11.33px;">THW</a> <a href="/tags/TS3-Codec/" style="font-size: 10px;">TS3-Codec</a> <a href="/tags/TTRL/" style="font-size: 10.67px;">TTRL</a> <a href="/tags/TTS/" style="font-size: 14px;">TTS</a> <a href="/tags/Tagging/" style="font-size: 10px;">Tagging</a> <a href="/tags/TanH/" style="font-size: 10px;">TanH</a> <a href="/tags/TensorBay/" style="font-size: 10px;">TensorBay</a> <a href="/tags/Tensorflow/" style="font-size: 10px;">Tensorflow</a> <a href="/tags/Test/" style="font-size: 10px;">Test</a> <a href="/tags/Text-Classification/" style="font-size: 10px;">Text Classification</a> <a href="/tags/Text-Generation/" style="font-size: 10px;">Text Generation</a> <a href="/tags/Text-Normalization/" style="font-size: 10px;">Text Normalization</a> <a href="/tags/TextCNN/" style="font-size: 10.67px;">TextCNN</a> <a href="/tags/TextRank/" style="font-size: 10px;">TextRank</a> <a href="/tags/Thought/" style="font-size: 10.67px;">Thought</a> <a href="/tags/Tokenizer/" style="font-size: 10px;">Tokenizer</a> <a href="/tags/Transformer/" style="font-size: 17.33px;">Transformer</a> <a href="/tags/Transformer-XL/" style="font-size: 10px;">Transformer-XL</a> <a href="/tags/Tree/" style="font-size: 10px;">Tree</a> <a href="/tags/Treebank/" style="font-size: 10px;">Treebank</a> <a href="/tags/Tuning/" style="font-size: 10px;">Tuning</a> <a href="/tags/Tutorial/" style="font-size: 10px;">Tutorial</a> <a href="/tags/Ubuntu/" style="font-size: 10px;">Ubuntu</a> <a href="/tags/UniLM/" style="font-size: 10px;">UniLM</a> <a href="/tags/Unity-Operation/" style="font-size: 10px;">Unity Operation</a> <a href="/tags/Unix/" style="font-size: 10px;">Unix</a> <a href="/tags/Unsupervised-Elicitation/" style="font-size: 10px;">Unsupervised Elicitation</a> <a href="/tags/UserCF/" style="font-size: 10px;">UserCF</a> <a href="/tags/VAPO/" style="font-size: 10px;">VAPO</a> <a href="/tags/VITS/" style="font-size: 10px;">VITS</a> <a href="/tags/Vagrant/" style="font-size: 10px;">Vagrant</a> <a href="/tags/Valence/" style="font-size: 10px;">Valence</a> <a href="/tags/Vector-Semantics/" style="font-size: 10px;">Vector Semantics</a> <a href="/tags/Verifier/" style="font-size: 10px;">Verifier</a> <a href="/tags/Virtual-Network/" style="font-size: 10px;">Virtual Network</a> <a href="/tags/VirtualBox/" style="font-size: 10px;">VirtualBox</a> <a href="/tags/Visualization/" style="font-size: 10px;">Visualization</a> <a href="/tags/Viterbi/" style="font-size: 10.67px;">Viterbi</a> <a href="/tags/Vocabulary-Learning/" style="font-size: 10px;">Vocabulary Learning</a> <a href="/tags/VoiceAgent/" style="font-size: 10px;">VoiceAgent</a> <a href="/tags/Voila/" style="font-size: 10px;">Voila</a> <a href="/tags/Voting/" style="font-size: 10px;">Voting</a> <a href="/tags/W2NER/" style="font-size: 11.33px;">W2NER</a> <a href="/tags/WOE/" style="font-size: 10px;">WOE</a> <a href="/tags/Web-Server-Multithreaded-Server/" style="font-size: 10px;">Web Server Multithreaded Server</a> <a href="/tags/Wide/" style="font-size: 10px;">Wide</a> <a href="/tags/Word2vec/" style="font-size: 10px;">Word2vec</a> <a href="/tags/Work/" style="font-size: 10px;">Work</a> <a href="/tags/World-Model/" style="font-size: 10px;">World Model</a> <a href="/tags/XLNet/" style="font-size: 10px;">XLNet</a> <a href="/tags/XTTS/" style="font-size: 10px;">XTTS</a> <a href="/tags/Z-Score/" style="font-size: 10px;">Z-Score</a> <a href="/tags/Zero-Short/" style="font-size: 10px;">Zero-Short</a> <a href="/tags/Zero-Shot/" style="font-size: 11.33px;">Zero-Shot</a> <a href="/tags/Zero-shot/" style="font-size: 10px;">Zero-shot</a> <a href="/tags/ZhouZhihua/" style="font-size: 10px;">ZhouZhihua</a> <a href="/tags/Zipf/" style="font-size: 10px;">Zipf</a> <a href="/tags/Ziya/" style="font-size: 10.67px;">Ziya</a> <a href="/tags/antigravity/" style="font-size: 10px;">antigravity</a> <a href="/tags/attention-sink/" style="font-size: 10.67px;">attention sink</a> <a href="/tags/bias/" style="font-size: 10px;">bias</a> <a href="/tags/binning/" style="font-size: 10px;">binning</a> <a href="/tags/emacs/" style="font-size: 10px;">emacs</a> <a href="/tags/few-shot/" style="font-size: 10px;">few-shot</a> <a href="/tags/ffmpeg/" style="font-size: 10px;">ffmpeg</a> <a href="/tags/gated-attention/" style="font-size: 10px;">gated attention</a> <a href="/tags/gpt-oss/" style="font-size: 10px;">gpt-oss</a> <a href="/tags/harmony-format/" style="font-size: 10px;">harmony format</a> <a href="/tags/jpype/" style="font-size: 10px;">jpype</a> <a href="/tags/knowledge-Graph/" style="font-size: 10px;">knowledge Graph</a> <a href="/tags/lightinfer/" style="font-size: 10px;">lightinfer</a> <a href="/tags/motion/" style="font-size: 10px;">motion</a> <a href="/tags/node2vec/" style="font-size: 10px;">node2vec</a> <a href="/tags/oat-zero/" style="font-size: 10.67px;">oat-zero</a> <a href="/tags/off-by-one-attention/" style="font-size: 10px;">off-by-one attention</a> <a href="/tags/orz/" style="font-size: 10px;">orz</a> <a href="/tags/pararun/" style="font-size: 10px;">pararun</a> <a href="/tags/promptlog/" style="font-size: 10px;">promptlog</a> <a href="/tags/s1/" style="font-size: 11.33px;">s1</a> <a href="/tags/ssh/" style="font-size: 10px;">ssh</a> <a href="/tags/str/" style="font-size: 10px;">str</a> <a href="/tags/trae/" style="font-size: 10px;">trae</a> <a href="/tags/vim/" style="font-size: 10px;">vim</a> <a href="/tags/vlc/" style="font-size: 10px;">vlc</a>
    </div>
  </aside>

  
</div>
      </div>
      <footer id="colophon" role="contentinfo">
    <p>&copy; 2026 hscspring
    All rights reserved.</p>
    <p>Powered by <a href="https://hexo.io/" target="_blank">Hexo</a></p>
    
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <!-- <span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_site_pv"></span>次</span> -->
    <!-- <span id="busuanzi_container_page_pv">本文总阅读量<span id="busuanzi_value_page_pv"></span>次</span> -->
    <!-- <span id="busuanzi_container_site_uv">本站访客数<span id="busuanzi_value_site_uv"></span>人次</span> -->

</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

<script src="/js/navigation.js"></script>

<div id="bg"></div>

  </div><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>