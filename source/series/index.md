---
title: 各主题系列
date: 2019-07-13 20:00:00
---

> 说明：读书笔记（类型为 Feeling）并非原创，内容和图均来自原作，仅用于学习交流。

<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->
**Table of Contents**  *generated with [DocToc](https://github.com/thlorenz/doctoc)*

- [个人成长Growth](#%E4%B8%AA%E4%BA%BA%E6%88%90%E9%95%BFgrowth)
- [人工智能AI](#%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BDai)
  - [思考](#%E6%80%9D%E8%80%83)
  - [哲学](#%E5%93%B2%E5%AD%A6)
- [LLM系列](#llm%E7%B3%BB%E5%88%97)
  - [Reward](#reward)
  - [R1/RL相关](#r1rl%E7%9B%B8%E5%85%B3)
  - [ChatGPT/LLM](#chatgptllm)
  - [LLM预训练](#llm%E9%A2%84%E8%AE%AD%E7%BB%83)
  - [LLM继续训练](#llm%E7%BB%A7%E7%BB%AD%E8%AE%AD%E7%BB%83)
  - [LLM数据处理相关](#llm%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E7%9B%B8%E5%85%B3)
  - [LLM指令跟随](#llm%E6%8C%87%E4%BB%A4%E8%B7%9F%E9%9A%8F)
- [LMM系列](#lmm%E7%B3%BB%E5%88%97)
  - [VoiceAgent](#voiceagent)
  - [LMM论文速览](#lmm%E8%AE%BA%E6%96%87%E9%80%9F%E8%A7%88)
  - [LMM论文笔记](#lmm%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0)
- [NLP系列](#nlp%E7%B3%BB%E5%88%97)
  - [基础](#%E5%9F%BA%E7%A1%80)
  - [思考](#%E6%80%9D%E8%80%83-1)
  - [语言](#%E8%AF%AD%E8%A8%80)
  - [设计](#%E8%AE%BE%E8%AE%A1)
  - [图谱](#%E5%9B%BE%E8%B0%B1)
  - [NLP论文笔记](#nlp%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0)
  - [SLP](#slp)
  - [冯志伟《自然语言计算机形式分析的理论与方法》](#%E5%86%AF%E5%BF%97%E4%BC%9F%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%BD%A2%E5%BC%8F%E5%88%86%E6%9E%90%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E6%96%B9%E6%B3%95)
- [推荐广告Recommendation](#%E6%8E%A8%E8%8D%90%E5%B9%BF%E5%91%8Arecommendation)
- [深度学习DeepLearning](#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0deeplearning)
- [机器学习MachineLearning](#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0machinelearning)
- [数据科学DataScience](#%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6datascience)
- [数学Math](#%E6%95%B0%E5%AD%A6math)
- [系统Unix](#%E7%B3%BB%E7%BB%9Funix)
- [网络Net](#%E7%BD%91%E7%BB%9Cnet)
- [树莓派Raspberrypi](#%E6%A0%91%E8%8E%93%E6%B4%BEraspberrypi)
- [编程Coding](#%E7%BC%96%E7%A8%8Bcoding)
  - [基础环境](#%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83)
  - [Rust与AI](#rust%E4%B8%8Eai)
  - [Rust](#rust)
  - [Python](#python)
  - [Python 小白快速入门教程](#python-%E5%B0%8F%E7%99%BD%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B)
  - [C 语言课程笔记](#c-%E8%AF%AD%E8%A8%80%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0)
  - [服务基础](#%E6%9C%8D%E5%8A%A1%E5%9F%BA%E7%A1%80)
- [算法Algorithm](#%E7%AE%97%E6%B3%95algorithm)
  - [LeetCode](#leetcode)
  - [剑指 Offer2（Python 版）解析](#%E5%89%91%E6%8C%87-offer2python-%E7%89%88%E8%A7%A3%E6%9E%90)
  - [数据结构与算法](#%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95)
- [经金商管EFBM](#%E7%BB%8F%E9%87%91%E5%95%86%E7%AE%A1efbm)
- [认知心理CogPsy](#%E8%AE%A4%E7%9F%A5%E5%BF%83%E7%90%86cogpsy)
- [育儿](#%E8%82%B2%E5%84%BF)
- [杂文随笔Essay](#%E6%9D%82%E6%96%87%E9%9A%8F%E7%AC%94essay)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->


## 个人成长Growth

- [AI 工程师养成记（上）](https://yam.gift/2021/02/19/ExpSum/2021-02-19-AI-Engineer-Growing-I/)
- [一些关于工作的观点（From《华为工作法》）](https://yam.gift/2019/06/08/ExpSum/2019-06-08-Concept-and-View-of-Work/)


## 人工智能AI

### 思考

- [分类与 AI](https://yam.gift/2020/11/28/AI/2020-11-28-Classification-and-AI/)
- [语言、AI、情感](https://yam.gift/2017/09/07/NLP/2017-09-07-Language-AI-Emotion/)
- [NLP 与 AI](https://yam.gift/2018/07/22/NLP/2018-07-22-NLP-and-AI/)
- [关于AI前沿的思考 | Yam](https://yam.gift/2024/12/20/NLP/2024-12-20-Think-About-AI-and-Related/)

### 哲学

- [西蒙《人工科学》读书笔记](https://yam.gift/2018/09/30/AI/2018-09-30-The-Science-of-Artificial/)
- [人工智能哲学笔记](https://yam.gift/2018/04/07/AI/2018-04-07-AI-Philosophy-Note/)
- [《与机器人共舞》读后感兼谈 AI 与 IA](https://yam.gift/2016/03/31/AI/2016-03-31-Machines-of-Loving-Grace/)

## LLM系列

### Reward

- [解锁模型潜能：Reward 数据如何塑造与激发 LLM 的推理策略 | Yam](https://yam.gift/2025/07/13/NLP/LLM-Training/2025-07-13-RM-Data/)
- [Reward Model建模 | Yam](https://yam.gift/2025/06/09/NLP/LLM-Training/2025-06-09-RM-Modeling/)

### R1/RL相关

- [GRPO“又一背锅侠”：Clip的各种拉扯 | Yam](https://yam.gift/2025/09/12/NLP/LLM-Training/2025-09-12-GRPO-Clip/)
- [GRPO“第一背锅侠”Token Level X2：GTPO双“T”傍地走 | Yam](https://yam.gift/2025/08/30/NLP/LLM-Training/2025-08-30-GTPO/)
- [GRPO“第一背锅侠”Token Level X：DAPO/DrGRPO与GSPO/GMPO的殊途同归 | Yam](https://yam.gift/2025/08/14/NLP/LLM-Training/2025-08-14-Token-Level-GSPO-GMPO/)
- [GiGPO：双层级优势函数驱动的Agent强化学习新范式 | Yam](https://yam.gift/2025/07/25/NLP/LLM-Training/2025-07-25-GiGPO/)
- [GRPO优化在继续——CISPO和熵 | Yam](https://yam.gift/2025/06/19/NLP/LLM-Training/2025-06-19-CISPO-and-Entropy/)
- [R1后范式最佳实践：Seed-Thinking和Qwen3 | Yam](https://yam.gift/2025/05/01/NLP/LLM-Training/xx/)
- [Yarz-Logic：R1-Zero相关实验报告 | Yam](https://yam.gift/2025/04/26/NLP/LLM-Training/2025-04-26-R1-Zero-Lab-Yarz-Logic/)
- [R1相关：R1-Zero的进一步理解和探索 | Yam](https://yam.gift/2025/04/10/NLP/LLM-Training/2025-04-10-Think-More-about-R1-Zero/)
- [VAPO：基于价值方法的新突破 | Yam](https://yam.gift/2025/04/19/NLP/LLM-Training/2025-04-19-VAPO/)
- [异曲同工之妙的DrGRPO——DAPO几乎同时出现的又一GRPO优化！ | Yam](https://yam.gift/2025/03/28/NLP/LLM-Training/2025-03-28-LLM-PostTrain-DrGRPO/)
- [DAPO：为GRPO的锦上加四点花 | Yam](https://yam.gift/2025/03/19/NLP/LLM-Training/2025-03-19-LLM-PostTrain-DAPO/)
- [DeepSeek R1后应用、职业与行业影响——2025年梳理 | Yam](https://yam.gift/2025/03/15/AI/2025-03-15-LLM-App-Develop/)
- [DeepSeek R1后LLM新范式 | Yam](https://yam.gift/2025/03/15/NLP/LLM-Training/2025-03-15-R1-New-Paradigm/)
- [DeepSeek R1：新范式、新纪元 | Yam](https://yam.gift/2025/02/17/NLP/LLM-Training/2025-02-17-DeepSeek-R1/)
- [R1相关：少量高质量数据SFT激活LLM推理能力 | Yam](https://yam.gift/2025/02/18/NLP/LLM-Training/2025-02-18-LLM-PostTrain-SFT-Data/)
- [R1相关：RL数据选择与Scaling | Yam](https://yam.gift/2025/02/27/NLP/LLM-Training/2025-02-27-LLM-PostTrain-PPO-Data/)
- [R1相关：DPO数据选择与DPO等RL算法 | Yam](https://yam.gift/2025/03/02/NLP/LLM-Training/2025-03-02-LLM-PostTrain-DPO-Data/)
- [LLM、强化、蒸馏讨论 | Yam](https://yam.gift/2025/02/27/AI/2025-02-27-AI-Discussion/)

### ChatGPT/LLM

- [群聊中的AGI拼图：GPT-5发布后关于全模态、推理、世界模型与实时学习的思考 | Yam](https://yam.gift/2025/08/11/AI/2025-08-11-AI-Develop/)
- [关于gpt-oss那些值得关注的点 | Yam](https://yam.gift/2025/08/06/NLP/2025-08-06-gpt-oss/)
- [重识LLM法则：上下文工程与数据进化 | Yam](https://yam.gift/2025/07/27/NLP/LLM-Context/2025-07-27-Context-Engineering-and-Data/)
- [LLM极简科普](https://yam.gift/2024/03/16/AI/2024-03-16-LLM-Basic/)
- [LLM打街霸](https://yam.gift/2024/04/08/NLP/2024-04-08-LLM-Colosseum/)
- [ChatGPT 基础科普：知其一点所以然](https://yam.gift/2023/04/15/NLP/2023-04-15-ChatGPT-Introduction/)
- [ChatGPT Prompt工程：设计、实践与思考](https://yam.gift/2023/01/25/NLP/2023-01-25-ChatGPT-Prompt-Engineering/)
- [ChatGPT Prompt 示例](https://yam.gift/2023/01/31/NLP/2023-01-31-ChatGPT-Prompt-Example/)
- [ChatGPT 标注指南：任务、数据与规范](https://yam.gift/2023/02/19/NLP/2023-02-19-ChatGPT-Labeling/)
- [ChatGPT 开发指南：Hugging LLM Hugging Future](https://yam.gift/2023/04/22/NLP/2023-04-22-ChatGPT-Development/)
- [关于大语言模型的思考](https://yam.gift/2023/10/15/NLP/2023-10-15-Think-About-LLM/)
- [OpenAIGC 大赛小结](https://yam.gift/2023/11/04/AI/2023-11-04-OpenAIGC/)
- [ChatGPT 影响冲击：职业、行业与产业](https://yam.gift/2023/02/21/NLP/2023-02-21-ChatGPT-Impact/)

### LLM预训练

- [预训练：无处安放的躁动之心 | Yam](https://yam.gift/2025/01/05/NLP/LLM-Training/2025-01-05-LLM-Pretrain-PreStart/)
- [预训练：NTP和Scaling Law | Yam](https://yam.gift/2025/02/28/NLP/LLM-Training/2025-02-28-LLM-Pretrain-NTP-and-ScaleLaw/)

### LLM继续训练

- [Tiny LLM Continual Pre-training：RHO-1 | Yam](https://yam.gift/2024/04/13/NLP/LLM-Training/2024-04-13-LLM-Tiny-Continual-Training-RHO-1/)
- [LLM Tiny Pretrain：H2O-Danube and Stable LM | Yam](https://yam.gift/2024/02/03/NLP/LLM-Training/2024-02-03-LLM-Tiny-Pretrain/)
- [LLM Continual Pre-training：Ziya2 | Yam](https://yam.gift/2024/01/23/NLP/LLM-Training/2024-01-23-LLM-Continual-Training-Ziya2/)

### LLM数据处理相关

- [LLM DataManagement：Weaver | Yam](https://yam.gift/2024/02/01/NLP/LLM-DM/2024-02-01-LLM-DataManagement-Weaver/)
- [LLM DataManagement：Ziya2 | Yam](https://yam.gift/2024/01/29/NLP/LLM-DM/2024-01-29-LLM-DataManagement-Ziya2/)

### LLM指令跟随

- [激活诱导LLM指令跟随 | Yam](https://yam.gift/2025/07/01/NLP/LLM-IF/2025-07-01-Activation-Steering/)
- [指令跟随近期工作梳理（2025年上半年） | Yam](https://yam.gift/2025/06/26/NLP/LLM-IF/2025-06-26-Instruction-Following/)
- [LLM指令跟随论文速览](https://yam.gift/2024/12/31/Paper/LLM/2024-12-31-Instruction-Following-Papers/)

## LMM系列

### VoiceAgent

- [从Voila看语音端到端发展 | Yam](https://yam.gift/2025/05/14/MM/2025-05-14-Voila-and-OMNI/)
- [实时语音交互场景下RAG的机遇和挑战 | Yam](https://yam.gift/2025/01/05/MM/2025-01-05-RAG-and-Voice-Agent/)

### LMM论文速览

- [OMNI论文速览（2025） | Yam](https://yam.gift/2025/03/08/Paper/MM/2025-03-08-OMNI-Papers-2025/)
- [OMNI论文速览（2024） | Yam](https://yam.gift/2024/12/31/Paper/MM/2024-12-31-OMNI-Papers-2024/)
- [SLM论文速览](https://yam.gift/2024/12/31/Paper/MM/2024-12-31-SLM-Papers/)
- [音频Codec论文速览](https://yam.gift/2024/12/31/Paper/TTS/2024-12-31-Codec-Papers/)

### LMM论文笔记

- [2024 MIO](https://yam.gift/2024/09/28/Paper/2024-09-28-MIO/)
- [2024 BigCodec](https://yam.gift/2024/12/26/Paper/TTS/2024-12-26-BigCodec/)
- [2024 TS3-Codec](https://yam.gift/2024/12/27/Paper/TTS/2024-12-27-TS3-Codec/)
- [2023 DAC](https://yam.gift/2024/12/30/Paper/TTS/2024-12-30-DAC/)
- [2023 XTTS](https://yam.gift/2024/12/31/Paper/TTS/2024-12-31-XTTS/)
- [2021 VITS](https://yam.gift/2024/12/31/Paper/TTS/2024-12-31-VITS/)

## NLP系列

### 基础

- [自然语言处理（NLP）知识地图](https://yam.gift/2017/04/09/NLP/2017-04-09-NLPKnowledgeTree/)
- [hscspring/All4NLP: All For NLP, especially Chinese.](https://github.com/hscspring/All4NLP)
- [中文分词系列一：思考分词](https://yam.gift/2020/05/13/NLP/2020-05-13-Segmentation-Thinking/)
- [正则表达式笔记](https://yam.gift/2017/09/04/NLP/2017-09-04-Regular-Expression/)
- [《Elasticsearch 权威指南》之基础入门 Note（基于 7.x）](https://yam.gift/2019/07/09/NLP/2019-07-09-Elasticsearch-Basic/)
- [浅析文本分类 —— 情感分析与自然语言处理](https://yam.gift/2021/10/27/NLP/2021-10-27-Senta/)
- [TensorBay 指南](https://yam.gift/2021/09/21/NLP/2021-09-21-TensorBay-Intro/)

### 思考

- [对NLP预训练模型的思考](https://yam.gift/2021/06/10/NLP/2021-06-10-Pretrain-Thinking/)
- [NLP 表征的历史与未来](https://yam.gift/2020/12/12/NLP/2020-12-12-NLP-Representation-History-Future/)
- [句子表征综述](https://yam.gift/2022/03/27/NLP/2022-03-27-Sentence-Representation-Summarization/)

### 语言

- [《纳博科夫最喜欢的词》读书笔记与思考](https://yam.gift/2019/03/31/NLP/2019-03-31-Nabokov-Favorite-Word/)

### 设计

- [2018CCF-GAIR：自然语言如何商业落地摘录及思考](https://yam.gift/2018/07/12/NLP/2018-07-12-NLP-Business-and-System/)
- [ChatBot 设计方案](https://yam.gift/2019/07/20/NLP/2019-07-20-ChatBot-Design/)

### 图谱

- [关系提取简述](https://yam.gift/2019/12/11/NLP/KG/2019-12-11-Relationship-Extraction/)
- [自然语言记忆模块（NLM）](https://yam.gift/2019/12/02/NLP/KG/2019-12-02-NLM/)

### NLP论文笔记

- [2024 LLM中的演绎推理、归纳推理和溯因推理](https://yam.gift/2024/04/06/Paper/2024-04-06-Deductive-Inductive-Abductive/)
- [2022 LM Cascades](https://yam.gift/2023/01/27/Paper/2023-01-27-Language-Model-Cascades/)
- [2022 Put Human in NLP Loop](https://yam.gift/2023/01/21/Paper/2023-01-21-Human-in-Loop/)
- [2022 DeepGen](https://yam.gift/2022/10/15/Paper/2022-10-15-DeepGen/)
- [2022 Global Pointer](https://yam.gift/2022/10/16/Paper/2022-10-16-GlobalPointer/)
- [2022 大脑解码与NLP](https://yam.gift/2022/07/02/Paper/2022-07-02-Cross-view-Brain-Decoding/)
- [2022 MarkBERT](https://yam.gift/2022/04/23/Paper/2022-04-23-MarkBERT/)
- [2022 深度vsBM25排序](https://yam.gift/2022/04/23/Paper/2022-04-23-Pretrained-for-Rank/)
- [2022 Impossible Triangle](https://yam.gift/2022/04/15/Paper/2022-04-15-Impossible-Triangle/)
- [2022 NLM Memorization](https://yam.gift/2022/04/15/Paper/2022-04-15-Quantifying-Memorization-NLM/)
- [2022 REINA](https://yam.gift/2022/04/05/Paper/2022-04-05-Retrieving-From-Training-Data/)
- [2022 FLAN](https://yam.gift/2022/08/28/Paper/2022-08-28-FLAN/)
- [2021 W2NER](https://yam.gift/2022/06/11/Paper/2022-06-11-W2NER/)
- [2021 W2NER 代码](https://yam.gift/2022/07/17/Paper/2022-07-17-W2NER-Code/)
- [2021 W2NER 解读](https://yam.gift/2022/10/30/Paper/2022-10-30-W2NER-Study/)
- [2021 ExT5](https://yam.gift/2022/02/19/Paper/2022-02-19-ExT5/)
- [2021 多任务Prompt元学习](https://yam.gift/2021/12/25/Paper/2021-12-25-MLT-Promote/)
- [2021 Prompt综述](https://yam.gift/2021/12/04/Paper/2021-12-04-Prompt/)
- [2021 数据增强综述](https://yam.gift/2021/11/28/Paper/2021-11-28-DataAugmentation/)
- [2021 去偏技术综述](https://yam.gift/2021/11/18/Paper/2021-11-18-Debiasing/)
- [2021 在上下文中学习如何学习：MetaICL](https://yam.gift/2021/11/01/Paper/2021-11-01-MetaICL/)
- [2021 通过最优转移进行词表学习：VOLT](https://yam.gift/2021/07/18/Paper/2021-07-18-VOLT/)
- [2021 SimCSE 和 R-Drop 在 TextCNN 上的实验](https://yam.gift/2021/08/31/AI/2021-08-31-SL-CL-Dropout/)
- [2021 R-Drop](https://yam.gift/2021/08/18/Paper/2021-08-18-R-Drop/)
- [2021 简单的对比学习框架：SimCSE](https://yam.gift/2021/07/10/Paper/2021-07-10-SimCSE/)
- [2021 高效深度学习：让模型更小、更快、更好](https://yam.gift/2021/07/04/Paper/2021-07-04-Efficient-DeepLearning/)
- [2021 预训练模型的过去、现在和未来](https://yam.gift/2021/06/20/Paper/2021-06-20-PretrainedModels/)
- [2021 Few-Shot NER and BERT Noisy Learning：ProtoBERT](https://yam.gift/2021/06/06/Paper/2021-06-06-ProtoBERT/)
- [2020 GPT3 和它的 In-Context Learning](https://yam.gift/2023/01/20/NLP/2023-01-20-GPT3/)
- [2020 T5](https://yam.gift/2022/03/05/Paper/2022-03-05-T5/)
- [2020 SqueezeBERT](https://yam.gift/2021/01/17/Paper/2021-01-17-SqueezeBERT/)
- [2020 深度探索 Bert：BERTology](https://yam.gift/2021/05/22/Paper/2021-05-22-BERTology/)
- [2020 Bert-Flow](https://yam.gift/2020/12/13/Paper/2020-12-13-Bert-Flow/)
- [2020 Funnel Transformer](https://yam.gift/2020/10/13/Paper/2020-10-13-FunnelTransformer/)
- [2020 PEGASUS](https://yam.gift/2020/09/13/Paper/2020-09-13-PEGASUS/)
- [2020 DeBERTa](https://yam.gift/2020/06/27/Paper/2020-06-27-DeBERTa/)
- [2020 Reformer](https://yam.gift/2020/02/15/Paper/2020-02-15-Reformer-Paper/)
- [2019 T5](https://yam.gift/2022/03/05/Paper/2022-03-05-T5/)
- [2019 UniLM](https://yam.gift/2021/07/31/Paper/2021-07-31-UniLM/)
- [2019 Sentence-Bert](https://yam.gift/2020/12/27/Paper/2020-12-27-Sentence-Bert/)
- [2019 Bart](https://yam.gift/2020/06/13/Paper/2020-06-13-Bart/)
- [2019 DistilBERT](https://yam.gift/2020/04/27/Paper/2020-04-27-DistilBERT/)
- [2019 ALBERT](https://yam.gift/2020/05/10/Paper/2020-05-10-ALBERT/)
- [2019 GPT2](https://yam.gift/2020/04/07/Paper/2020-04-07-GPT2/)
- [2019 ELECTRA](https://yam.gift/2019/12/08/Paper/2019-12-08-ELECTRA-Paper/)
- [2019 CTRL](https://yam.gift/2019/09/28/Paper/2019-09-28-CTRL/)
- [2019 RoBERTa](https://yam.gift/2020/06/25/Paper/2020-06-25-RoBERTa/)
- [2019 ERNIE](https://yam.gift/2019/08/02/Paper/2019-08-02-Baidu-ERNIE-Tutorial/)
- [2019 XLNet](https://yam.gift/2019/07/14/Paper/2019-07-14-XLNet-Paper/)
- [2019 Bert](https://yam.gift/2019/08/05/Paper/2019-08-05-Bert-Paper/)
- [2018 Attributes External Feature](https://yam.gift/2019/12/15/Paper/2019-12-15-Label-Attributes-Representation-Paper/)
- [2017 Transformer Code](https://yam.gift/2020/04/23/Paper/2020-04-23-Transformer/)
- [2017 Transformer Paper](https://yam.gift/2019/08/04/Paper/2019-08-04-Transformer-Paper/)
- [2016 Node2Vec](https://yam.gift/2020/03/30/Paper/2020-03-30-Node2Vec/)
- [2016 NER with Bi-LSTM and CRF](https://yam.gift/2019/12/28/Paper/2019-12-28-Bi-LSTM-CRF-NER-Paper/)
- [2015 Bahdanau Attention](https://yam.gift/2020/02/08/Paper/2020-02-08-Bahdanau-Attention-Paper/)
- [2015 Luong Attention](https://yam.gift/2020/04/14/Paper/2020-04-14-Luong-Attention/)
- [2004 TextRank Keyword Extraction](https://yam.gift/2020/03/21/Paper/2020-03-21-Text-Rank/)

### [SLP](https://web.stanford.edu/~jurafsky/slp3/)

- [Regular Expressions, Text Normalization, and Edit Distance Note (SLP Ch02)](https://yam.gift/2019/04/22/NLP/SLP/2019-04-22-Ch02-RegularExpressions-TextNormalization-EditDistance/)
- [Language Model Note (SLP Ch03)](https://yam.gift/2017/10/14/NLP/SLP/2017-10-14-Ch03-Language-Model/)
- [Naive Bayes and Sentiment Classification Note (SLP Ch04)](https://yam.gift/2019/05/05/NLP/SLP/2019-05-05-Ch04-NaiveBayes-and-Sentiment-Classification/)
- [Logistic Regression Note (SLP Ch05)](https://yam.gift/2019/05/08/NLP/SLP/2019-05-08-Ch05-Logistic-Regression/)
- [Vector Semantics Note (SLP Ch06)](https://yam.gift/2019/05/16/NLP/SLP/2019-05-16-Ch06-Vector-Semantics/)
- [Neural Networks and Neural Language Models Note (SLP Ch07)](https://yam.gift/2019/05/31/NLP/SLP/2019-05-31-Ch07-Neural-Networks-and-Neural-Language-Models/)
- [Part-of-Speech Tagging Note (SLP Ch08)](https://yam.gift/2019/06/11/NLP/SLP/2019-06-11-Ch08-Part-of-Speech-Tagging/)
- [Sequence Processing with Recurrent Networks Note (SLP Ch09)](https://yam.gift/2019/06/17/NLP/SLP/2019-06-17-Ch09-Senquence-Processing-with-Recurrent-Networks/)
- [Encoder-Decoder Models Attention and Contextual Embedding Note (SLP Ch10)](https://yam.gift/2020/01/23/NLP/SLP/2020-01-23-Ch10-Encoder-Decoder-Models-Attention-and-Contextual-Embeddings/)
- [Formal Grammars of English Note (SLP Ch12)](https://yam.gift/2019/06/21/NLP/SLP/2019-06-21-Ch12-Formal-Grammars-of-English/)
- [Syntactic Parsing Note (SLP Ch13)](https://yam.gift/2019/07/08/NLP/SLP/2019-07-08-Ch13-Syntactic-Parsing/)
- [Statistical Parsing Note (SLP Ch14)](https://yam.gift/2019/07/17/NLP/SLP/2019-07-17-Ch14-Statistical-Parsing/)
- [Information Extraction Note (SLP Ch18)](https://yam.gift/2019/04/09/NLP/SLP/2019-04-09-Ch18-Information-Extraction/)

### 冯志伟《自然语言计算机形式分析的理论与方法》

- [第一章：自然语言处理的学科定位](https://yam.gift/2018/09/19/NLP/NLPFA/2018-09-19-Ch01-Orientation-of-NLP/)
- [第二章：自然语言研究的先驱](https://yam.gift/2018/10/11/NLP/NLPFA/2018-10-11-Ch02-Pioneers-in-Language-Computing/)
- [第三章：基于短语结构语法的形式模型](https://yam.gift/2018/12/22/NLP/NLPFA/2018-12-22-Ch03-Formal-Model-Based-on-Phrase-Structure-Grammar/)
- [第四章：基于合一运算的形式模型](https://yam.gift/2019/01/09/NLP/NLPFA/2019-01-09-Ch04-Formal-Model-Based-on-Unity-Operation/)
- [第五章：基于依存和配价的形式模型](https://yam.gift/2019/01/15/NLP/NLPFA/2019-01-15-Ch05-Formal-Model-Based-on-Dependence-and-Valence/)
- [第六章：基于格语法的形式模型](https://yam.gift/2019/01/18/NLP/NLPFA/2019-01-18-Ch06-Formal-Model-Based-on-Grid-Grammar/)
- [第七章：基于词汇主义的形式模型](https://yam.gift/2019/01/31/NLP/NLPFA/2019-01-31-Ch07-Formal-Model-Based-on-Lexicalism/)
- [第八章：语义自动处理的形式模型](https://yam.gift/2019/02/15/NLP/NLPFA/2019-02-15-Ch08-Formal-Model-of-Semantic-Automatic-Processing/)
- [第九章：系统功能语法](https://yam.gift/2019/02/21/NLP/NLPFA/2019-02-21-Ch09-System-Function-Syntax/)
- [第十章：语用自动处理的形式模型](https://yam.gift/2019/02/27/NLP/NLPFA/2019-02-27-Ch10-Formal-Model-of-Pragmatic-Automatic-Processing/)
- [第十一章：概率语法](https://yam.gift/2019/03/01/NLP/NLPFA/2019-03-01-Ch11-Probabilistic-Grammar/)
- [第十二章：Bayes 公式与动态规划算法](https://yam.gift/2019/03/11/NLP/NLPFA/2019-03-11-Ch12-Bayes-and-Dynamic-Programming/)
- [第十三章：N 元语法和数据平滑](https://yam.gift/2019/03/15/NLP/NLPFA/2019-03-15-Ch13-Ngram-and-Smoothing/)
- [第十四章：隐 Markov 模型](https://yam.gift/2019/03/22/NLP/NLPFA/2019-03-22-Ch14-HMM/)
- [第十五章：语音自动处理的形式模型](https://yam.gift/2019/03/29/NLP/NLPFA/2019-03-29-Ch15-Formal-Model-of-Automatic-Speech-Processing/)
- [自然语言计算机形式分析的理论与方法笔记(Ch16) | Yam](https://yam.gift/2019/04/04/NLP/NLPFA/2019-04-04-Ch16-Formal-Model-in-Statistical-Machine-Translation/)
- [第十七章：自然语言处理系统评测](https://yam.gift/2019/04/08/NLP/NLPFA/2019-04-08-Ch17-NLP-System-Evaluation/)
- [第十八章：自然语言处理中的理性主义与经验主义](https://yam.gift/2019/04/08/NLP/NLPFA/2019-04-08-Ch18-Rationalism-and-Empiricism-in-NLP/)


## 推荐广告Recommendation

- [推荐系统概述](https://yam.gift/2020/10/19/RecSys/2020-10-19-RecIntroduction/)
- [协同过滤](https://yam.gift/2020/10/22/RecSys/2020-10-22-CollaborativeFiltering/)
- [矩阵分解](https://yam.gift/2020/10/24/RecSys/2020-10-24-MF/)
- [Wide & Deep](https://yam.gift/2020/10/27/Paper/2020-10-27-WideDeepLearning4RecSys/)
- [GBTD + LR](https://yam.gift/2020/10/30/Paper/2020-10-30-GBTD-LR/)


## 深度学习DeepLearning

- [“心有麟熙”《强化学习炼金术》系列笔记 | Yam](https://yam.gift/2018/05/07/AI/2018-05-07-RL-Series/)
- [Gan 原理、证明与实现 | Yam](https://yam.gift/2018/03/26/AI/2018-03-26-Gan-Series/)
- [NG CNN 笔记 | Yam](https://yam.gift/2018/08/14/AI/2018-08-14-Ng-CNN/)
- [AI 小课堂：Activation Function | Yam](https://yam.gift/2020/07/05/AI/2020-07-05-BK-Activation/)


## 机器学习MachineLearning

- [机器学习概念](https://yam.gift/2018/04/22/ML/2018-04-22-ML-Concept/)
- [Metrics](https://yam.gift/2020/09/15/ML/2020-09-15-Metrics/)
- [EDA](https://yam.gift/2020/09/18/ML/2020-09-18-EDA/)
- [特征工程](https://yam.gift/2020/09/21/ML/2020-09-21-FeatureEngineering/)
- [建模调参](https://yam.gift/2020/09/24/ML/2020-09-24-ModelParameters/)
- [模型融合](https://yam.gift/2020/09/26/ML/2020-09-26-ModelFusing/)
- [Hard-SVM, Soft-SVM 和 KKT](https://yam.gift/2020/08/13/ML/2020-08-13-SVM-Hard-Soft-KKT/)
- [核方法 和 SMO](https://yam.gift/2020/09/09/ML/2020-09-09-Kernel-SMO/)


## 数据科学DataScience

- [高性能数据处理 | Yam](https://yam.gift/2021/08/12/DataSci/2021-08-12-Dataprocess-Performance/)
- [List, Dict, Array, Series, DataFrame 相互转换](https://yam.gift/2017/02/15/DataSci/2017-02-15-list-dict-series-dataframe-ndarray-transform/)
- [Numpy 入门](https://yam.gift/2016/09/19/DataSci/2016-09-19-NumPy/)
- [Pandas 入门](https://yam.gift/2017/03/05/DataSci/2017-03-05-Pandas/)
- [绘制文本分类数据](https://yam.gift/2018/12/15/DataSci/2018-12-15-Text-Classification-Data-Plot/)
- [QA 小课堂：Introduction | Yam](https://yam.gift/2020/07/05/AIQA/2020-07-05-Introduction/)


## 数学Math

- [辛普森悖论及其哲学思考 | Yam](https://yam.gift/2016/09/03/Math/2016-09-03-Simpson-Paradox/)
- [信息熵与选择：由三门问题想到的 | Yam](https://yam.gift/2019/06/19/Math/2019-06-19-Think-From-Three-Gates/)
- [线性代数的本质笔记 | Yam](https://yam.gift/2018/05/13/Math/2018-05-13-Essence-of-Linear-Algebra/)
- [微积分的本质笔记 | Yam](https://yam.gift/2018/05/12/Math/2018-05-12-Essence-of-Calculus/)


## 系统Unix

- [Ubuntu16.04 安装 VirtualBox & Vagrant 管理 VirtualBox 各种问题总结 | Yam](https://yam.gift/2016/09/04/Unix/2016-09-04-Ubuntu-VirtualBox-Vagrant-questions/)
- [AINLP GPU 使用体验指南 | Yam](https://yam.gift/2019/12/09/Unix/2019-12-09-AINLP-GPU-Guide/)
- [Unix Cheat Sheet | Yam](https://yam.gift/2021/07/02/Unix/2021-07-02-Unix-Cheat-Sheet/)
- [Docker Memo | Yam](https://yam.gift/2021/08/05/Unix/2021-08-05-Docker/)
- [Git Memo | Yam](https://yam.gift/2021/08/12/Unix/2021-08-15-Git/)


## 网络Net

- [虚拟网络指南 | Yam](https://yam.gift/2021/12/19/Net/2021-12-19-VirtualNetwork/)


## 树莓派Raspberrypi

- [机器之脑：树莓派初使用 | Yam](https://yam.gift/2021/07/01/Raspberrypi/2021-07-01-RaspberryPi-Init/)
- [机器之眼：树莓派摄像头 | Yam](https://yam.gift/2021/07/03/Raspberrypi/2021-07-03-RaspberryPi-Camera/)


## 编程Coding

### 基础环境

- [hscspring/ALL4AI: AI Related Tools/Projects](https://github.com/hscspring/ALL4AI)
- [Programming Language Environment Cheat Sheet | Yam](https://yam.gift/2024/03/06/Unix/2024-03-06-LanguageEnvCheatSheet/)

### Rust与AI

- [【Rust与AI】概览和方向 | Yam](https://yam.gift/2023/12/03/Rust/RustAI/2023-12-03-Rust-and-AI-Introduction/)
- [【Rust与AI】LLM模型基本架构 | Yam](https://yam.gift/2023/12/24/Rust/RustAI/2023-12-24-Rust-and-AI-LLM/)
  
### Rust

- [Rust str 转 String](https://yam.gift/2021/06/06/Rust/2021-06-06-str2String/)
- [Rust Tutorial](https://yam.gift/2019/12/21/Rust/2019-12-21-Rust-Tutorial/)
- [Rust by Example Brief Note | Yam](https://yam.gift/2020/02/02/Rust/RPL/2020-02-02-Rust-by-Example-Brief-Note/)

### Python

- [记一次诡异的 FD 泄露：躲在暗处的猴子补丁 | Yam](https://yam.gift/2025/09/21/Python/2025-09-21-FD-Leak/)
- [Python 编码笔记整理 | Yam](https://yam.gift/2017/03/05/Python/2017-03-05-Python-encode-decode/)
- [Jupyter Notebook Cheat Sheet | Yam](https://yam.gift/2021/06/07/Python/2021-06-07-JupyterCheatSheet/)
- [Python 调用 Java](https://yam.gift/2021/06/14/Python/2021-06-14-Python-Call-Java/)
- [Python Ellipsis | Yam](https://yam.gift/2021/11/13/Python/2021-11-13-Ellipsis/)

### Python 小白快速入门教程

- [Ch00：在开始前](https://yam.gift/2019/04/10/Python/Py4F/2019-04-10-Python-for-Freshman-Ch00/)
- [Ch01：基础知识](https://yam.gift/2019/10/02/Python/Py4F/2019-10-02-Python-for-Freshman-Ch01/)
- [Ch02：使用模块](https://yam.gift/2019/10/03/Python/Py4F/2019-10-03-Python-for-Freshman-Ch02/)
- [Ch03：使用框架](https://yam.gift/2019/10/10/Python/Py4F/2019-10-10-Python-for-Freshman-Ch03/)
- [Ch04：阅读源码](https://yam.gift/2019/10/06/Python/Py4F/2019-10-06-Python-for-Freshman-Ch04/)
- [Ch05：在结束后](https://yam.gift/2019/10/07/Python/Py4F/2019-10-07-Python-for-Freshman-Ch05/)

### C 语言课程笔记

- [浙大翁恺老师《程序设计入门 ——C 语言》笔记](https://yam.gift/2018/06/20/C/2018-06-20-C-Weng-ZhejiangUniversity/)
- [浙大翁恺老师《C 语言程序设计进阶》笔记](https://yam.gift/2018/07/31/C/2018-07-31-C-Advance-Weng-ZhejiangUniversity/)

### 服务基础

- [GraphQL Glance](https://yam.gift/2019/08/24/GraphQL/2019-08-24-GraphQL/)
- [GraphQL Elixir Glance](https://yam.gift/2019/08/24/GraphQL/2019-08-24-GraphQL-Elixir/)
- [常用 DataBase 相关操作和资源](https://yam.gift/2019/06/15/DB/2019-06-15-Common-DB-Related/)
- [DataBase Foreign Data Wrapper](https://yam.gift/2019/04/21/DB/2019-04-21-DB-FDW/)


## 算法Algorithm

### LeetCode

- [Longest Substring Without Repeating Characters (LeetCode 3)](https://yam.gift/2019/07/13/DSA/LeetCode/2019-07-13-Longest-Substring-Without-Repeating-Characters/)
- [Median of Two Sorted Arrays (LeetCode 4)](https://yam.gift/2019/07/18/DSA/LeetCode/2019-07-15-Median-of-Two-Sorted-Arrays/)
- [Longest Palindromic Substring (LeetCode 5)](https://yam.gift/2019/08/03/DSA/LeetCode/2019-08-03-Longest-Palindromic-Substring/)
- [Generate Parentheses (LeetCode 22) | Yam](https://yam.gift/2020/08/12/DSA/LeetCode/2020-08-12-Generate-Parentheses/)
- [Swap Nodes in Paris (LeetCode 24)](https://yam.gift/2020/08/20/DSA/LeetCode/2020-08-20-Swap-Nodes-in-Paris/)
- [Search in Rotated Sorted Array (LeetCode 33, 81, 153)](https://yam.gift/2020/08/22/DSA/LeetCode/2020-08-22-Search-in-Rotated-Sorted-Array/)
- [Find First and Last Position of Element in Sorted Array (LeetCode 34)](https://yam.gift/2020/08/31/DSA/LeetCode/2020-08-31-Find-First-and-Last-Position-of-Element-in-Sorted-Array/)


### 剑指 Offer2（Python 版）解析

- [剑指 Offer2（Python 版）解析（Ch2）](https://yam.gift/2019/12/15/DSA/Coding-Review2/2019-12-15-CR2-Ch2/)
- [剑指 Offer2（Python 版）解析（Ch3）](https://yam.gift/2019/12/15/DSA/Coding-Review2/2019-12-15-CR2-Ch3/)
- [剑指 Offer2（Python 版）解析（Ch4） ](https://yam.gift/2019/12/15/DSA/Coding-Review2/2019-12-15-CR2-Ch4/)
- [剑指 Offer2（Python 版）解析（Ch5）](https://yam.gift/2019/12/15/DSA/Coding-Review2/2019-12-15-CR2-Ch5/)
- [剑指 Offer2（Python 版）解析（Ch6）](https://yam.gift/2019/12/15/DSA/Coding-Review2/2019-12-15-CR2-Ch6/)


### 数据结构与算法

- [数据结构与算法：前言](https://yam.gift/2018/12/01/DSA/Think-Ds-Algo/2018-12-01-Ch00-Preface/)
- [数据结构与算法：导论](https://yam.gift/2018/12/21/DSA/Think-Ds-Algo/2018-12-21-Ch01-Introduction/)
- [数据结构与算法：思考排序](https://yam.gift/2018/12/31/DSA/Think-Ds-Algo/2018-12-31-Ch02-Thinking-Sort/)
- [数据结构与算法：线性结构](https://yam.gift/2019/07/13/DSA/Think-Ds-Algo/2019-07-13-Ch03-Linear-Structure/)
- [Sort Based on Multiway Tree](https://yam.gift/2019/11/03/DSA/2019-11-03-Multiway-Tree-Sort/)


## 经金商管EFBM

- [由一场供应链讲座引发的思考](https://yam.gift/2017/12/23/Economy/2017-12-23-Thinking-From-a-Supply-Chain-Lecture/)
- [《基业长青》读书笔记](https://yam.gift/2015/11/30/Economy/2015-11-28-Built-to-Last/)
- [《管人的真理》读书笔记](https://yam.gift/2015/12/01/Economy/2015-12-01-Management-Truth/)
- [《海底捞你学不会》读书笔记](https://yam.gift/2015/11/30/Economy/2015-11-30-HaiDiLao/)


## 认知心理CogPsy

- [多贝里《清醒思考的艺术》读书笔记](https://yam.gift/2020/04/28/CogPsy/2020-04-28-The-Art-of-Clearly-Thinking/)
- [《自私的基因》读书笔记](https://yam.gift/2016/02/27/CogPsy/2016-02-17-Selfish-Gene/)
- [麦肯锡战略化思维》读书笔记](https://yam.gift/2022/10/23/CogPsy/2022-10-23-Structured-Strategic-Thought/)


## 育儿

- [《真希望父母读过这本书》读书笔记 | Yam](https://yam.gift/2024/09/30/BabyGrow/2024-09-30-Hope-Parents-Read-the-Book/)


## 杂文随笔Essay

- [60小时备考高架擦边过经验 | Yam](https://yam.gift/2025/06/26/Diary/2025-06-26-60hours-Pass-Arch-Exam/)
- [我为什么做开源？ | Yam](https://yam.gift/2025/01/12/Diary/2025-01-12-Why-OpenSource/)
- [随笔：人生，当有所为有所不为 | Yam](https://yam.gift/2017/08/31/Diary/2017-08-31-diary/)
- [随笔：命运 | Yam](https://yam.gift/2019/07/15/Diary/2019-07-15-diary/)
- [《舞狮少年》观后 —— 信念、文化与希望 | Yam](https://yam.gift/2021/12/26/Diary/2021-12-25-Lion-Dance/)
- [只如初见的不只爱情 | Yam](https://yam.gift/2022/09/11/Diary/2022-09-11-Passion/)
- [人生随笔 | Yam](https://yam.gift/2023/01/21/Diary/2023-01-21-Life/)
- [基础和取舍 | Yam](https://yam.gift/2024/09/30/Diary/2024-09-30-Work-Design/)
