---
title: 分类与 AI
date: 2020-11-28 23:00:00
categories: Thinking
tags: [AI, Classification]
mathjax: false
---

分类作为机器学习或深度学习的基础任务之一，相信任何一位算法工程师都能说得头头是道。不过，能深入思考其背后涉及到的认知过程和机理的就凤毛麟角了。本文涉及到的思考部分从我 2017 年一开始接触人工智能与 NLP 就开始萌芽了，这源于我的切入点与正常人不同。由于个人经历关系，我一开始是从认知科学这个角度开始自己的工程师生涯的，刚开始看的论文也更加偏向于思考如何构建真正的人工智能。比如，Few-Shot 或 One-Shot Learning、因果推理、快速思考、学习如何学习，甚至开始思考语言学以及究竟什么是智能。很自然地也熟知了图灵、冯诺依曼、维特根斯坦。直至现在依然对这些理论相当沉迷，这也是我当初下定决心从事 AI 领域的原因。虽然目前从事 NLP 研发工作，但我对自己的定位一直都是 AI 工程师，AI 不应该被割裂，他从来都是个整体，作为成年人，我们自然是都要。

<!--more-->

## 分类是本能

言归正传，说回我们的主题——分类。乍一看这个问题好像很简单，分类不就是对给定样本根据特征不同做划分吗。从表面来看这么说当然没问题，但让我们再往深多想一点点，为什么是分类？或者说，为什么要做分类？要回答这个问题我们得先了解分类到底在干什么。不妨先看个小例子，就拿 Ng 那个猫咪识别器吧。先想人是怎么区分猫和其他动物的，大多数情况下，即便是小孩子，只要给他们看少数几张（甚至一张）照片，他们就知道 “猫咪” 长啥样子了。他们不需要学习大量照片，也不需要常识（所以先不要说预训练）。这说明人类在做分类时，不仅仅是在做分类，他们还从特征中构建出了更加抽象的 “概念”，也可以理解为 “知识”。这正是人类 “学习” 的过程。正是由于人类的 “好奇心” 让我们想去 “学习”，而在人类刚刚出现时并没有现成的 “知识体系”，所以很自然地要从观察到的不同个体中去学习。面对未知个体，很自然地我们就会尝试将其纳入我们已有的知识体系，这时候自然而然地就开始做分类了。综上所述，“分类” 根本上是人类自然进化来的 “学习” 方法，也是我们认识和了解这个世界的基本方法。

换个角度来看，将未知的个体快速归到已知的类别这也是最节省脑力的方法，这也可以解释为什么我们倾向于贴标签，想象一下这样的描述：“他狮子座，A 型血，乐观，有幽默感”，是不是很有画面感？但其实仔细思考一下，其实这些描述并没有太多意义，每个人都有乐观和幽默的一面，星座血型更加不能说明什么。但这就是很符合我们的认知习惯，有助于我们快速在大脑中 “刻画” 出一个人形象的人来。而且，人类倾向于觉得 “即便有个错误的认知也比完全一抹黑” 要好。我可以举个例子，假设公司某个项目出问题了，老板吩咐你和你的另一个同事（我们叫他小林）赶紧去解决，假设你是那种谋定而后动型，喜欢先花很多时间思考；而小林正好和你相反，马上开始跑这跑那，一会儿打电话，一会儿找人沟通。现在，假设过了两个小时候，项目问题突然消失了（也就是说，实际可能并不是公司这边的问题），你觉得老板会觉得你和小林谁的表现更好些？这就是人类认知上的问题，我们倾向于觉得遇到问题时总应该做点什么，也就是说，即使你做的事情毫无意义甚至还浪费了大家的时间和精力，但大多数人就是会认为比什么都不做好。先别着急失望悲观，我们退一步看，其实人类本身就有很强的自我纠正能力，并不怕错；而且错误的认知并非没有意义，它至少让我们知道了那样是不对的。虽然小林的认知是错误的（并不知道原因就开始行动），但他的行为无疑给大家极大的 “安慰”，而且并没有损失不是。你还别说，“安慰” 某种程度上就像信仰一样，我们可不能轻易说它没用。综上，星座血型有人信不足为奇，喜欢贴标签更加正常，毕竟又不损失什么。

## 知识是力量

现在，我们应该对分类有了一个比较深入的了解。接下来讨论人类通过 “分类” 学习到 “知识” 的过程。说这个之前，我先介绍个关于学习和认知的模型：DIKW 模型，D 表示 Data（数据）、I 表示 Information（信息）、K 表示 Knowledge（知识）、W 表示 Wisdom（智慧）。四个层次一个比一个抽象，我们现在的 AI 基本还停留在 Data 到 Information 的阶段，未来很重要的就是 “知识” 这一步。至于 “智慧”，只要活得足够久（拥有足够多的知识）自然有可能会产生智慧，现在谈论为时尚早。提到 “知识”，顺带讨论一下其实很早之前就有但现在突然很火的知识图谱，这玩意儿现在看来更像是个 “常识图谱”，Ontology 勉强能算，但这方面的研究又不多。不过这可以理解，毕竟具体的东西更容易做，科研需要一步一步实践。言归正传，我们还是从人类学习到 “知识” 的过程开始，并假定是婴幼儿。继续拿猫咪识别器举例子，当婴儿在看到一张猫的图片后，大脑会在瞬间完成特征提取工作。这里有两个需要注意的：第一，这些特征应该并不是从零开始得到的，而是基于婴儿脑中已有的 “知识”（也许是 “特征”），比如猫的一张脸，上面有两只眼睛、一个鼻子等，这些可能从婴儿脑中已有的动物或者人的面孔而来。第二，特征是整体的，婴儿可能并不会特别关注鼻子或眼睛长得怎样，他们首先用的是宏观轮廓特征，当两个图片很相像时，才会去关注具体的细节。在这个过程中，“知识” 是什么？在哪里？怎么存储的？需要时怎么使用的？发现错误时怎么更新的？

从之前的分析我们已经知道 “知识” 就是信息的抽象，也可以理解为特征的抽象。我觉得这里和因子分析法有点类似，它最终得到的不同因子的组合有点类似 “知识” 的概念，而且往往需要人肉去给个抽象的描述。当然，知识又不仅仅只是简单的特征抽象，它首先就一定是综合的、可以跨领域通用的。比如，我们上面提到的 “脸” 这个知识，其实更宏观点应该是 “一张脸+四条腿” 这个抽象的知识，我们也许不知道（可能也不需要要知道）这个知识具体叫什么（但我们可以给它起个名字），但我们知道 “鱼” 不是它，“人” 也不是它，但比 “鱼” 像。其次，它应该既可以从具体的样本学习而来，也可以从已有的 “知识体系” 学习而来，而且还应该具备根据具体样本或知识体系更新已有体系能力。往简单方向思考，我觉得可以先将知识看作是某种模式，具体而言就是一个模板或框架。模式会优先执行，搞不定时，具体特征再进一步处理。对于未知样本，我们同样首先提取模式处理。各种各样的模式之间可能并不需要继续分层次，模式的分层只需到能应付具体的场景即可。比如做猫咪识别，就到 “一张脸+四条腿” 这个层次，即便是有其他非动物的识别，也只是很多个不同的平行模式。接下来需要探讨如何获得这些模式，理想状态下，按照人类的标准，我们可以从任何单个样本中提取到模式，并强化或更新已有的 “模式体系”。从可操作的角度看，模式可以看作是宏观层面的分类模型，而具体的个体则可以看作是微观层面的分类模型。这提醒我们在构建系统时，可以尝试采用分层的思想，不同层负责不同的职能。层内可以互相关联成网，也就是说，图谱的构建不仅要在具体的实体和关系之间进行，也应该在抽象的模式和模式关系之间进行。

## 智慧是生命

“智慧” 是更加抽象的概念，我们首先需要尽可能地将它具体化——具备什么样的特征才能算具有 “智慧”？我们这里应该排除掉 “情绪” 或 “情感” 方面的感受，比如沉着、冷静等，这些特质可以看作是人类特有的，它们的功能可以看作是辅助 “大脑” 这台仪器产生 “智慧” 的工具。智慧的第一个特征应该是 “全面”，即面对问题会考虑多个因素（模式），类似芒格所提倡的跨学科多模型思维；第二个特征应该是 “长远”，即除了考虑当下也会充分考虑未来的各种可能性，也就是要有一定的前瞻性；第三个特征应该是 “深入”，即能够尽可能直达本质，也就是能将具体问题抽象到本质，再从抽象出发提出具体的针对性的方法。通过上面的分析，我们应当可以大胆预测，当一个人拥有足够多的知识时，他就有可能产生 “智慧”；那么同样，当一个机器拥有足够多的知识时，他也有可能产生 “智慧”。

如果一个机器产生了 “智慧” 或者足够 “智慧” 以至于我们无法将他与人区分，我们是否可以认为他是一个新的生命体、新的物种？当然，我们这里说的生命或物种是指至少和人类相当的 “生命体”。需要说明的是，我们所说的无法区分除了 “智能” 角度外，也包括 “情绪” 角度，我们可以假定机器足以 “智慧” 到虽然他们不懂 “情绪” 但能理解它。这就类似我们不懂狗狗说话，但我们能够理解他们表达的意思。如果到了这个阶段，人类又将如何自处？该以何种身份、何种形式存在？也许，人类会进化到 “肉体消亡、灵魂永存”，彼时的人类还能被称为 “人类” 吗？

> 后记：本来想整理一篇关于深度学习文本分类的笔记的，没想到一写开就成这样了。那篇完全应用层面的整理笔记只能另行择文了。需要特别说明的是，本文只是个人的一些思考，仅代表个人观点，不保证正确（什么是正确……）。作为一名算法工程师，想这些可能对工作并没有什么帮助；但作为一个真正热爱 AI 的人来说，有这样的思考我觉得很正常（后面也列了之前写过的类似的思考），我也非常喜欢并经常进行类似这样或更深层次的思考。另外，虽然很清楚一图胜千言，但对思考类文章，个人比较喜欢使用纯文字对观点进行论证，这可能和喜欢哲学有关，但自知功力尚浅，难免会有不严谨之处。如果你能读到这里，我自不胜感激；如果你能就其中某些观点和我讨论，我会异常欣喜；如果你能提出一些改进建议，我们日后也许可以尝试更多更深入的探讨交流。

相关论文代表：

- [Human-level concept learning through probabilistic program induction | Science](https://science.sciencemag.org/content/350/6266/1332)
- [[1604.00289] Building Machines That Learn and Think Like People](https://arxiv.org/abs/1604.00289)

以及以前写过的一些思考：

- [语言、AI、情感 | Yam](https://yam.gift/2017/09/07/2017-09-07-Language-AI-Emotion/)
- [NLP 与人工智能 | Yam](https://yam.gift/2018/07/22/2018-07-22-NLP-and-AI/)

还有关于人工智能哲学的课堂笔记：

- [人工智能哲学笔记 | Yam](https://yam.gift/2018/04/07/2018-04-07-AI-Philosophy-Note/)

