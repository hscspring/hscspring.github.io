---
title: 信息熵与选择：由三门问题想到的
date: 2019-06-19 22:20:00
categories: Thinking
tags: [Entropy, Information Theory]
---

今天看公众号文章正好看到一篇[《三门问题》](https://mp.weixin.qq.com/s/AvSBzyS2Xbbso8SGT172qQ)，虽然看似简单，但细想感觉很有意思，特意把自己的思考记录一下。三门问题出自上世纪 70 年代美国的一个综艺节目，基本描述是这样的：你是游戏的参与者，面前有三扇门，其中一扇门后面是一辆跑车，其他两扇后面什么都没有。在你选择一扇门后先不打开，主持人打开了另一扇门（后面必然是空的），此时你有两个选择，坚持选择刚才选的那扇，或者换另外一扇还没打开的。怎么选择才能让你得到跑车的概率最大？

<!--more-->

乍一看这个问题好像很简单，无论换不换好像概率一样的呀，事实当然不是如此啦，否则也不会有那篇公众号的文章和这篇文章了。公众号的文章中用基本的概率计算来解释说明，过程如下：

主持人开门之前：

- 选择有跑车的门：1/3
- 选择空门 A：1/3
- 选择空门 B：1/3

主持人开门之后：

- 选择有跑车的门：
    - 换门：0
    - 不换门：1
- 选择空门 A（此时 B 已经打开并确认是空门）：
    - 换门：1
    - 不换门：0
- 选择空门 B（此时 A 已经打开并确认是空门）：
    - 换门：1
    - 不换门：0

整理一下可得：

- 换门的得奖概率：1/3 × 0 + 1/3 × 1 + 1/3 × 1 = 2/3
- 不换门的得奖概率：1/3 × 1 + 1/3 × 0 + 1/3 × 0 = 1/3

结果看起来是没什么问题，但我们的思维可能还是觉得有点奇怪，感觉不直观、难以理解，我觉得这是因为上面这种分析过程只是到了表层，并没有深入背后的本质，所以让我们感到有些困惑。本文接下来就尝试从理解本质的角度去分析这个问题。为了分析方便，我假设有四个门（道理是一样的，因为三门剩下的那个就是有奖品的，可能会引起一些理解上的误会和偏差），其他条件不变，也就是在主持人打开门后，你要坚持选择第一次的还是在剩余的两扇门中选择一扇。

在分析具体问题之前，我们需要先了解 “信息熵” 的概念，它来源于[热力学第二定律]([https://zh.wikipedia.org/wiki/%E7%83%AD%E5%8A%9B%E5%AD%A6%E7%AC%AC%E4%BA%8C%E5%AE%9A%E5%BE%8B](https://zh.wikipedia.org/wiki/热力学第二定律))：孤立系统自发地朝着热力学平衡方向──最大熵状态──演化，它描述的是一个系统的混乱（稳定）程度，一个系统处于稳定时就是其熵值最大的时候。香农将此概念引入信息论，用它来度量信息量的大小。熵值越大，不确定性越大，此时可能获得的信息量最大。提到熵就不得不提另一个重要的概念：自信息，这里不列公式了。总之自信息满足三个条件（非常符合我们的直觉）：条件一，非常可能发生的事件信息量要少；条件二，较不可能发生的事件具有更高的信息量；条件三，独立事件应具有增量的信息。而熵也就是自信息的期望：当事件等概率时，熵就等于自信息（因为概率相等，所以整个的不确定性也就等于单个的不确定性），当事件概率不相等时，熵降低（不确定性降低了，因为有的结果概率高了，可能性大了）。这里就是反直觉和令人迷惑的地方。举个例子容易理解些，比如有个地方天气变化非常反复无常，简单起见假设有 “晴天、雨天” 两种，每天两种天气出现的概率分别是 50%，这时候天气预报的作用就非常大，也就是带给你的信息量非常大；相反如果一个地方几乎天天是晴天，我们假设晴天、雨天的概率分别是 99% 和 1%，那这时候天气预报带给你的信息量非常小（简直无关紧要啊）。对于前一种情况，不确定性大，熵值大（事实上由于是均匀分布，不确定性和熵值均为最大），此时可预测性很小，额外获得的信息（在这里是天气预报）的信息量就很大；后一种情况正好相反。也就是说，在面临不确定性时，我们应该利用已知的信息（有些东西已经是确定的）让选择等可能性（不确定性最大）。这就是熵的思维。

> 关于其在排序算法中的应用可以阅读刘未鹏大神的精彩文章：[数学之美番外篇：快排为什么那样快 – 刘未鹏 | Mind Hacks](http://mindhacks.cn/2008/06/13/why-is-quicksort-so-quick/) 和拙作：[数据结构与算法浅思：思考排序 | Yam](https://yam.gift/2018/12/31/DS/2018-12-31-Ch02-Thinking-Sort/)。

我觉得反直觉的地方就在这里，我们总是有一种直觉，就是确定的东西信息量比较大，不确定的好像没啥信息。出现这个问题的原因我理解是把 “信息” 和  “知识” 这两个概念（自然而然地）混淆了，我们一般说一个东西信息量很大，总感觉这个东西内容很多、很有用；但其实却正好相反，我们真正有用的（知识或模型）都是信息量小、稳定的、可预测性大的，事实上智能的本质就是减熵，也就是降低不确定性。如果举一些具体的例子，机器学习的目的也是减少熵，希望自己的预测比较确定，熵正好可以用来衡量这个置信度；贝叶斯学习中，我们经常假设一个先验分布具有较宽广的概率密度函数，这反映了随机变量在观测之前的不确定性，当数据来了以后，熵会减小，并且让后验分布在最可能的参数值周围形成峰值。所以，也许应该把信息量叫作 “混乱度” 比较好。这里还有个好玩儿的是 “小概率事件”，因为发生的概率小，所以该事件本身（不是整个系统）具有很高的信息量，熵值很大（熵是自信息的期望，事件本身来说发生的概率为 1）。也就是这类事件因为发生概率比较低所以熵也比较低，虽然它本身的熵比较高，但是一旦这类事件正好（发生概率达到 100%）发生了，它具有的高熵和高信息量对整个系统带来的影响往往非常严重。这也就是所谓的 “黑天鹅” 事件。

现在让我们用上面的思维来重新思考三门问题（我以四门为例）。当主持人打开一扇空门后，我们的第二次选择应该怎么选，是继续坚持第一次的选择，还是换一扇门？回想一下熵的思维：让选择等可能性。如果我们继续坚持第一次的选择，那意味着我们给第一次的那个选择更高的概率；而等可能性意味着我们第二次应该在剩下的两扇门中等可能性地选择一扇。注意，这里其实我们有两次 “等可能性”。所以，三门问题之所以在第二次应该换门，其背后的本质思想就在这里。而这个问题之所以具有迷惑性和反直觉，我觉得原因可能有以下两点：

- 第一，两次的选择是一个整体事件，不应该被孤立看待，极端点我们甚至可以假设没有主持人打开那道门，那你想要自己在两次选择中选中的概率最大，第二次肯定不会选择和第一次一样的那扇门，所以这里主持人打开那扇门并不是本质，它只是提高了你的概率。所以，这其实是一个 “两次选择” 的概率问题。
- 第二，我们在分析问题的时候不由自主地站在了上帝视角。这个稍微有点难理解，直观地说就是我们在选择时总是把概率当作了真实，而事实上只有在确定的那一刻才是真实。换个意思就是，整个系统本来应该是不确定的，但我们总是不自觉地把某种情况（可能性）当作成了真实。这和薛定谔的猫是一个意思，系统总是处于量子态，只有当观测的时候才会坍缩到你观测到的样子。我这里所说的上帝视角的意思就是我们总是人为地、自主地、想当然地、处在上帝的角度 “看到了” 观测结果。

以上就是由三门问题想到的，关于我们决策时的思维过程的一点思考。这里没有涉及贝叶斯，实际上三门问题中当然也有贝叶斯，第二次选择的所有概率都应该是贝叶斯概率（关于三门问题与贝叶斯可以看[这篇文章](https://blog.csdn.net/zjuPeco/article/details/76850866)）；而且贝叶斯在决策过程中也扮演着非常有趣的角色，它的哲学虽然看似简单实则异常迷人，我们择文再议。



**参考**：

- [漫画：反直觉的 “三门问题”](https://mp.weixin.qq.com/s/AvSBzyS2Xbbso8SGT172qQ)
- [数学之美番外篇：快排为什么那样快 – 刘未鹏 | Mind Hacks](http://mindhacks.cn/2008/06/13/why-is-quicksort-so-quick/)

