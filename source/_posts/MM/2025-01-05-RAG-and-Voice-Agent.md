---
title: 实时语音交互场景下RAG的机遇和挑战
date: 2025-01-05 23:00:00
categories: Feeling
tags: [AI, VoiceAgent, RAG]
mathjax: true
---

这是2025年1月4日笔者受邀参加Zilliz举办的【向心力】系列会议《中美AI应用与落地分享》专场中的演讲，特此记录。

> 本文与演讲不完全相同，但核心内容一致。其中涉及到的内容还比较新，观点不一定准确，供参考交流。

这次分享的题目是《实时语音交互场景下RAG的机遇和挑战》，内容主要包括四个方面：主题引入、实时语音交互与RAG的结合、面临的技术挑战和未来的机遇与发展方向。

<!--more-->

## 引入

RAG已经非常成熟，可以说只要落地LLM，就必定有RAG。它解决了LLM的两个主要问题：实时更新和幻觉。LLM无法做到实时更新，导致对某些问题（比如近期的事件）无法做出相应的回复，也无法回答实时性问题（如天气、导航等）。LLM的幻觉是因为其内部的知识与实际情况不一致（一般是错误或不准确的），导致LLM随意发挥输出错误的回复。通过RAG获取当前用户问题的相关信息，再交给LLM，只要相关信息正确，LLM就能准确回复。可以预计，在未来很长一段时间内，RAG都不可或缺。

随着智能手机和智能音箱的普及，语音交互已经成为人们日常生活中常见的交互方式之一。2025年被称为Agent元年，我们认为也会是语音元年，那自然也是语音Agent元年。随着GPT4o等OMNI模型的出现，用户对语音助手的实时性和智能性提出了更高的要求，这为将RAG拓展到实时语音交互场景提供了契机和挑战。

接下来我们将主要围绕如何将RAG拓展到实时语音交互场景，以及在实现这一目标过程中面临的机遇和挑战。

## 实时语音交互与RAG

### 语音交互的特性

首先介绍实时语音交互的特性，主要包括三个方面。

1. 精准理解。

在语音交互中，准确理解用户的意图和需求是至关重要的。这不光需要语音识别技术，还需要语音理解，比如口音、噪音、口语习惯词、情绪、笑声等等。语音交互不光是字面的表达，更多的是双方的交流。只有精准理解用户输入，才能提高RAG在实时语音交互场景下的准确性。

2. 实时性。

实时性（单工、双工）是语音交互的核心特征之一，大部分语言的间隔在200-500毫秒间波动，RAG需要在相当有限的时间内完成语音信息提取、知识库检索和响应生成等任务，以满足用户对实时性的需求。

> 单工是指按轮次对话；双工指双方可以同时讲话。

3. 自然交互。

语音交互的目标是提供一种自然、流畅的用户体验。这种自然既体现在交互行为上，比如打断；也体现在交互内容上，比如输出内容应该是口语化的。RAG需要满足用户的连续提问和反馈、实时打断等，以提供一种无缝的交互体验；同时，其内容应不影响LLM口语化的风格。

### 语音交互与RAG

主要谈与RAG相关的三个方面，暂时不考虑性能方面。

1. 语音检索。

在实时语音交互场景下，语音直接检索知识库可能会是一种常态，知识库可能是文本、语言、图像等多种模态。

2. 语音信息提取+结构化文本+知识库检索。

除了语音直接检索，还有一种方案就是先信息提取，再结构化，再检索。注意，这里的信息提取不仅仅包括ASR的文本，还包括情绪、背景、语速、声调、富语言（笑声、叹息声之类）等等。对信息进行结构化处理也非常重要，我们知道，ASR后的文本一般都和书面语有比较明显的不同，比如各种口水词、衔接语、反复话语等。如果直接去匹配知识库，由于文本风格和知识库的书面语不同，可能导致效果较差。最后是检索，正常的RAG只有一个Query文本，我们现在这种情况则可能需要带上更多信息，比如从音频中提取到的情绪、富语言等。

3. 响应生成。

由于RAG的输出可能是文本、图片或音频，导致丢给LLM的输入可能变成了多模态的，LLM需要能够基于此生成自然、流畅的响应。

### 模型方案

1. Pipeline级联模式。

包括ASR、语音理解、Query解析、RAG、LLM、ToolCall、TTS等模块。这种方案本质上还是围绕LLM，把输入的语音转化为文本描述。优点是方便优化、灵活；缺点是错误逐级放大，类似物流管理中的牛鞭效应。

> 牛鞭效应：一种需求变异放大现象，使信息流从最终客户端向原始供应商端传递时，无法有效地实现信息共享，使得信息扭曲而逐级放大。

2. SpeechLLM。

语音输入到文本输出统一使用SLM（比如Qwen-Audio），使用用户输入音频RAG，接TTS输出Bot音频。这种方案主要做音频RAG、或ASR后文本RAG。

3. 端到端。

完全的端到端，语音进语音出，2024年大火的OMNI，其RAG方案与上面的SpeechLLM一样，但需要模型支持多模态输入。

但是不管哪种方案，RAG都需要，这是未来非常长一段时间内的实际情况。不同的是怎么去RAG，因为现在输入不是文本，而是语音。

## 技术挑战

其实通过前面的介绍，我们应该能大致感受到挑战点。这里列了三个方面。

### 语音信息提取的精度和效率

1. 精度

在实时语音交互场景下，用户的口音、语速和语调、背景噪音等因素都可能对语音信息提取的精度产生影响。此外，语音通话还包含大量的指代，需要综合考虑多轮对话，更是增加了信息提取的难度。

2. 效率

实时性要求系统在有限的时间内完成语音信息提取任务。此外，还需要考虑实时打断、同时讲话等复杂情况。

### 利用相关信息实时检索

1. 知识库检索速度与生成质量的平衡

在实时语音交互场景下，知识库检索的速度和准确性都需要得到保证。然而，由于知识库规模较大且需要在有限的时间内完成检索任务，如何平衡检索速度和准确性是一个挑战。

2. 如何更好地利用相关信息进行检索

由于用户的需求可能是多方面的，如天气、交通、新闻等，而且语音中有更多非Speech内容的信息。因此RAG如何综合所有相关信息进行检索，以提高检索的准确性和全面性是一个挑战。

### 多模态融合匹配问题

1. 语音信号与文本知识库的差异

这点前面已经提到过了。语音和文本是两种不同的模态，而且实际场景下的语音信号还可能存在噪声、口音等问题。如何在这种情况下结合不同模态更好地进行跨模态检索，是提升RAG性能的一个挑战。

2. 多模态输入的上下文理解和一致性生成

如何理解这些多模态输入之间的上下文关系，并根据这些上下文关系生成一致性的响应是一个挑战。

可以看到，三个方面的挑战其核心在”多模态“这里，无论是输入还是输出，语音交互都给模型带来了极大的挑战。如果再考虑到实时性和自然交互，其难度可想而知。

## 未来机遇

### 技术突破点

其实刚刚讨论的技术挑战都是可能的突破点。

先说语音理解，它看起来只针对Pipeline模式，但由于有RAG，其实所有模式都可以用。最常见的理解内容可能包括：文本内容、情绪、语速、音量等。

接下来是知识库匹配优化，包括跨模态检索和结构化检索（即综合各种结构化信息进行检索）。语音直接检索语音的情况其实不太常见，可能音乐类应用比较合适。

最后是多模态理解和基于理解结果的回复生成，这里值得关注的是模态的融合，以及如何基于已有的不同模态预训练模型进行融合训练。

### VoiceAgent赛道

最后要说的是VoiceAgent赛道，2025年是Agent、语音元年，VoiceAgent首当其冲。扣子发布之前，国内大的已经有豆包、海螺、讯飞等语音Agent；扣子发布之后，语音Agent类的产品必定会迎来爆发式增长，毕竟，语音才是人类最自然的交流方式。

关于语音AI的发展，我们引用来自 Bessemer Venture Partners 的[报告](https://www.bvp.com/atlas/roadmap-voice-ai)（[中文版](https://mp.weixin.qq.com/s/BEsT9YPQMVQVR1M52l5xtw)），报告显示，尽管市场规模超过 50 亿美元，传统的电话客服系统仍备受企业和消费者诟病。但过去一年（2024年），语音 AI 在研究、基础设施和应用方面取得了显著进展（关注相关Paper就会深有感触），推动了语音应用开发的热潮。语音到语音模型无需音频转录即可处理语音任务，实现了低延迟、更拟人等突破性进展。报告认为，目前最有机会的应用场景包括：转录、呼入、呼出与筛选、培训、谈判等。

关于Agent的发展，红杉合伙人 Konstantine Buhler 在近期接受了 Bloomberg 独家[采访](https://mp.weixin.qq.com/s/AdXstldGMxP2hLmoslL_dw)时强调，AI 的当前热点是“智能体”，即能够完成具体任务的 AI 系统。他预测，2025 年及以后，AI 智能体将从单一智能体发展到“群体协作”的模式，即多个代理组成网络，彼此协作甚至对抗，完成更复杂的任务。此外，他还指出医疗和教育等关键领域将成为 AI 技术的下一个重要战场，有潜力降低成本、提高效率，从而推动社会进步。

总的来说，笔者个人非常看好这个赛道。