---
title: 自然语言计算机形式分析的理论与方法笔记(Ch17)
date: 2019-04-08 23:32:00
categories: Feeling
tags: [NLP, AI, Evaluation]
---

# 第十七章：自然语言处理系统评测

## 测评的一般原则和方法

两种不同的测评方法：

- 黑箱评测（外在评测）：不关心 NLP 系统内部机制和组成结构，主要根据输入输出结果判断，有助于了解外在的总体性能。
- 白箱评测（内在评测）：对 NLP 内部机制分别分析，测评各组成部分性能，有助于了解内部组成部分的性能。

主要采用黑箱评测，“宽进严出”。

<!--more-->

## 语音合成和文语转换系统的评测

包括语音学模块评测和语言学模块评测。语音合成只包括语音学评测；文语转换包括两者。

语音学评测包括语音清晰度和语音自然度两部分。前者指输出语音是否容易听清楚；后者指输出语音听起来是否自然。

语音清晰度又分为音节清晰度测试、单词清晰度测试和单句清晰度测试。

- 音节清晰度测试方法主要有诊断性押韵测试（Diagnostic Rhyme Test，DRT）和改进的押韵测试（Modified Rhyme Test，MRT）两种。
    - DRT 一般以三个音节为一组，每个组为一个文本文件
    - MRT 一般以一个音节为一组，每个组为一个文本文件
    - MRT 的结果可以作为 DRT 测试法的参考

- 单词清晰度测试采用 “语义不可预测句”（Semantic Unpredictable Sentence，SUS），句子在语义上不可预测，避免根据上下文猜测，并在一定程度上削弱学习效应。

- 单句清晰度测试主要测试单句中语调的清晰性和单句类型的差异性。应注意区分单句的类型（如陈述句、疑问句、感叹句、命令句等），注意测试标点符号对于句子语音清晰度的影响。
- 音节清晰度采用 DRT 或 MRT 方法测试，单词、单句清晰度采用 SUS 方法测试。收集完所有系统的合成语音，打乱顺序播放，由听音人对合成语音结果测试进行打分，按百分比进行评分。
    - DRT 和 MRT：P = (R-W)/T，R 和 W 分别是正确和错误辨识的音节数，T 是测试的总音节数
    - 单词只要其中一个音节错则该词错；单句只要有一个关键词错则全句错：P = R/T

语言自然度主要测试合成语音的拟人性、连贯性和韵律感。

- 拟人性考察合成语音是否与人的语音接近

- 连贯性考察合成语音是否连贯，切词是否正确，节奏与停顿是否自然，语速是否正常，发音是否流利

- 韵律感考察合成语音的语调、重音位置、轻声和儿化是否正确，听起来是否费力

- 这些特征在短文中得到了比较全面的体现，因此一般以短文作为测试材料
    - 短文根据领域分为通用领域和特定领域，长度 50-200 字
    - 通用领域由不同体裁若干短文组成
    - 特定领域由若干欢迎语、提示语、情景对话、信息服务内容片断组成

- 语言自然度评分方法有两两比较法和平均评价法两种
    - 两两评分法（Paired Comparison，PC）：对同一段短文，n 个参测系统，共有 n(n-1)/2 个对比组合，听音人按照拟人性、连贯性、韵律感等因素对合成结果采用五级评分值（+2 +1 0 -1 -2）评分。
    - 平均评分法（Mean Opinion Score，MOS）：需要专家参与评分，根据总体印象用优良中差劣五级计分评价。
    - PC 评分为主，MOS 评分为辅。
    - 具体要求如下：
        - 切词：特别注意实体及术语切词是否正确
        - 多音字
        - 姓氏的特殊读音
        - 数字进位制
        - 年代、时间、电话号码、百分比、分数和小数
        - 符号与单位
        - 以西文字母开头的词语
        - “一” “不” 的读音
        - 上声变调
        - 轻声的读音
        - 儿化的读音
        - 专有名词读音
        - 专业术语读音

语音识别系统的评测主要测试语音文本转换和音节转换。

- 语音文本转换测评指标有：

    - 汉字正识率
    - 插入汉字错误率
    - 删除汉字错误率
    - 替换汉字错误率
    - 句子正识率
    - 完成时间
    - 系统故障数
- 音节识别测评指标有：
    - 音节正识率
    - 插入音节错误率
    - 删除音节错误率
    - 替换音节错误率
    - 完成时间
    - 系统故障数
- 对语音识别系统产生的文本也要进行语言学方面测评，具体要求包括：
    - 字形
    - 异形词
    - 同音词
    - 歧义（切分）
    - 儿化词

## 机器翻译系统的评测

机器翻译系统一般分为如下几种类型：

- 用于浏览者的机器翻译（MT for the Watcher，MT-W）：目的是帮助浏览者查阅外文资料，对译文质量要求不高
- 用于修订者的机器翻译（MT for the Reviser，MT-R）：目的是帮助用户修订粗糙的译文，质量比 MT-W 有所提高
- 用于翻译者的机器翻译（MT for the Translator，MT-T）：目的是帮用户在线翻译，质量要求较高
- 用于写作者的机器翻译（MT for the Author，MT-A）：目的是帮助用户翻译或写作，质量要求更高

根据类型不同，测评时考虑不同的重点。评测题目选取应遵循以下原则：

- 外汉机翻系统中，源语言应以相应外语大学教学大纲作为题目选取的主要依据；汉外机翻系统中，汉语应以常用句型作为题目选取的主要依据
- 通用机翻系统测试题目的词汇选自一般领域；专业机翻系统测试题目的词汇和语法结构应体现不同专业领域的特点
- 测试题目可以包含少量常用固定词组
- 测试题目应该注意区别兼类词
- 测试题目应该注意区别多义词或同音词
- 测试题目应该有一定数量的用于区别结构歧义的句子
- 测试题目应该选取现代书面语中的规范句子

机翻系统评测分为人工和自动评测两种。

- 人工：
    - 忠实度（0-5分）：是否忠实地表达了原文内容；流畅度（0-5分）：是否流畅和地道
    - 可理解度
    - 符合语言文字规范：字形、异形词、标点符号、术语、人名等
    - 注意不同风格、不同语体文章
- 自动：
    - BLEU 基于 N 元语法，通过对译文跟参考译文进行 N-gram 的比较综合得出译文的好坏的评价分数，可以参考这篇[笔记](https://nbviewer.jupyter.org/github/hscspring/All4NLP/blob/master/BLEU/BLEU-Tutorial.ipynb)
    - NIST 是在 BLEU 基础上的改进方案，采用各阶 N-gram 的平均值而不是加权平均值，使得总体评价结果更偏重于忠实度，而且也不至于因为某一阶 N-gram 的匹配率为零而导致总体评价为零。另外，NIST 考虑到每一个 N-gram 在多个参考译文中出现的次数不同能够表现出该词的重要性，因此根据其在多个参考译文中出现的次数而给每一个 N-gram 赋予一个权值。可以参考这篇[笔记](https://nbviewer.jupyter.org/github/hscspring/All4NLP/blob/master/BLEU/NIST-Tutorial.ipynb)

其他测评机翻译文质量的方式：

- 根据编辑对译文的修改量
- 机翻译文与人翻译文比较
- 根据最终费用

除了译文质量，还可以采用以下指标评测机翻系统：

- 根据机翻所需要的时间
- 根据使用环境的要求
- 根据可维护性
- 根据可扩充性
- 根据系统性价比
- 根据系统鲁棒性
- 根据模块性
- 根据单调性

## 语料库系统的评测

语料库是为一个或多个应用目标而专门收集的、有一定结构的、有代表性的、可被计算机程序检索的、具有一定规模的语料的集合。实际上是对自然语言运用的随机抽样。

语料库可以从规范性、代表性、结构性和平衡性等四个方面进行评测。

语料的元数据可以反映语料库的基本信息。

语料库自动切词和标注的评测遵循以下原则：

- 应当遵循《分词规范》
- 不确定的参照《现代汉语词典》
- 不同应用对切词的颗粒度不同，可以容许同一语言结构按照不同层次切分
- 注意切分时的歧义
    - 交集型：从小|学|电脑，从|小学|毕业
    - 多义组合型：他|将|来|北京|工作，情况|将来|会变

- 注意命名实体
- 标注时注意区分兼类词

计算公式：

- 切词正确率 = 正确的切词数/标准切词数
- 词性标注正确率 = 正确标注的切词数/标准切词数
- 词性标注相对正确率 = 正确标注的切词数/正确的切词数（由于切词错误时标注自然没有意义）

## 国外自然语言处理系统的评测

除了 BLEU 和 NIST，还有词对齐、基于编辑距离的方法，以及分类、回归和排序。研究发现回归比分类更可靠。

- 分类是从多个机翻系统中选最好的
- 回归通过调节不同特征参数，使得结果接近训练数据的人工评分
- 根据不同机翻系统之间译文质量进行排序

两种自动增加参考译文的方法：

- 使用伪参考译文：“伪参考译文” 是指其他机翻系统的译文。
- 使用同义互训：把一些句子或短语表示为语义上对等的句子或短语。

其他方面的评测：

- C-STAR 组织口语机翻系统评测

- DARPA 组织语音识别和语音合成的评测
- NIST 组织文本检索的评测
- NIST 组织问答系统评测，任务包括：
    - Factoid 任务：对基于事实、有简短答案的提问的处理能力
    - List 任务：列出满足用户提问的若干答案
    - Definition 任务：给出对于某个概念、术语或现象的定义
    - Context 任务：对于相互关联的系列提问的处理能力
    - Passage 任务：要求系统给出包含答案的字符序列
    - Other 任务：要求返回非空、无序、无限定内容的关于目标的描述，但不能包含 Factoid 和 List 已经回答的内容
- NIST 组织文档理解评测，人工五项指标：
    - 文摘是否合乎语法
    - 文摘是否冗余
    - 指代是否清晰
    - 聚焦情况
    - 结构和连贯性
- MUC 对文本信息抽取系统的评测，评测任务包括：
    - 场景模板填充
    - 命名实体识别
    - 共指关系确定
    - 模板元素填充
    - 模板关系确定
- NIST 组织自动内容测评对 MUC 的任务进行融合：
    - 实体检测和识别：命名实体识别+共指关系确定
    - 关系检测和识别：模板元素填充+模板关系确定
    - 事件检测和识别：场景模板填充
    - 时间短语表达和数量值识别

## 小结

- 测评的一般原则和方法

    - 黑箱测评+白箱测评
    - 主要采用黑箱评测，“宽进严出”
- 语音合成和文语转换系统的评测

    - 包括语音学模块评测和语言学模块评测。语音合成只包括语音学评测；文语转换包括两者。
    - 语音学评测包括语音清晰度和语音自然度两部分。前者指输出语音是否容易听清楚；后者指输出语音听起来是否自然。
    - 语音清晰度又分为音节清晰度测试、单词清晰度测试和单句清晰度测试。音节清晰度采用 DRT 或 MRT 方法测试，单词、单句清晰度采用 SUS 方法测试。收集完所有系统的合成语音，打乱顺序播放，由听音人对合成语音结果测试进行打分，按百分比进行评分。
    - 语言自然度主要测试合成语音的拟人性、连贯性和韵律感。
        - 拟人性考察合成语音是否与人的语音接近
        - 连贯性考察合成语音是否连贯，切词是否正确，节奏与停顿是否自然，语速是否正常，发音是否流利
        - 韵律感考察合成语音的语调、重音位置、轻声和儿化是否正确，听起来是否费力
    - 语言自然度评分方法有两两比较法和平均评价法两种，PC 评分为主，MOS 评分为辅。
    - 语音识别系统的评测主要测试语音文本转换和音节转换。对语音识别系统产生的文本也要进行语言学方面测评。
- 机器翻译系统的评测

    - 机器翻译系统一般分为如下几种类型：用于浏览者的机器翻译、用于修订者的机器翻译、用于翻译者的机器翻译和用于写作者的机器翻译
    - 根据类型不同，测评时考虑不同的重点。评测题目选取应遵循以下原则：
        - 外汉机翻系统中，源语言应以相应外语大学教学大纲作为题目选取的主要依据；汉外机翻系统中，汉语应以常用句型作为题目选取的主要依据
        - 通用机翻系统测试题目的词汇选自一般领域；专业机翻系统测试题目的词汇和语法结构应体现不同专业领域的特点
        - 测试题目可以包含少量常用固定词组
        - 测试题目应该注意区别兼类词
        - 测试题目应该注意区别多义词或同音词
        - 测试题目应该有一定数量的用于区别结构歧义的句子
        - 测试题目应该选取现代书面语中的规范句子
    - 机翻系统人工测评：忠实度、流畅度、可理解度

    - 机翻系统自动测评：BLEU 和 NIST
- 语料库系统的评测
    - 语料库可以从规范性、代表性、结构性和平衡性等四个方面进行评测。
    - 语料库自动切词和标注的评测遵循以下原则：
        - 应当遵循《分词规范》
        - 不确定的参照《现代汉语词典》
        - 不同应用对切词的颗粒度不同，可以容许同一语言结构按照不同层次切分
        - 注意切分时的歧义
        - 注意命名实体
        - 标注时注意区分兼类词
- 国外自然语言处理系统的评测
    - 机翻：除了 BLEU 和 NIST，还有词对齐、基于编辑距离的方法，以及分类、回归和排序。研究发现回归比分类更可靠。
    - C-STAR 组织口语机翻系统评测
    - DARPA 组织语音识别和语音合成的评测
    - NIST 组织文本检索的评测
    - NIST 组织问答系统评测
    - NIST 组织文档理解评测
    - MUC 对文本信息抽取系统的评测
    - NIST 组织自动内容测评对 MUC 的任务进行融合



本章内容可以了解一下，某些内容也可以在 NLP 很多任务中参考，比如语言自然度评测的一些要求也可以用在纠错中。