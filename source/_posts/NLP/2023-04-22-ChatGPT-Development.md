---
title: ChatGPT 开发指南：Hugging LLM Hugging Future
date: 2023-04-22 12:00:00
categories: Thinking
tags: [AI, NLP, ChatGPT, LLM, LM, HuggingLLM]
mathjax: false
---

> 本文属于DataWhale [Hugging-LLM](https://github.com/datawhalechina/hugging-llm)开源教程介绍内容，详细教程请跳转链接。

随着ChatGPT的爆火，我们相信未来会有越来越多的大模型及类似OpenAI提供的服务出现，AI 正在逐渐平民化，将来每个人都可以利用大模型轻松地做出自己的AI产品。

HuggingLLM是一个面向非算法、有一定编程基础、对AI和ChatGPT（或类似模型）感兴趣的，基于ChatGPT API开发相关应用的开源项目。当然部分内容不需要任何编程经验也可以学习，算法工程师也可能从中受益。项目主要包括ChatGPT基础科普、ChatGPT实现各种NLP常见任务（相似匹配、句词分类、编辑生成、推理等大类）、ChatGPT局限和商业应用等内容。

项目名为 HuggingLLM，因为我们相信正在经历一个伟大的时代，我们相信这是一个值得每个人全身心拥抱的时代，我们更加相信这个世界必将会因此而变得更加美好。

<!--more-->

## 动机初心

从去年年底ChatGPT的发布以来，作为NLP（Natural Language Processing）一线从业人员已经感受到了巨大压力，我甚至觉得NLP工程师这个职位以后一定会消亡，至今这个观点依然不变。当时在见识了ChatGPT的各种逆天能力后，很自然地就会瞬间想到以后开发人员只要借助ChatGPT，完全可以做到现在大部分NLP工程师在做的事，比如文本分类、实体抽取、推理等。甚至随着LLM（Large Language Model）能力的不断提升，可能做的比NLP工程是都要好。既然这是迟早会发生的事，干脆我们就再点把火，做一个教程告诉开发人员或有一些编程能力的人去利用LLM做一些NLP任务或服务，让变革来的更猛烈些。当时发起此项目时，颇有一种悲壮感。

NLP工程师未来不一定存在（就像没有公司有Office工程师一样），但如果每个企业，尤其是中小企业都能自由地使用LLM的能力创造AI服务或应用，这不正是自己这些年的理想吗？我曾在几家小公司呆过，深刻知晓和理解小企业对AI的「情」，那种想用但又无力的矛盾。他们大多非常珍惜AI人才，但又不能大量投入。类似ChatGPT这样的LLM让他们异常兴奋。我们就是想要架起这么一座桥梁，让没有任何算法背景的开发人员能够尽量无缝、顺滑地对接起算法工作。

项目发起时，DataWhale内部马上就有小伙伴响应，我们一起讨论这个教程，大家一致觉得可以做。一方面是确实很有意义，另一方面也是市面上的教程太多了，确实有不少精品教程，但更多的是在割韭菜，割的让人有点看不下去。我依然记得玉琳同学义愤填膺，说我们要做一个开源教程，3块钱的。我们听了后大为赞同。

> DataWhale的开源学习是3块：1块学习，1块分享，1块成长。

不过，我们的教程设计主要是偏API开发，基础应用那块由其他成员负责。API这块据我们当时所知，国内应该没有类似教程。其实，除了上面说的那些，我在立项时还有个想法，那就是——授人以渔。自从ChatGPT出来后，底层的技术变化不大，但上层的应用却是天翻地覆。我承认自己脑子没那么灵活，市场意识也很一般，在我看来好像很多事情可以做，但好像又没什么真正特别亮眼的。实际证明还是自己狭隘了，既然如此，那我们把方法传播给更多人，也算是对这个行业的一点贡献吧。行业蒸蒸日上，作为其中的从业人员，能得到的肯定比失去的更多，即便是这个职业未来岌岌可危。

项目就这么立起来了，当时的立项理由如下：

> ChatGPT改变了NLP行业，甚至正在改变整个产业。我们想借这个项目将ChatGPT介绍给更多的人，尤其是对此感兴趣、想利用相关技术做一些新产品或应用的学习者，尤其是非本专业人员。希望新的技术突破能够更多地改善我们所处的世界。

教程的结构从一开始定下来基本没有调整，只有章节内部内容有一些微调，但整体最终呈现出来的就是当时设计时构思的。我们相信教程是忠于理由的，我们期望教程能为改善世界贡献一分力量。

## 内容设计

教程一共有七章内容，分别如下：

- ChatGPT基础科普。主要介绍了和ChatGPT相关的一些NLP领域的基础知识，具体包括：LM（Language Model）、Transformer、GPT（Generative Pre-trained Transformer）和RLHF（Reinforcement Learning from Human Feedback）四个部分。掌握了这部分知识就能大概知道ChatGPT或其他LLM是怎么回事，对一些概念也能有个基本认识。
- ChatGPT使用指南：相似匹配。主要介绍了文本表示，以及和文本匹配相关的任务和应用。这是NLP领域（还有其他一些算法领域）最常用的技术。具体内容包括：Embedding基础、API使用、QA任务、聚类任务和推荐应用。
- ChatGPT使用指南：句词分类。主要介绍了NLP领域最常见的任务——分类。其实也是人类最基本的认知方式（比如男女、星座、标签化等）。具体内容包括：NLU（Natural Language Understanding）、API使用、文档问答任务、分类与实体识别微调任务和智能对话应用。
- ChatGPT使用指南：编辑生成。主要介绍了和生成相关的任务，具体包括文本摘要、文本纠错和机器翻译。生成技术在实际场景中使用会相对少一些，也相对独立一些。
- ChatGPT使用指南：文本推理。主要介绍如何使用ChatGPT做复杂的逻辑推理任务，这一块内容在实际中应用很少，但在新的产品形态上却有很多想象空间。具体内容包括：推理简介、能力测试、能力调用等。
- ChatGPT局限不足。主要介绍ChatGPT（或类LLM）的缺陷或不擅长的地方，包括：事实错误、实时更新、资源耗费等。我们在畅想可能的同时，也应该了解它不擅长的地方，一方面是对其有更加全面的认识；另一方面反向思维有时候也能想象出一些好的应用或服务。
- ChatGPT商业应用。可以当做一篇调研报告来阅读，主要针对工具应用和行业应用两个大的方面展开，期望能够给学员更多启迪，帮助大家构思更好的应用或服务。

在实际学习时，上面的内容会重新组合为以下两个部分：

- 第一部分：基础科普+局限不足+商业应用。作为「基础」的阅读材料，可以先行了解，带着这些内容学习有助于更好地构思自己的应用。
- 第二部分：根据内容规模和难度，重新排列为：相似匹配、文本推理、生成编辑和句词分类。

当然，学习者也可以根据自己的兴趣，选择任意章节进行学习。本教程有两个基本的理念：

- 各章节相对独立，彼此没有直接明显的前后依赖关系。这体现在内容上，也体现在设计上。学习者可以灵活选取自己感兴趣的章节学习。
- 以「任务」为核心。我们始终强调「任务」多于「工具」，ChatGPT是目前最好的工具，但未来一定会有其他LLM出现。但只要我们理解了要做的事情，理解了系统设计，工具就能为我所用。

此外，教程还有比较详细的示例代码，大部分的代码都可以直接用于生产环境。我们也着重强调构建实际应用需要注意的细节。写代码容易，写好代码很不容易；做Demo简单，提供一个稳定可靠的服务很不简单。

所以，学习本教程要有一定编程基础或实际项目（不一定是算法）经历，它不是零基础教程（虽然有部分内容零基础也可以学习）。除此之外，你还应该能够调用OpenAI的API，并有一定的时间保证。具体可以阅读[学习指南](https://github.com/datawhalechina/hugging-llm#%E5%A6%82%E4%BD%95%E5%AD%A6%E4%B9%A0)。

## 指南说明

相信通过上面的介绍，学习者应该对本教程的情况有了初步了解。我们这里主要从创作者的角度简单谈一下教程期望学习者能收获什么或应该做什么。

首先，我们期望学习者能够完成一个大作业，也是整个学习期间唯一的任务：以教程任一方向为例，完成一个应用或服务Demo。具体要求可以参考[学习指南](https://github.com/datawhalechina/hugging-llm#%E5%AD%A6%E4%B9%A0%E6%8C%87%E5%8D%97)。光看不做在编程领域是绝对不行的，万事开头难，做了第一个，后面的会自然而然。

其次，我们期望学习者能在学习过程中多思考，可以和自己工作的实际业务相结合，也可以天马行空地构想。我们非常期待大家能分享自己的想法，众人拾柴火焰高，个体能想到的太少了，但这么多人一起想，也许能够改变一个行业。

第三，我们期望学习者能对NLP领域常见任务有个基本的认识，了解一些基本概念。我们不是要大家都成为NLP工程师，但期望大家能够利用ChatGPT或其他LLM提供的API来完成NLP的任务，提供相关服务，期望大家在学习完教程后都具备这样的能力。

第四，洛克菲勒说过：“真正重要的不在于有多少知识，而在于如何使用现有的知识。知识只是潜在的力量，只有将其付诸应用，而且是建设性的应用，才会显示出它的威力”。由于教程围绕着任务展开，很多设计思路和细节其实可以应用在多个领域。我们再次强调，期望学习者能够多多实践，多多应用。

最后，由于创作团队精力有限，教程难免有些疏漏甚至错误，我们期望学习者在学习的同时，也能积极给我们建议，或者直接对项目进行贡献，让我们共同打磨教程，为后面的学习者提供更好的内容。

除此之外，针对本教程还有一些其他补充说明，大家可以阅读[学习说明](https://github.com/datawhalechina/hugging-llm#%E5%AD%A6%E4%B9%A0%E8%AF%B4%E6%98%8E)。我们期望所有学习者都能够学有所得，期待大家能做出举世瞩目的产品和应用。