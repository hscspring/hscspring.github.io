<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  
  <meta name="description" content="AI | NLP | 人工智能 | 哲学 | 自然语言处理 | 机器学习">
  

  
  
  
  
  
  <title>自然语言计算机形式分析的理论与方法笔记(Ch08) | Yam</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="第八章：语义自动处理的形式模型 关于语义与语法分析的关系，有两种方式：先句法后语义和句法语义一体化。">
<meta name="keywords" content="AI,NLP,Semantic Automatic Processing">
<meta property="og:type" content="article">
<meta property="og:title" content="自然语言计算机形式分析的理论与方法笔记(Ch08)">
<meta property="og:url" content="https://yam.gift/2019/02/15/NLP/NLPFA/2019-02-15-Ch08-Formal-Model-of-Semantic-Automatic-Processing/index.html">
<meta property="og:site_name" content="Yam">
<meta property="og:description" content="第八章：语义自动处理的形式模型 关于语义与语法分析的关系，有两种方式：先句法后语义和句法语义一体化。">
<meta property="og:locale" content="default">
<meta property="og:updated_time" content="2024-06-12T02:06:43.540Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="自然语言计算机形式分析的理论与方法笔记(Ch08)">
<meta name="twitter:description" content="第八章：语义自动处理的形式模型 关于语义与语法分析的关系，有两种方式：先句法后语义和句法语义一体化。">
  
  
    <link rel="icon" href="/css/images/favicon.ico">
  
  <link rel="stylesheet" href="/css/style.css">
  

  
  <!-- baidu webmaster push -->
<link rel="alternate" href="/atom.xml" title="Yam" type="application/atom+xml">
<link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /><!-- hexo-inject:begin --><!-- hexo-inject:end --></head></html>
<body class="home blog custom-background custom-font-enabled single-author">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="page" class="hfeed site">
      <header id="masthead" class="site-header" role="banner">
    <hgroup>
      <h1 class="site-title">
        <a href="/" title="Yam" rel="home">Yam</a>
      </h1>
      
        <h2 class="site-description">
          <a href="/" id="subtitle">Feeling, Coding, Thinking</a>
        </h2>
      
    </hgroup>

    <nav id="site-navigation" class="main-navigation" role="navigation">
            <button class="menu-toggle">菜单</button>
            <a class="assistive-text" href="/#content" title="跳至内容">跳至内容</a><!--TODO-->
            <div class="menu-main-container">
                <ul id="menu-main" class="nav-menu">
                
                    <li class="menu-item menu-item-type-post_type menu-item-object-page"><a href="/">Home</a></li>
                
                    <li class="menu-item menu-item-type-post_type menu-item-object-page"><a href="/series/">Series</a></li>
                
                    <li class="menu-item menu-item-type-post_type menu-item-object-page"><a href="/archives/">Archives</a></li>
                
                    <li class="menu-item menu-item-type-post_type menu-item-object-page"><a href="/about/">About</a></li>
                
                    <li class="menu-item menu-item-type-post_type menu-item-object-page"><a href="https://github.com/hscspring">Projects</a></li>
                
                </ul>
            </div>
    </nav>
</header>
      <div id="main" class="wrapper">
        <div id="primary" class="site-content"><div id="content" role="main"><article id="post-NLP/NLPFA/2019-02-15-Ch08-Formal-Model-of-Semantic-Automatic-Processing" class="post-NLP/NLPFA/2019-02-15-Ch08-Formal-Model-of-Semantic-Automatic-Processing post type-post status-publish format-standard hentry">
    <!---->

      <header class="entry-header">
        
        
  
    <h1 class="entry-title article-title">
      自然语言计算机形式分析的理论与方法笔记(Ch08)
    </h1>
  

        
        <!-- <div class="comments-link">
            
            <a href="javascript:void(0);" data-url="https://yam.gift/2019/02/15/NLP/NLPFA/2019-02-15-Ch08-Formal-Model-of-Semantic-Automatic-Processing/" data-id="cm5jp90mb016yvmbz5jmyrvon" class="leave-reply bdsharebuttonbox" data-cmd="more"></a>
        </div> --><!-- .comments-link -->
      </header><!-- .entry-header -->

    <div class="entry-content">
      
            <!-- Table of Contents -->
              
        <h1>第八章：语义自动处理的形式模型</h1>
<p>关于语义与语法分析的关系，有两种方式：先句法后语义和句法语义一体化。</p>
<a id="more"></a>
<h2 id="义素分析法">义素分析法</h2>
<p>20 世纪 40 年代初期，结构主义丹麦学派代表人数 L. Hjelmslev 提出义素分析法的设想；20 世纪 50 年代，美国人类学家 F. G. Lounsbury 和 W. H. Goodenough 在研究亲属词的含义时提出了义素分析法；20 世纪 60 年代初，美国语言学家 J. J. Katz 和 J. A. Fodor 提出了解释语义学，将义素分析法引入语言学，为生成转换语法提供语义特征。</p>
<p>义素是意义的基本要素，它就是词的理性意义的区别特征。词的理性意义是一束语义特征（义素）的总和。一组词的义素可以用义素矩阵表示，纵坐标表示词，横坐标表示义素，纵横坐标相交点注以 + 或 - 号或其他表示方法。</p>
<p>采用义素分析法建造机器词典可以解决利用辞典直接存储每个词意义（义项）的问题（占用空间大；难于判断别同义词、近义词在意义上的差别；难以确定词与词之间的搭配关系）：</p>
<ul>
<li>机器词典中词条以义素存储，可以使用较少的义素对大量的词义做形式化描述</li>
<li>通过对机器词典中不同义素集合内的各个义素的分析比较，计算机容易找出不同单词在词义上的细微差别</li>
<li>通过义素分析法，计算机可以了解词与词搭配时在语义上要受到什么样的限制</li>
</ul>
<p>隐喻在修辞学中属于一种 “辞格”，一个完整的隐喻一般由 “喻体” 和 “本体” 构成，喻体通常是我们熟悉的、比较具体直观、容易理解的一些概念范畴，本体则是我们后来才认识的、抽象的、不易理解的概念范畴。在认知语言学中，喻体叫作 “始源域”，本体叫作 “目标域”。隐喻的认知力量就在于将始源域的图式结构映射到目标域上，使人们对目标域有更清晰的认识。<strong>认知语言学认为，隐喻不但是一种修辞手段，而且还是人的一种思维方式普遍存在于人们的各种认知活动中。</strong></p>
<h2 id="语义场">语义场</h2>
<p>要进行义素分析，首先要对该语言的词汇体系建立起 “语义场”。</p>
<p>1924 年，德国学者 G. Ipsen 提出该术语，20 世纪 30 年代初，德国学者 J. Trier 提出系统的语义场理论，1992 年，北大贾彦德在《汉语语义学》中系统提出了汉语的语义场理论，北京语言大学张普提出 “场型” 的概念。</p>
<p>语义场是词义形成的系统，它是基于概念的关系场，是词义与词义之间构成的一种完全虚化、非物质的空间领域。若干个意义上紧密相联的词义，通常归属于一个总称之下，就构成了语义场。</p>
<p>语义场可进一步分为词汇场和联想场。词汇场是静态的，表现为词义与词义之间的组合关系。这里的语义场主要指词汇场。</p>
<p>汉语的场型（不同类型的语义场）包括：</p>
<ul>
<li>分类场型：基本场型，一般是多层次的，特点如下：
<ul>
<li>上下词义之间存在着领属关系，上位表示领域，下位表示分类</li>
<li>下位可以继承上位的基本义素</li>
</ul>
</li>
<li>构件场型：基本场型，下位是上位的构件，特点如下：
<ul>
<li>上下位之间是整体和构件的关系</li>
<li>不是下位继承上位义素而是上位抽取下位的某些义素来集成</li>
</ul>
</li>
<li>有序场型：基于分类场型和构件场型的特殊场型，所有平位是有序的，特点如下：
<ul>
<li>同一层次的词义排列是有序的，反应了客观世界的有序性</li>
<li>一些有序的词义是封闭型的，封闭型的词义可以循环</li>
</ul>
</li>
<li>对立场型：特殊场型，平位的词义之间存在对立关系，特点如下：
<ul>
<li>一些对立场型中的平位只有两个</li>
<li>一些对立场型的平位不止两个，之间还有中间状态，这种对立叫作两极对立</li>
</ul>
</li>
<li>同义场型：特殊场型，同一场型中，同位和变位的理性意义完全相同，只是附属于理性意义的风格、色彩等方面义素不同</li>
</ul>
<p>场与场之间的关系有：</p>
<ul>
<li>嵌套关系：同一类场型之间的关系</li>
<li>交叉关系：不同场型之间的关系</li>
<li>传递关系：不同场型之间的关系</li>
<li>联想关系：不同场型之间和同一场型不同子场之间都可以产生联想关系</li>
</ul>
<h2 id="语义网络">语义网络</h2>
<p>1968 年美国心理学家 M. R. Quillian 研究人类联想记忆时提出的，1972 年，美国人工智能专家 R. F. Simmons 和 J. Slocum 首先将语义网络用于自然语言理解系统中。1977 年，美国人工智能学者 G. Hendrix 提出了分块语义网络的思想，把语义的逻辑表示与 “格语法” 结合起来，把复杂问题分解为若干简单的子问题，每个子问题以一个语义网络表示。</p>
<p>语义网络可用有向图表示，一个语义网络就是由一些以有向图表示的三元组：（结点1，弧，结点2）连接而成的。三元组可写成二元谓词：P（个体1，个体2）</p>
<p>在人工智能中，语义网络内各概念之间的关系主要（常见的关系）由 ISA, PART-OF, IS 等谓词来表示，分别是 “具体-抽象” 关系（隶属关系）、“整体-构件” 关系（包含关系）、“一个结点是另一个结点的属性”。</p>
<p>语义网络可表示一个事件，事件由若干个概念组合所反映的客观现实，可以分为叙述性事件、描述性事件和表述性事件三种。语义网络表述事件时，结点之间的关系还可以为施事（AGENT）、受事（OPATIENT）、位置（LOCATION）、时间（TIME）等。</p>
<p>语义网络的推理机制一般基于网络的匹配。根据提出的问题构建局部网络，查询解答的过程就是查询局部网络到网络知识库的匹配操作。</p>
<p>知识图谱描述真实世界中存在的各种实体或概念，每个属性-值偶对用来刻画实体的内在特性，而关系用来连接两个实体。可以看作一个巨大的语义网络。</p>
<p>知识图谱不仅需要在数据层构建（自底向上），还需要在模式层上构建（自顶向下），模式是对知识的提炼，遵循预先给定的模式，有助于知识的标准化。</p>
<h2 id="montague-语法">Montague 语法</h2>
<p>Montague 语法采用内涵逻辑的方法描述句子语义内容，1970 年前后美国数理逻辑学家 R. Montague 等把内涵逻辑应用于自然语言的研究，并把生成语法与内涵逻辑这两个领域的研究集中提炼为 Montague 语法。</p>
<p>Montague 认为自然语言与高度形式化的逻辑语言没有区别，他将 Frege 原理（一个句子的整体意义是它各部分意义和组合方式的函数）中的 “意义” 扩展到 “结构”：一个句子的整体结构是它各部分的结构和组合方式的函数。</p>
<p>因此在 Montague 语法里，一个句子的句法形式、内涵逻辑表达式和语义所指都是从基本单位开始，通过句法规则、转译规则和语义规则，从小到大逐段确定的。句法、转译和语义三大部分是同态的。有一条句法规则就有一条转译规则把它处理的短语转译成内涵逻辑表达式，然后再由一条语义规则来确定这个内涵逻辑表达式的语义。歧义问题通过不同的组合方式和运用不同的句法、语义规则来解决，这是 Montague 语法的 “规则对规则假说”。</p>
<ul>
<li>句法：包括一套语类和一套句法规则。功能是把来自词库的词语组成句子。
<ul>
<li>语类给基本词语规定一个句法范畴
<ul>
<li>语类由基本语类 e 和 t 以及它们之间关系的一组集合，e 和 t 是基本语类，其他是派生语类。</li>
<li>语类 e 表示自然界某类事物中的个体词语或实体词语，并不等于传统语法中的名词或名词短语。</li>
<li>语类 t 表示具有真值的语言单位，叫作真值词语或陈述语句。</li>
</ul>
</li>
<li>句法规则把基本词语变成短语，然后再把较小片段短语合成较大片段短语</li>
</ul>
</li>
<li>转译：包括一套转译规则，把短语转译成内涵逻辑表达式。</li>
<li>语义：以内涵逻辑为基础建立的。内涵逻辑包括句法和语义两方面：
<ul>
<li>句法：由一套义类系统和句法规则组成，主要解决内涵逻辑结构成分的结合问题。
<ul>
<li>义类由对应函数从该词项的语类中求得</li>
<li>句法规则规定各种成分结合以后的义类</li>
</ul>
</li>
<li>语义：解决语义所指问题，有一套语义规则，运用这套规则可以求出内涵逻辑表达式在特定模型中的语义所指。</li>
</ul>
</li>
</ul>
<p>Montague 语法有两个来源：N. Chomsky 的生成转换语法 和 Louis 的内涵逻辑学。采用内涵逻辑学来描述句子的深层结构，在句子的每一个层次上都可得出一个相应的内涵逻辑表达式，并以此来表示该句子深层结构的逻辑含义。从 (λx…x…)a 出发得到 …a… 这一性质称为 “λ-变换”， <strong>λ-变换是 Montague 语法转译计算的关键</strong>，生成语法得出的完全相同的树形图在 λ-变换后，可以得出不同的内涵逻辑表达式。</p>
<p>Montague 通过真值条件语义学、模型论语义学和可能世界语义学（Montague 语法的语义理论的三个特点），把自然语言所表现出来的意义介入内涵逻辑学中，从而建立了 Montague 语法的语义理论。由于将句法和语义结合，使得任何一个通过句法分析得到的表示句子的句法结构的树形图，都可以用 Montague 语法解释为相应的内涵逻辑表达式，从而表现出句子的语义内容。</p>
<p>Montague 在《普通英语中量化的特定处理》中提出了 PTQ 系统用以计算句子的语义值，步骤如下：</p>
<ul>
<li>选出有限片段的英语，从中提炼出包含 9 个派生语类的词典和 17 条句法规则，根据组合原则，从最简单的成分词汇开始，逐层组合成复杂成分</li>
<li>片段英语的 17 条句法规则中的每一条都相应地对应着一条转译规则，将片段英语中的每一个语言成分转译成内涵逻辑语言中的一个内涵逻辑表达式，最后将复杂的语言表达式转译成复杂的内涵逻辑表达式</li>
<li>根据内涵逻辑的语义解释规则，将内涵逻辑表达式在给定的模型下求出其语义值，即为该片段英语表达式的一个语义解释</li>
</ul>
<h2 id="wilks-的优选语义学">Wilks 的优选语义学</h2>
<p>1874 年，Y. A. Wilks 在研制英法机器翻译系统的基础上，提出了 “优选语义学”，它共有五种语义单位：义素、义式、裸模板、模板、超模板，并有从较小的单位到较大的单位的构造规则。义素构成义式以描写单词的语义，由义式构成裸模板和模板以描述简单句的语义，再由超模板描写更大的文句单位一直到句子的语义。</p>
<ul>
<li>义素：80 个语义单元，用以表示语义实体、状态、性质和动作，分为 五大类：语义实体、动作、性状、种类、格</li>
<li>义式：由义素及左右圆括号构成，最重要的在最右端，称为义式的首部，直接或间接支配义式中其他义素。</li>
<li>裸模板：由一个行为主体义式<strong>首部</strong>、一个动作义式<strong>首部</strong>和一个客体义式<strong>首部</strong>组成的能够直观解释的通的序列。
<ul>
<li>裸模板提出了句子的主要成分——主语、谓语和直接宾语的语义类</li>
<li>如果谓语是不及物动词，裸模板中宾语的位置用一个虚构节点 DTHIS 代替，叫作哑元</li>
</ul>
</li>
<li>模板：如果义式的<strong>首部能组成裸模板</strong>，那么这些义式可能依附于其上的其他义式所组成的序列，就称为该原文片段的一个模板。模板并不仅仅包括义式的首部，实际上是义式组成的网络，首部是其核心部分。</li>
<li>超模板：把模板结合起来就形成超模板。两种结合方式：
<ul>
<li>利用虚构的结点</li>
<li>找出指代和照应关系</li>
</ul>
</li>
</ul>
<p>采用优选语义学进行语言自动分析的过程：</p>
<ul>
<li>切分：根据关键词（标点、连接词和介词）</li>
<li>匹配：找出与切分段匹配的裸模板</li>
<li>扩展：把裸模板扩展为模板的网络，切分段内部以模板为框架建立词与词之间的关系，如果上一步匹配到不止一个裸模板，那么在建立关系时要根据各个裸模板语义联系程度的不同情况进行优选</li>
<li>捆绑：在各个模板之间建立联系，把模板捆绑为超模板，在切分段外部（切分段之间）建立联系。主要任务：
<ul>
<li>建立模板之间的深层格的联系</li>
<li>建立哑元与它所替代的词之间的联系</li>
<li>解决遗留的歧义问题</li>
<li>解决代词的指代问题</li>
</ul>
</li>
</ul>
<p>优选语义学特点：</p>
<ul>
<li>语言分析不经过形态和句法分析，都通过语义信息表示出来，摆脱了传统的句法分析框框</li>
<li>各个片段的语义描写都可以用义素和括号统一进行</li>
</ul>
<h2 id="schank-的概念依存理论">Schank 的概念依存理论</h2>
<p>1973 年美国计算语言学家 R. Schank 提出，用于描述自然语言中的短语和句子的意义。</p>
<p>三条重要原理：</p>
<ul>
<li>意义相同的句子，无论属于什么语言，语义表达式只有一个</li>
<li>蕴涵在一个句子里的任何为理解所必需的信息都应该在概念依存理论中得到显式表达，一般使用概念依存表达式：由若干个语义基元组成，语义基元分为基本行为和基本状态两种。
<ul>
<li>基本行为 11 个：PTRANS（物体物理位置转移）、ATRANS（占有、物主或控制等抽象关系转移）、INGEST（使某种东西进入动物体内）、PROPEL（在某物上使用体力）、MTRANS（人与人或一个人身上的精神信息转移）、MBUILD（人根据旧信息加工成新信息）、MOVE、GRASP、EXPEL、SPEAK、ATTEND；基本行为的概念之间的关系叫做依存。基本状态数量很多。</li>
<li>概念依存理论建立了五条推导因果关系的规则：
<ul>
<li>行为可能引起状态改变</li>
<li>状态可以使行为成为可能</li>
<li>状态可以使行为成为不可能</li>
<li>状态可以激发一个精神事件，行为也可以激发一个精神事件</li>
<li>精神事件可以成为行为的原因</li>
</ul>
</li>
</ul>
</li>
<li>在句子的意义表达式中，必须把隐晦地存在于句子中的信息尽量显现出来</li>
</ul>
<p>概念依存表达式一般不依赖于句法，Schank 认为，概念依存理论具有一定的心理学效应，反映了人们认知活动的知觉概念。在概念依存理论原理的基础上，Schank 等提出了一些更高层次的知识结构：脚本、计划、目的和主题。</p>
<ul>
<li>
<p>脚本：用来描述人们活动的一种标准化事件序列，是人们对特定场合下可能出现的一些事件的固定顺序特有的一种集装知识。有两个项目特别重要：</p>
<ul>
<li>关键事件：首先要匹配关键事件，以便开始分析句子</li>
<li>主要概念：脚本所叙述的故事的目的</li>
</ul>
</li>
<li>
<p>计划、目的和主题：在指定情况为了达到某个目标而必须（或可能）采取的行动序列，是另一类更一般化的集装知识。</p>
<ul>
<li>计划是故事中的角色为实现其目的（如去电影院）所采取的手段（如走到车站）；计划还可以包括为实现某个一般目的（如去某地）所采取的手段（如开车、步行等）。计划集中起来构成计划库，计划库中存储着有关各种目的以及手段的信息。</li>
<li>采用计划理解故事的过程：
<ul>
<li>首先确定角色目的</li>
<li>再确定导致主要目的之 D-目的</li>
<li>然后再把角色的行动同存储着 D-目的之打算库相匹配，从而获得对故事的一定理解</li>
</ul>
</li>
<li>主题是我们的预见所赖以建立起来的背景信息，背景信息中一定包含着角色的某种目的。一个主题要列举一系列角色，说明这些角色所处情况以及为了处理这种包含于主题中的情况而必须采取的行动，而主题的目的是完成这些行动。</li>
<li>Schank 和 Abelson 提出了七种类型的目的，主要有：
<ul>
<li>A-目的或达成性目的</li>
<li>P-目的或保护性目的</li>
<li>C-目的或紧急性目的</li>
</ul>
</li>
<li>用计划、目的和主题这类知识结构理解一个故事的过程：
<ul>
<li>用计划和主题这类知识结构去识别故事的目的</li>
<li>利用计划找到满足该目的之子目的以及相应的实施行动</li>
<li>在故事的相继输入中寻找上述子目的和行动，并据此对故事做出解释</li>
</ul>
</li>
</ul>
</li>
<li>
<p>脚本、计划、目的和主题之间的关系：</p>
<ul>
<li>主题引起目的</li>
<li>当目的被认出，并且其行动与该目的之实现相一致时，就可以引起计划</li>
<li>脚本是事件的标准化模式</li>
<li>脚本是特殊的，而计划是一般的</li>
<li>计划的来源是脚本</li>
<li>计划是表示人的目的之一种方法，这些目的隐含在脚本中，它们只表示行动</li>
<li>脚本中有一个关键事件，要与输入的句子进行模式匹配；计划中没有关键事件，每一个计划归入一个目的之下。</li>
</ul>
</li>
</ul>
<p>采用脚本、计划、目的和主题，Schank 等先后建立了 MARGIE、SAM、PAM、MOP、FRUMP、IPP 等系统。</p>
<ul>
<li>MARGIE 分为三部分
<ul>
<li>概念分析程序：把英文句子转换成概念依存表达式</li>
<li>推理程序：接收依存表达式，根据系统存储器中有关信息进行推理，推演出大量事实。推理知识在存储器中用语义网络表示</li>
<li>文本生成程序：把概念依存表达式转为英文句子输出，两种方法
<ul>
<li>分辨网络：用于区分不同词义，可以根据上下文选择恰当的单词</li>
<li>扩充转移网络：把概念依存表达式转为线性单词符号序列，输出句子表层线性结构</li>
</ul>
</li>
</ul>
</li>
<li>SAM 和 PAM 采用脚本和计划理解简单故事。区别在建立概念依存表达式之后的处理过程。
<ul>
<li>SAM 采用故事与脚本相匹配的办法理解故事，匹配完成后就可以对故事做出总结</li>
<li>PAM 建立在计划基础上的，它的方法是确定故事中任务的目的，并且把而后的行动解释为实现这些行动的目的和 D-目的（直接目的）</li>
</ul>
</li>
<li>人们在理解故事中存在另一类知识结构，能同时容纳集装知识和抽象知识，叫作记忆组织包（MOP），MOP 中，各种不同环境共享的抽象知识存放在一个地方，以便不同的 MOP 调用。概念依存表达式、脚本、计划等属于静态记忆，而 MOP 则是具有自修改能力的动态记忆，它能把具体事件中获得的经验升华为抽象的一般性经验，反映了人类学习的过程。</li>
<li>Schank 认为传统分离的句法分析是不必要的，也不符合人们理解语言的心理过程。主张把句法和语义知识结合在一起，一次就把输入语句转换成某种机器的内部表示。这种分析方法叫作一体化的概念分析模型。MARGIE 的概念分析程序体现了这种思想，该程序经过扩充后成为 ELI（English Language Interpreter），充当许多故事理解系统的公共前端：把输入语句直接映射为概念依存表达式。ELI 采用的基本手段是 ”期望“：当一个人谈到或听到一个词时，他会预见某些别的词或者已经出现，或者即将相继出现。这种期望根据迄今已被理解的内容以及有关语言和世界的知识建立起来的。人们在阅读过程中，不断根据这样的期望预见下一步可能会读到什么，并利用它们来排除歧义和理解正读入的文本。
<ul>
<li>第一个一体化程序是 FRUMP，通过对输入文本浏览来寻找它感兴趣的东西，这些东西往往是系统打算在故事的总结中陈述的那些重要信息。FRUMP 采用梗概脚本作为它的知识表示模型。整个理解程序是期望驱动的，附加在指定梗概脚本上的期望指明了脚本希望寻找的信息是什么。</li>
<li>FRUMP 的故事理解是根据实现设计好的梗概脚本的内容进行的，如果脚本设计时忽略了某些重要情节，理解就会出错。IPP 克服了这个缺陷，它采用 MOP 作为知识结构，抽象程度较高，并能够从读入的故事中自动地归纳出一般的结论来。它的词典中的词条分为立即分析的词、暂时跳过的词和完全忽略的词，处理故事时只可能忽略单词，不会证据忽略，这样就能发现和处理事先某些没有预见到的重要情节，有效克服了 FRUMP 的缺陷。IPP 论文：<a href="https://onlinelibrary.wiley.com/doi/pdf/10.1207/s15516709cog0701_1" target="_blank" rel="noopener">Generalization From Natural Language Text*</a></li>
<li>其他系统：
<ul>
<li>自动编写简单故事：<a href="https://www.cs.utah.edu/nlp/papers/talespin-ijcai77.pdf" target="_blank" rel="noopener">TALE-SPIN</a></li>
<li>模拟人们在国际政治事件意识形态上的理解：<a href="https://onlinelibrary.wiley.com/doi/abs/10.1207/s15516709cog0201_3" target="_blank" rel="noopener">POLITICS: Automated Ideological Reasoning* - Carbonell - 1978 - Cognitive Science - Wiley Online Library</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>本节后面提到的几个系统在内部的模块设计理念上非常具有启发性。MOP 在具体事件中获得一般性经验，其理念甚至超过了知识图谱；ELI 利用期望的方法，也很符合人类认知；FRUMP 和 IPP 利用梗概脚本提取信息在 NLP 中有非常广泛的应用场景。</p>
</blockquote>
<h2 id="mel-chuk-的意义-文本理论">Mel’chuk 的意义&lt;=&gt;文本理论</h2>
<p>A. K. Zolkovski 和 I. A. Mel’chuk 20 世纪 60 年代提出。主张自然语言是建立意义和文本对应的逻辑工具。</p>
<p>三个基本假设：</p>
<ul>
<li>自然语言的意义和文本之间的对应是多对多的</li>
<li>自然语言的意义和文本之间的对应可以采用形式化的逻辑关系来描述，这个逻辑工具应当反映自然的说话人的语言活动</li>
<li>意义和文本之间关系复杂，所以在话语过程中，必须区分一些中间层次
<ul>
<li>七个层次：语义表示、深层句法表示、表层句法表示、深层形态表示、表层形态表示、深层音位表示、表层音位表示</li>
<li>六个模块：语义模块、深层句法模块、表层句法模块、深层形态模块、表层形态模块、音位模块</li>
</ul>
</li>
</ul>
<p><strong>意义到文本的转化过程是从多维的图，经过二维的树，最后转化到一维的串的过程。</strong></p>
<ul>
<li>语义表示：多维有向图
<ul>
<li>语义素：结点上的标记，是一个语义单位，它的函项叫作语义行动元</li>
<li>语义名：一般是具体名词，没有函项</li>
<li>语义依存：语义素和它的行动元之间用箭头相连，这种连接叫作语义依存</li>
</ul>
</li>
<li>表层句法表示：二维依存关系树
<ul>
<li>严格区分句法结构和形态结构</li>
<li>句法结构只表示二维依存关系而不表示一维的前后线性关系</li>
<li>与依存语法一致，与短语结构语法有差别</li>
</ul>
</li>
<li>表层形态表示：一维的符号串
<ul>
<li>单词有顺序</li>
<li>代词带有语法信息</li>
</ul>
</li>
</ul>
<p>意义&lt;=&gt;文本模型不是 ”生成“ 装置，而是 ”转换“ 装置，这是与 Chomsky 生成语法最重要的区别。主要工作原理是进行同义转换，在各个层次上生成大量同义结构，再经过各种过滤装置，筛选出合格文本。八种过滤器：</p>
<ul>
<li>一般类型过滤器：剔除语义合成结果中包含人造虚构词的深层句法结构</li>
<li>同类过滤器：剔除同义结构中所有包含 ”空位“ 关键词的深层结构语法</li>
<li>保障语义配价和句法配价饱和的过滤器：剔除不满足配价的深层句法结构</li>
<li>限制单词或词组的组合性能的过滤器：剔除不合规则的词汇组合</li>
<li>词序规则过滤器：剔除在一定语言环境下不合格的词序</li>
<li>限制表层句法成分的过滤器：剔除在表层句法结构中不合格的句法成分</li>
<li>限制形态或构词的过滤器：剔除在形态或构词上不合格的句法成分</li>
<li>优化文本的过滤器：剔除在修辞上不合格的文本</li>
</ul>
<p>巴黎第七大学的 S. Kahane 根据本理论提出了 ”转构语法“，主要功能是把意义-文本模型中不同层次上的结构集合对应起来，是一种 ”元语法的形式化模型“。</p>
<blockquote>
<p>本理论从多维的意义到二维的句法再到一维的符号这种结构非常具有启发性，尤其是多维的意义图让多维的语言有了一种呈现方式，也许自然语言的表示本身就是图结构的。</p>
</blockquote>
<h2 id="词义排歧方法">词义排歧方法</h2>
<p>排歧涉及上下文因素、语义因素、语境因素以及生活中的常识，是 NLP 最棘手的问题。常用的方法有：</p>
<ul>
<li>选择最常见义项：没有排歧功能</li>
<li>利用词类：不同的词义往往属于不同的词类</li>
<li>基于选择限制：“观其伴而知其意”
<ul>
<li>使用两方面知识
<ul>
<li>论元的语义类型分类</li>
<li>论元对于谓词的选择限制</li>
</ul>
</li>
<li>局限性
<ul>
<li>当选择限制一般性太强时，很难决定有关词的选择限制范围：what kind of dishes? (碟子 or 菜)</li>
<li>在否定句子的时候，否定关系违反选择限制，但语义合法：You can’t eat gold.</li>
<li>不寻常事件违反限制但句子合法：He ate glass in the trial.</li>
<li>有比喻或借喻：He wants to kill the USA.</li>
</ul>
</li>
<li>改进：
<ul>
<li>1987 年，Hirst 建议把选择限制看作一种优选关系</li>
<li>1997 年，Resnik 提出 “选择联想”：谓词与该谓词所支配论元的类别之间的联想强度的概率测度</li>
</ul>
</li>
</ul>
</li>
<li>自立的鲁棒法：依靠词类标注工作，力求把对于信息的要求减到最低限度
<ul>
<li>步骤如下：
<ul>
<li>选择相关语言学特征</li>
<li>根据算法要求对特征进行形式化描述</li>
</ul>
</li>
<li>用来训练的语言学特征分类：
<ul>
<li>搭配特征：对目标词左右的上下文编码</li>
<li>共现特征：不考虑相邻词的位置信息，单词本身可作为特征</li>
</ul>
</li>
</ul>
</li>
<li>有指导的学习方法（监督）
<ul>
<li>朴素 Bayes 分类法：在给定上下文环境下，计算多义词的各个义项中概率最大的义项</li>
<li>决策表分类法：根据共现词的等价类的不同制定决策表，表中项目的排列根据训练语料的特征决定</li>
</ul>
</li>
<li>自举法（半监督）：不需要训练大量语料，每一个词目的每一个义项都依靠少量的标记好的实例来判别，以这些实例作为种子，采用有监督训练得到初始分类，再利用初始分类从未训练的语料中抽取训练语料，反复进行
<ul>
<li>1991 年，Hearst 用简单的手工标记方法获得一个小的实例集合</li>
<li>1995 年，Yarowsky 提出 “每个搭配一个义项” 的原则：为每一个义项选择一个合理的标示词作为种子。选择种子的途径有：机器可读词典；统计方法根据搭配关系选择。</li>
</ul>
</li>
<li>无指导的方法（无监督）：根据相似度（从共现次数的分布可以看出）对语料聚类。
<ul>
<li>凝聚法是常用的方法，语料中每个实例被指派给一个类聚，自底向上陆续把两个最相似的类聚结合成新的类聚，直到达到预期目标为止</li>
<li>不足：
<ul>
<li>训练语料中无法得知什么是正确的义项</li>
<li>所得类聚往往与训练实例的义项在性质上差别很大</li>
<li>类聚的数量几乎总与需要消歧的目标词的义项的数量不一致</li>
</ul>
</li>
</ul>
</li>
<li>基于词典的方法：词典提供义项及义项的定义上下文，是一种利用既存知识源，判断两个词亲和程度时，比较它们在词典的定义中同时出现的词语情况。排歧时，把多义词的各个义项的定义进行比较，选择具有最大覆盖上下文的义项作为正确的义项。如 pine cone，cone 是多义词，把词典中 pine 的定义分别与 cone 的定义比较，选择重合最多的义项作为 cone 的义项。</li>
</ul>
<blockquote>
<p>这一节虽然内容有点相对古老，不过思想依旧有意义。</p>
</blockquote>
<h2 id="小结">小结</h2>
<p>本章都是关于语义（即如何理解自然语言）的形式模型，主要包括：</p>
<ul>
<li>义素分析法
<ul>
<li>20 世纪 50 年代，美国人类学家 F. G. Lounsbury 和 W. H. Goodenough 在研究亲属词的含义时提出了义素分析法；20 世纪 60 年代初，美国语言学家 J. J. Katz 和 J. A. Fodor 提出了解释语义学，将义素分析法引入语言学，为生成转换语法提供语义特征。</li>
<li>义素是意义的基本要素，它就是词的理性意义的区别特征。词的理性意义是一束语义特征（义素）的总和。</li>
<li>一组词的义素可以用义素矩阵表示，纵坐标表示词，横坐标表示义素，纵横坐标相交点注以 + 或 - 号或其他表示方法。</li>
</ul>
</li>
<li>语义场
<ul>
<li>20 世纪 30 年代初，德国学者 J. Trier 提出系统的语义场理论，1992 年，北大贾彦德在《汉语语义学》中系统提出了汉语的语义场理论，北京语言大学张普提出 “场型” 的概念。</li>
<li>语义场是词义形成的系统，它是基于概念的关系场，是词义与词义之间构成的一种完全虚化、非物质的空间领域。若干个意义上紧密相联的词义，通常归属于一个总称之下，就构成了语义场。语义场可进一步分为词汇场和联想场。词汇场是静态的，表现为词义与词义之间的组合关系。这里的语义场主要指词汇场。</li>
<li>汉语的场型（不同类型的语义场）包括：
<ul>
<li>分类场型：基本场型，一般是多层次的</li>
<li>构件场型：基本场型，下位是上位的构件</li>
<li>有序场型：基于分类场型和构件场型的特殊场型，所有平位是有序的</li>
<li>对立场型：特殊场型，平位的词义之间存在对立关系</li>
<li>同义场型：特殊场型，同一场型中，同位和变位的理性意义完全相同，只是附属于理性意义的风格、色彩等方面义素不同</li>
</ul>
</li>
<li>场与场之间的关系有：嵌套关系、交叉关系、传递关系、联想关系</li>
</ul>
</li>
<li>语义网络
<ul>
<li>1972 年，美国人工智能专家 R. F. Simmons 和 J. Slocum 首先将语义网络用于自然语言理解系统中。1977 年，美国人工智能学者 G. Hendrix 提出了分块语义网络的思想，把语义的逻辑表示与 “格语法” 结合起来，把复杂问题分解为若干简单的子问题，每个子问题以一个语义网络表示。</li>
<li>语义网络可用有向图表示，一个语义网络就是由一些以有向图表示的三元组：（结点1，弧，结点2）连接而成的。三元组可写成二元谓词：P（个体1，个体2）</li>
<li>语义网络可表示一个事件，事件由若干个概念组合所反映的客观现实，可以分为叙述性事件、描述性事件和表述性事件三种。语义网络表述事件时，结点之间的关系还可以为施事（AGENT）、受事（OPATIENT）、位置（LOCATION）、时间（TIME）等。</li>
<li>语义网络的推理机制一般基于网络的匹配。根据提出的问题构建局部网络，查询解答的过程就是查询局部网络到网络知识库的匹配操作。知识图谱描述真实世界中存在的各种实体或概念，每个属性-值偶对用来刻画实体的内在特性，而关系用来连接两个实体。可以看作一个巨大的语义网络。</li>
</ul>
</li>
<li>Montague 语法
<ul>
<li>1970 年前后美国数理逻辑学家 R. Montague 等把内涵逻辑应用于自然语言的研究，并把生成语法与内涵逻辑这两个领域的研究集中提炼为 Montague 语法。</li>
<li>在 Montague 语法里，一个句子的句法形式、内涵逻辑表达式和语义所指都是从基本单位开始，通过句法规则、转译规则和语义规则，从小到大逐段确定的。句法、转译和语义三大部分是同态的。有一条句法规则就有一条转译规则把它处理的短语转译成内涵逻辑表达式，然后再由一条语义规则来确定这个内涵逻辑表达式的语义。歧义问题通过不同的组合方式和运用不同的句法、语义规则来解决，这是 Montague 语法的 “规则对规则假说”。
<ul>
<li>句法：包括一套语类和一套句法规则。功能是把来自词库的词语组成句子。</li>
<li>转译：包括一套转译规则，把短语转译成内涵逻辑表达式。</li>
<li>语义：以内涵逻辑为基础建立的。内涵逻辑包括句法和语义两方面</li>
</ul>
</li>
<li>Montague 语法有两个来源：N. Chomsky 的生成转换语法 和 Louis 的内涵逻辑学。采用内涵逻辑学来描述句子的深层结构，在句子的每一个层次上都可得出一个相应的内涵逻辑表达式，并以此来表示该句子深层结构的逻辑含义。从 (λx…x…)a 出发得到 …a… 这一性质称为 “λ-变换”， <strong>λ-变换是 Montague 语法转译计算的关键</strong>，生成语法得出的完全相同的树形图在 λ-变换后，可以得出不同的内涵逻辑表达式。</li>
<li>Montague 通过真值条件语义学、模型论语义学和可能世界语义学（Montague 语法的语义理论的三个特点），把自然语言所表现出来的意义介入内涵逻辑学中，从而建立了 Montague 语法的语义理论。由于将句法和语义结合，使得任何一个通过句法分析得到的表示句子的句法结构的树形图，都可以用 Montague 语法解释为相应的内涵逻辑表达式，从而表现出句子的语义内容。</li>
</ul>
</li>
<li>Wilks 优选语义学
<ul>
<li>1874 年，Y. A. Wilks 在研制英法机器翻译系统的基础上，提出了 “优选语义学”，它共有五种语义单位：义素、义式、裸模板、模板、超模板，并有从较小的单位到较大的单位的构造规则。</li>
<li>采用优选语义学进行语言自动分析的过程：
<ul>
<li>切分：根据关键词（标点、连接词和介词）</li>
<li>匹配：找出与切分段匹配的裸模板</li>
<li>扩展：把裸模板扩展为模板的网络，切分段内部以模板为框架建立词与词之间的关系，如果上一步匹配到不止一个裸模板，那么在建立关系时要根据各个裸模板语义联系程度的不同情况进行优选</li>
<li>捆绑：在各个模板之间建立联系，把模板捆绑为超模板，在切分段外部（切分段之间）建立联系。</li>
</ul>
</li>
</ul>
</li>
<li>Schank 概念依存理论
<ul>
<li>1973 年美国计算语言学家 R. Schank 提出，用于描述自然语言中的短语和句子的意义。</li>
<li>三条重要原理：
<ul>
<li>意义相同的句子，无论属于什么语言，语义表达式只有一个</li>
<li>蕴涵在一个句子里的任何为理解所必需的信息都应该在概念依存理论中得到显式表达，一般使用概念依存表达式：由若干个语义基元组成，语义基元分为基本行为和基本状态两种。</li>
<li>在句子的意义表达式中，必须把隐晦地存在于句子中的信息尽量显现出来</li>
</ul>
</li>
<li>概念依存表达式一般不依赖于句法，Schank 认为，概念依存理论具有一定的心理学效应，反映了人们认知活动的知觉概念。在概念依存理论原理的基础上，Schank 等提出了一些更高层次的知识结构：脚本、计划、目的和主题。
<ul>
<li>脚本：用来描述人们活动的一种标准化事件序列，是人们对特定场合下可能出现的一些事件的固定顺序特有的一种集装知识。</li>
<li>计划、目的和主题：在指定情况为了达到某个目标而必须（或可能）采取的行动序列，是另一类更一般化的集装知识。</li>
<li>计划是故事中的角色为实现其目的（如去电影院）所采取的手段（如走到车站）；计划还可以包括为实现某个一般目的（如去某地）所采取的手段（如开车、步行等）。计划集中起来构成计划库，计划库中存储着有关各种目的以及手段的信息。</li>
<li>采用计划理解故事的过程：首先确定角色目的，再确定导致主要目的之 D-目的，然后再把角色的行动同存储着 D-目的之打算库相匹配，从而获得对故事的一定理解。</li>
<li>主题是我们的预见所赖以建立起来的背景信息，背景信息中一定包含着角色的某种目的。一个主题要列举一系列角色，说明这些角色所处情况以及为了处理这种包含于主题中的情况而必须采取的行动，而主题的目的是完成这些行动。</li>
<li>Schank 和 Abelson 提出了七种类型的目的。</li>
<li>用计划、目的和主题这类知识结构理解一个故事的过程：
<ul>
<li>用计划和主题这类知识结构去识别故事的目的</li>
<li>利用计划找到满足该目的之子目的以及相应的实施行动</li>
<li>在故事的相继输入中寻找上述子目的和行动，并据此对故事做出解释</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Mel’chuk 意义&lt;=&gt;文本理论
<ul>
<li>A. K. Zolkovski 和 I. A. Mel’chuk 20 世纪 60 年代提出。主张自然语言是建立意义和文本对应的逻辑工具。</li>
<li>三个基本假设：
<ul>
<li>自然语言的意义和文本之间的对应是多对多的</li>
<li>自然语言的意义和文本之间的对应可以采用形式化的逻辑关系来描述，这个逻辑工具应当反映自然的说话人的语言活动</li>
<li>意义和文本之间关系复杂，所以在话语过程中，必须区分一些中间层次</li>
</ul>
</li>
<li>意义到文本的转化过程是从多维的图，经过二维的树，最后转化到一维的串的过程。</li>
<li>意义&lt;=&gt;文本模型不是 ”生成“ 装置，而是 ”转换“ 装置，这是与 Chomsky 生成语法最重要的区别。主要工作原理是进行同义转换，在各个层次上生成大量同义结构，再经过各种过滤装置，筛选出合格文本。八种过滤器：一般类型过滤器、同类过滤器、保障语义配价和句法配价饱和的过滤器、限制单词或词组的组合性能的过滤器、词序规则过滤器、限制表层句法成分的过滤器、限制形态或构词的过滤器、优化文本的过滤器。</li>
</ul>
</li>
<li>词义排歧方法
<ul>
<li>排歧涉及上下文因素、语义因素、语境因素以及生活中的常识，是 NLP 最棘手的问题</li>
<li>选择最常见义项：没有排歧功能</li>
<li>利用词类：不同的词义往往属于不同的词类</li>
<li>基于选择限制：“观其伴而知其意”，使用两方面知识：论元的语义类型分类；论元对于谓词的选择限制</li>
<li>自立的鲁棒法：依靠词类标注工作，力求把对于信息的要求减到最低限度，用来训练的语言学特征分类分为：搭配特征和共现特征</li>
<li>有指导的学习方法（监督），包括朴素 Bayes 分类法决策表分类法</li>
<li>自举法（半监督）：每一个词目的每一个义项都依靠少量的标记好的实例来判别，以这些实例作为种子，采用有监督训练得到初始分类，再利用初始分类从未训练的语料中抽取训练语料，反复进行</li>
<li>无指导的方法（无监督）：根据相似度（从共现次数的分布可以看出）对语料聚类</li>
<li>基于词典的方法：词典提供义项及义项的定义上下文，排歧时，把多义词的各个义项的定义进行比较，选择具有最大覆盖上下文的义项作为正确的义项</li>
</ul>
</li>
</ul>
<p>本章的很多思想非常具有启发性，比如语义网络的构建和推理（涉及知识图谱）、基于概念依存理论的 MOP 和 ELI、意义&lt;=&gt;文本理论的多维意义到二维句法再到一维符号的结构表达，最后的词义排歧方法也是涵盖全面，虽然时间上早了些，但方法却依然在使用。</p>

      
    </div><!-- .entry-content -->

    <footer class="entry-meta">
    <a href="/2019/02/15/NLP/NLPFA/2019-02-15-Ch08-Formal-Model-of-Semantic-Automatic-Processing/">
    <time datetime="2019-02-15T03:32:00.000Z" class="entry-date">
        2019-02-15
    </time>
</a>
    
  <span class="article-delim">&#8226;</span>
  <div class="article-category">
  <a class="article-category-link" href="/categories/Feeling/">Feeling</a>
  </div>

    
  <span class="article-delim">&#8226;</span>
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/AI/">AI</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NLP/">NLP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Semantic-Automatic-Processing/">Semantic Automatic Processing</a></li></ul>

    </footer>
</article>


    
<nav class="nav-single">
    <h3 class="assistive-text">文章导航</h3>
    
        <span class="nav-previous"><a href="/2019/02/21/NLP/NLPFA/2019-02-21-Ch09-System-Function-Syntax/" rel="prev"><span class="meta-nav">←</span> 自然语言计算机形式分析的理论与方法笔记(Ch09)</a></span>
    
    
        <span class="nav-next"><a href="/2019/01/31/NLP/NLPFA/2019-01-31-Ch07-Formal-Model-Based-on-Lexicalism/" rel="next">自然语言计算机形式分析的理论与方法笔记(Ch07) <span class="meta-nav">→</span></a></span>
    
</nav><!-- .nav-single -->







<div class="bdsharebuttonbox"><a href="#" class="bds_more" data-cmd="more"></a><a href="#" class="bds_fbook" data-cmd="fbook" title="分享到Facebook"></a><a href="#" class="bds_twi" data-cmd="twi" title="分享到Twitter"></a><a href="#" class="bds_linkedin" data-cmd="linkedin" title="分享到linkedin"></a><a href="#" class="bds_qzone" data-cmd="qzone" title="分享到QQ空间"></a><a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a><a href="#" class="bds_douban" data-cmd="douban" title="分享到豆瓣网"></a><a href="#" class="bds_weixin" data-cmd="weixin" title="分享到微信"></a><a href="#" class="bds_evernotecn" data-cmd="evernotecn" title="分享到印象笔记"></a></div>
<script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"1","bdSize":"24"},"share":{},"image":{"viewList":["fbook","twi","linkedin","qzone","tsina","douban","weixin","evernotecn"],"viewText":"分享到：","viewSize":"16"}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='/static/api/js/share.js?v=89860593.js?'];</script>

<section id="comment">
  <!-- 评论代码 -->
  <div id="gitalk-container"></div>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
  <script src="https://cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
  <script>
  const gitalk = new Gitalk({
    clientID: '0eb512031083d6e7edfb',
    clientSecret: 'e830808995dd813ca26fed50573760963457da37',
    repo: 'hscspring.github.io',
    owner: 'hscspring',
    admin: ['hscspring'],
    id: md5(location.pathname),
    distractionFreeMode: false
  })
  gitalk.render('gitalk-container')
  </script>
  <!-- 评论代码已完成 -->
</section>

</div></div>
        <div id="secondary" class="widget-area" role="complementary">
  
    
  <aside class="widget">
    <h3 class="widget-title">Categories</h3>
    <div class="widget-content">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Coding/">Coding</a><span class="category-list-count">73</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Feeling/">Feeling</a><span class="category-list-count">146</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Thinking/">Thinking</a><span class="category-list-count">37</span></li></ul>
    </div>
  </aside>

  
    
  <aside class="widget">
    <h3 class="widget-title">Music</h3>
    <div class="widget-content">
      <iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=541131&auto=0&height=66"></iframe>
      <!-- 评论代码 -->
      <!-- <audio src="http://qnimg.lovevivian.cn/miss.mp3" controls="controls"
             style="width:100%">
        您的浏览器不支持 audio 标签。
      </audio> -->
    </div>
  </aside>

  
    
  <aside class="widget">
    <h3 class="widget-title">Recents</h3>
    <div class="widget-content">
      <ul>
        
          <li>
            <a href="/2025/07/01/NLP/LLM-IF/2025-07-01-Activation-Steering/">激活诱导LLM指令跟随</a>
          </li>
        
          <li>
            <a href="/2025/06/26/Diary/2025-06-26-60hours-Pass-Arch-Exam/">60小时备考高架擦边过经验</a>
          </li>
        
          <li>
            <a href="/2025/06/26/NLP/LLM-IF/2025-06-26-Instruction-Following/">指令跟随近期工作梳理（2025年上半年）</a>
          </li>
        
          <li>
            <a href="/2025/06/19/NLP/LLM-Training/2025-06-19-CISPO-and-Entropy/">GRPO优化在继续——CISPO和熵</a>
          </li>
        
          <li>
            <a href="/2025/06/13/NLP/LLM-Training/2025-07-13-RM-Data/">解锁模型潜能：Reward 数据如何塑造与激发 LLM 的推理策略</a>
          </li>
        
      </ul>
    </div>
  </aside>

  
    
  <aside class="widget">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget-content tagcloud">
      <a href="/tags/AE/" style="font-size: 10px;">AE</a> <a href="/tags/AI/" style="font-size: 19.33px;">AI</a> <a href="/tags/AIGC/" style="font-size: 10.67px;">AIGC</a> <a href="/tags/ALBERT/" style="font-size: 10px;">ALBERT</a> <a href="/tags/AR/" style="font-size: 10px;">AR</a> <a href="/tags/AUC/" style="font-size: 10px;">AUC</a> <a href="/tags/Accuracy/" style="font-size: 10px;">Accuracy</a> <a href="/tags/Activation/" style="font-size: 10px;">Activation</a> <a href="/tags/Activation-Steering/" style="font-size: 10px;">Activation Steering</a> <a href="/tags/Agent/" style="font-size: 10px;">Agent</a> <a href="/tags/Aha/" style="font-size: 10px;">Aha</a> <a href="/tags/Algorithm/" style="font-size: 12.67px;">Algorithm</a> <a href="/tags/Array/" style="font-size: 10px;">Array</a> <a href="/tags/Arrow/" style="font-size: 10px;">Arrow</a> <a href="/tags/Attention/" style="font-size: 12px;">Attention</a> <a href="/tags/Automatic-Speech-Processing/" style="font-size: 10px;">Automatic Speech Processing</a> <a href="/tags/Automation/" style="font-size: 10px;">Automation</a> <a href="/tags/BERT/" style="font-size: 16.67px;">BERT</a> <a href="/tags/BIO/" style="font-size: 10.67px;">BIO</a> <a href="/tags/BIOHD/" style="font-size: 10.67px;">BIOHD</a> <a href="/tags/BM25/" style="font-size: 10px;">BM25</a> <a href="/tags/BPE/" style="font-size: 10px;">BPE</a> <a href="/tags/BabyGrow/" style="font-size: 10px;">BabyGrow</a> <a href="/tags/Backtracking/" style="font-size: 10px;">Backtracking</a> <a href="/tags/Backward/" style="font-size: 10px;">Backward</a> <a href="/tags/Bahdanau-Attention/" style="font-size: 10px;">Bahdanau Attention</a> <a href="/tags/Bart/" style="font-size: 10px;">Bart</a> <a href="/tags/Bayes/" style="font-size: 10px;">Bayes</a> <a href="/tags/Beam-Search/" style="font-size: 10px;">Beam Search</a> <a href="/tags/Bert-Flow/" style="font-size: 10px;">Bert-Flow</a> <a href="/tags/Bi-LSTM/" style="font-size: 10px;">Bi-LSTM</a> <a href="/tags/Biasing/" style="font-size: 10px;">Biasing</a> <a href="/tags/BigCodec/" style="font-size: 10px;">BigCodec</a> <a href="/tags/Binary-Search/" style="font-size: 11.33px;">Binary Search</a> <a href="/tags/Blending/" style="font-size: 10px;">Blending</a> <a href="/tags/Brain/" style="font-size: 10px;">Brain</a> <a href="/tags/Brain-Decoding/" style="font-size: 10px;">Brain Decoding</a> <a href="/tags/Bridge/" style="font-size: 10px;">Bridge</a> <a href="/tags/Business/" style="font-size: 12px;">Business</a> <a href="/tags/C/" style="font-size: 10.67px;">C</a> <a href="/tags/C4/" style="font-size: 10px;">C4</a> <a href="/tags/CCG/" style="font-size: 10.67px;">CCG</a> <a href="/tags/CE-BERT/" style="font-size: 10px;">CE BERT</a> <a href="/tags/CFG/" style="font-size: 10px;">CFG</a> <a href="/tags/CISPO/" style="font-size: 10px;">CISPO</a> <a href="/tags/CKY/" style="font-size: 10px;">CKY</a> <a href="/tags/CNN/" style="font-size: 10px;">CNN</a> <a href="/tags/CRF/" style="font-size: 10px;">CRF</a> <a href="/tags/CS/" style="font-size: 10px;">CS</a> <a href="/tags/CYK/" style="font-size: 10px;">CYK</a> <a href="/tags/Calculus/" style="font-size: 10px;">Calculus</a> <a href="/tags/Camera/" style="font-size: 10px;">Camera</a> <a href="/tags/Cascades/" style="font-size: 10px;">Cascades</a> <a href="/tags/Catalan/" style="font-size: 10px;">Catalan</a> <a href="/tags/ChatBot/" style="font-size: 10px;">ChatBot</a> <a href="/tags/ChatGPT/" style="font-size: 15.33px;">ChatGPT</a> <a href="/tags/Chi2/" style="font-size: 10px;">Chi2</a> <a href="/tags/Chunking/" style="font-size: 10px;">Chunking</a> <a href="/tags/Class-Imbalance-Loss/" style="font-size: 10px;">Class Imbalance Loss</a> <a href="/tags/Classification/" style="font-size: 10.67px;">Classification</a> <a href="/tags/CoT/" style="font-size: 10px;">CoT</a> <a href="/tags/Codec/" style="font-size: 12px;">Codec</a> <a href="/tags/Cognition/" style="font-size: 10.67px;">Cognition</a> <a href="/tags/Collaborative-Filtering/" style="font-size: 10px;">Collaborative Filtering</a> <a href="/tags/Collins-Parser/" style="font-size: 10px;">Collins Parser</a> <a href="/tags/Computational-Linguistics/" style="font-size: 10px;">Computational Linguistics</a> <a href="/tags/Computer/" style="font-size: 10px;">Computer</a> <a href="/tags/Computer-Science/" style="font-size: 12px;">Computer Science</a> <a href="/tags/Confusing-Labels/" style="font-size: 10px;">Confusing Labels</a> <a href="/tags/Context-Free-Grammars/" style="font-size: 10px;">Context-Free Grammars</a> <a href="/tags/Continual-Pre-training/" style="font-size: 14px;">Continual Pre-training</a> <a href="/tags/Continual-Pretraining/" style="font-size: 10.67px;">Continual Pretraining</a> <a href="/tags/Contrastive-Learning/" style="font-size: 10px;">Contrastive-Learning</a> <a href="/tags/Coordinate-Ascent/" style="font-size: 10px;">Coordinate Ascent</a> <a href="/tags/Cosine/" style="font-size: 10.67px;">Cosine</a> <a href="/tags/Cosine-Similarity/" style="font-size: 10px;">Cosine Similarity</a> <a href="/tags/Cross-Entropy/" style="font-size: 10px;">Cross Entropy</a> <a href="/tags/Cross-brackets/" style="font-size: 10px;">Cross-brackets</a> <a href="/tags/Cross-view/" style="font-size: 10px;">Cross-view</a> <a href="/tags/Ctrl/" style="font-size: 10px;">Ctrl</a> <a href="/tags/Culture/" style="font-size: 10px;">Culture</a> <a href="/tags/DA/" style="font-size: 10px;">DA</a> <a href="/tags/DAC/" style="font-size: 10px;">DAC</a> <a href="/tags/DAPO/" style="font-size: 12.67px;">DAPO</a> <a href="/tags/DB/" style="font-size: 10.67px;">DB</a> <a href="/tags/DNN/" style="font-size: 10px;">DNN</a> <a href="/tags/DP/" style="font-size: 10px;">DP</a> <a href="/tags/DPO/" style="font-size: 10px;">DPO</a> <a href="/tags/Data-Augmentation/" style="font-size: 10px;">Data Augmentation</a> <a href="/tags/Data-Clearing/" style="font-size: 10px;">Data Clearing</a> <a href="/tags/Data-Enhancement/" style="font-size: 10px;">Data Enhancement</a> <a href="/tags/Data-Preprocess/" style="font-size: 10px;">Data Preprocess</a> <a href="/tags/Data-Science/" style="font-size: 14px;">Data Science</a> <a href="/tags/Data-Structure/" style="font-size: 15.33px;">Data Structure</a> <a href="/tags/DataManagement/" style="font-size: 10.67px;">DataManagement</a> <a href="/tags/Database/" style="font-size: 10px;">Database</a> <a href="/tags/DeBERTa/" style="font-size: 10px;">DeBERTa</a> <a href="/tags/Debiasing/" style="font-size: 10px;">Debiasing</a> <a href="/tags/Decoder/" style="font-size: 10px;">Decoder</a> <a href="/tags/Decoding/" style="font-size: 10.67px;">Decoding</a> <a href="/tags/Deep/" style="font-size: 10px;">Deep</a> <a href="/tags/DeepGen/" style="font-size: 10px;">DeepGen</a> <a href="/tags/DeepGraph/" style="font-size: 10px;">DeepGraph</a> <a href="/tags/DeepLearning/" style="font-size: 12px;">DeepLearning</a> <a href="/tags/DeepScaleR/" style="font-size: 10.67px;">DeepScaleR</a> <a href="/tags/DeepSeek/" style="font-size: 10px;">DeepSeek</a> <a href="/tags/DeepSeek-GRM/" style="font-size: 10px;">DeepSeek-GRM</a> <a href="/tags/Dependence/" style="font-size: 10px;">Dependence</a> <a href="/tags/Diary/" style="font-size: 15.33px;">Diary</a> <a href="/tags/Disentangled-Attention/" style="font-size: 10px;">Disentangled Attention</a> <a href="/tags/DistilBERT/" style="font-size: 10px;">DistilBERT</a> <a href="/tags/Distillation/" style="font-size: 10.67px;">Distillation</a> <a href="/tags/Django/" style="font-size: 10px;">Django</a> <a href="/tags/Docker/" style="font-size: 10px;">Docker</a> <a href="/tags/Docker-Compose/" style="font-size: 10px;">Docker-Compose</a> <a href="/tags/Dockerfile/" style="font-size: 10px;">Dockerfile</a> <a href="/tags/Dr-GRPO/" style="font-size: 10px;">Dr GRPO</a> <a href="/tags/DrDAPO/" style="font-size: 10px;">DrDAPO</a> <a href="/tags/Dream/" style="font-size: 10.67px;">Dream</a> <a href="/tags/Dropout/" style="font-size: 10.67px;">Dropout</a> <a href="/tags/Dynamic-Mask/" style="font-size: 10px;">Dynamic-Mask</a> <a href="/tags/EDA/" style="font-size: 10px;">EDA</a> <a href="/tags/EMD/" style="font-size: 10px;">EMD</a> <a href="/tags/ERNIE/" style="font-size: 10px;">ERNIE</a> <a href="/tags/Economics/" style="font-size: 10px;">Economics</a> <a href="/tags/Edit-Distance/" style="font-size: 10px;">Edit Distance</a> <a href="/tags/Efficient-DeepLearning/" style="font-size: 10px;">Efficient-DeepLearning</a> <a href="/tags/Elasticsearch/" style="font-size: 10px;">Elasticsearch</a> <a href="/tags/Electra/" style="font-size: 10px;">Electra</a> <a href="/tags/Elixir/" style="font-size: 10.67px;">Elixir</a> <a href="/tags/Ellipsis/" style="font-size: 10px;">Ellipsis</a> <a href="/tags/Embedding/" style="font-size: 11.33px;">Embedding</a> <a href="/tags/Embeddings/" style="font-size: 10.67px;">Embeddings</a> <a href="/tags/Embodied-AI/" style="font-size: 10px;">Embodied AI</a> <a href="/tags/Encoder/" style="font-size: 10px;">Encoder</a> <a href="/tags/Entropy/" style="font-size: 11.33px;">Entropy</a> <a href="/tags/Evaluation/" style="font-size: 10.67px;">Evaluation</a> <a href="/tags/ExT5/" style="font-size: 10px;">ExT5</a> <a href="/tags/Exam/" style="font-size: 10px;">Exam</a> <a href="/tags/F1/" style="font-size: 10px;">F1</a> <a href="/tags/FDW/" style="font-size: 10px;">FDW</a> <a href="/tags/FLAN/" style="font-size: 10px;">FLAN</a> <a href="/tags/FSM/" style="font-size: 10px;">FSM</a> <a href="/tags/Faith/" style="font-size: 10px;">Faith</a> <a href="/tags/FastCuRL/" style="font-size: 10px;">FastCuRL</a> <a href="/tags/Feature-Engineering/" style="font-size: 10px;">Feature Engineering</a> <a href="/tags/Feature-based/" style="font-size: 10px;">Feature-based</a> <a href="/tags/Few-Shot/" style="font-size: 11.33px;">Few-Shot</a> <a href="/tags/Few-shot-Prompting/" style="font-size: 10px;">Few-shot Prompting</a> <a href="/tags/Fine-tuning/" style="font-size: 10px;">Fine-tuning</a> <a href="/tags/Formal-Grammars/" style="font-size: 11.33px;">Formal Grammars</a> <a href="/tags/Forward/" style="font-size: 10px;">Forward</a> <a href="/tags/Full-Text-Search/" style="font-size: 10px;">Full-Text-Search</a> <a href="/tags/Function-Syntax/" style="font-size: 10px;">Function Syntax</a> <a href="/tags/Funk-MF/" style="font-size: 10px;">Funk MF</a> <a href="/tags/Funnel-Transformer/" style="font-size: 10px;">Funnel Transformer</a> <a href="/tags/GAE/" style="font-size: 10px;">GAE</a> <a href="/tags/GBTD/" style="font-size: 10px;">GBTD</a> <a href="/tags/GELU/" style="font-size: 10px;">GELU</a> <a href="/tags/GP/" style="font-size: 10px;">GP</a> <a href="/tags/GPT-1/" style="font-size: 10px;">GPT-1</a> <a href="/tags/GPT-2/" style="font-size: 10.67px;">GPT-2</a> <a href="/tags/GPT-3/" style="font-size: 10px;">GPT-3</a> <a href="/tags/GPT3/" style="font-size: 10px;">GPT3</a> <a href="/tags/GPU/" style="font-size: 10px;">GPU</a> <a href="/tags/GRM/" style="font-size: 10px;">GRM</a> <a href="/tags/GRPO/" style="font-size: 12.67px;">GRPO</a> <a href="/tags/GRU/" style="font-size: 10px;">GRU</a> <a href="/tags/GSG/" style="font-size: 10px;">GSG</a> <a href="/tags/Gan/" style="font-size: 10px;">Gan</a> <a href="/tags/Garden-path/" style="font-size: 10px;">Garden-path</a> <a href="/tags/Git/" style="font-size: 10px;">Git</a> <a href="/tags/Global-Pointer/" style="font-size: 10px;">Global Pointer</a> <a href="/tags/Glow/" style="font-size: 10px;">Glow</a> <a href="/tags/Graceful-Shutdown/" style="font-size: 10px;">Graceful Shutdown</a> <a href="/tags/Gradient-Descent/" style="font-size: 10px;">Gradient Descent</a> <a href="/tags/Graph/" style="font-size: 10.67px;">Graph</a> <a href="/tags/GraphQL/" style="font-size: 10.67px;">GraphQL</a> <a href="/tags/Grid-Grammar/" style="font-size: 10px;">Grid Grammar</a> <a href="/tags/Growth/" style="font-size: 12.67px;">Growth</a> <a href="/tags/H2O-Danube/" style="font-size: 10px;">H2O-Danube</a> <a href="/tags/HMM/" style="font-size: 10.67px;">HMM</a> <a href="/tags/Hard-SVM/" style="font-size: 10px;">Hard-SVM</a> <a href="/tags/Hinge-Loss/" style="font-size: 10px;">Hinge Loss</a> <a href="/tags/Hope/" style="font-size: 10px;">Hope</a> <a href="/tags/Host-only/" style="font-size: 10px;">Host-only</a> <a href="/tags/HuggingLLM/" style="font-size: 10px;">HuggingLLM</a> <a href="/tags/Human-in-Loop/" style="font-size: 10px;">Human-in-Loop</a> <a href="/tags/Human-in-the-Loop/" style="font-size: 10px;">Human-in-the-Loop</a> <a href="/tags/IDE/" style="font-size: 10px;">IDE</a> <a href="/tags/IE/" style="font-size: 10px;">IE</a> <a href="/tags/IQR/" style="font-size: 10px;">IQR</a> <a href="/tags/Imbalance-Data/" style="font-size: 10px;">Imbalance Data</a> <a href="/tags/Impossible-Triangle/" style="font-size: 10px;">Impossible-Triangle</a> <a href="/tags/In-Context-Learning/" style="font-size: 10.67px;">In-Context Learning</a> <a href="/tags/Industry/" style="font-size: 10px;">Industry</a> <a href="/tags/Inference-Scaling/" style="font-size: 11.33px;">Inference Scaling</a> <a href="/tags/Information-Extraction/" style="font-size: 10px;">Information Extraction</a> <a href="/tags/Information-Theory/" style="font-size: 10px;">Information Theory</a> <a href="/tags/Instruct/" style="font-size: 10px;">Instruct</a> <a href="/tags/InstructGPT/" style="font-size: 10.67px;">InstructGPT</a> <a href="/tags/Instruction-Following/" style="font-size: 12px;">Instruction Following</a> <a href="/tags/Instruction-Inference/" style="font-size: 10px;">Instruction Inference</a> <a href="/tags/Isolation-Forest/" style="font-size: 10px;">Isolation Forest</a> <a href="/tags/ItemCF/" style="font-size: 10px;">ItemCF</a> <a href="/tags/Jaccard/" style="font-size: 10px;">Jaccard</a> <a href="/tags/Java/" style="font-size: 10px;">Java</a> <a href="/tags/Jax/" style="font-size: 10px;">Jax</a> <a href="/tags/Job/" style="font-size: 10px;">Job</a> <a href="/tags/Jupyter/" style="font-size: 10px;">Jupyter</a> <a href="/tags/KKT/" style="font-size: 10px;">KKT</a> <a href="/tags/KL/" style="font-size: 10px;">KL</a> <a href="/tags/KS/" style="font-size: 10px;">KS</a> <a href="/tags/Kernel/" style="font-size: 10px;">Kernel</a> <a href="/tags/Kernel-Function/" style="font-size: 10px;">Kernel Function</a> <a href="/tags/Kernel-Method/" style="font-size: 10px;">Kernel Method</a> <a href="/tags/Keyword/" style="font-size: 10px;">Keyword</a> <a href="/tags/Knowledge-Graph/" style="font-size: 10.67px;">Knowledge Graph</a> <a href="/tags/L1/" style="font-size: 10px;">L1</a> <a href="/tags/LCPO/" style="font-size: 10px;">LCPO</a> <a href="/tags/LIMD/" style="font-size: 10.67px;">LIMD</a> <a href="/tags/LIMO/" style="font-size: 11.33px;">LIMO</a> <a href="/tags/LIMR/" style="font-size: 10.67px;">LIMR</a> <a href="/tags/LLM/" style="font-size: 18.67px;">LLM</a> <a href="/tags/LLM-Colosseum/" style="font-size: 10px;">LLM-Colosseum</a> <a href="/tags/LM/" style="font-size: 12px;">LM</a> <a href="/tags/LOF/" style="font-size: 10px;">LOF</a> <a href="/tags/LR/" style="font-size: 10px;">LR</a> <a href="/tags/LSTM/" style="font-size: 10px;">LSTM</a> <a href="/tags/Labeling/" style="font-size: 10px;">Labeling</a> <a href="/tags/Language-Model/" style="font-size: 10.67px;">Language Model</a> <a href="/tags/Lexical-Semantics/" style="font-size: 10px;">Lexical Semantics</a> <a href="/tags/Lexicalism/" style="font-size: 10px;">Lexicalism</a> <a href="/tags/Lexicalized-CFG/" style="font-size: 10px;">Lexicalized CFG</a> <a href="/tags/Lexicalized-Grammars/" style="font-size: 10px;">Lexicalized Grammars</a> <a href="/tags/Life/" style="font-size: 12px;">Life</a> <a href="/tags/Linear-Algebra/" style="font-size: 10px;">Linear Algebra</a> <a href="/tags/Linear-Sturcture/" style="font-size: 10px;">Linear Sturcture</a> <a href="/tags/Linked-List/" style="font-size: 10px;">Linked List</a> <a href="/tags/LinkedList/" style="font-size: 10.67px;">LinkedList</a> <a href="/tags/Linux/" style="font-size: 10px;">Linux</a> <a href="/tags/Llama/" style="font-size: 10px;">Llama</a> <a href="/tags/Logistic-Regression/" style="font-size: 10px;">Logistic Regression</a> <a href="/tags/Lucene/" style="font-size: 10px;">Lucene</a> <a href="/tags/Luong-Attention/" style="font-size: 10px;">Luong Attention</a> <a href="/tags/MEMM/" style="font-size: 10px;">MEMM</a> <a href="/tags/MF/" style="font-size: 10px;">MF</a> <a href="/tags/MIO/" style="font-size: 10px;">MIO</a> <a href="/tags/MM-Fusion/" style="font-size: 10px;">MM Fusion</a> <a href="/tags/MTL/" style="font-size: 11.33px;">MTL</a> <a href="/tags/Machine/" style="font-size: 10px;">Machine</a> <a href="/tags/Machine-Learning/" style="font-size: 14px;">Machine Learning</a> <a href="/tags/Machine-Translation/" style="font-size: 10px;">Machine Translation</a> <a href="/tags/Manacher/" style="font-size: 10px;">Manacher</a> <a href="/tags/Managemnt/" style="font-size: 11.33px;">Managemnt</a> <a href="/tags/MarkBERT/" style="font-size: 10px;">MarkBERT</a> <a href="/tags/Markov/" style="font-size: 10px;">Markov</a> <a href="/tags/Materialized-Views/" style="font-size: 10px;">Materialized Views</a> <a href="/tags/Math/" style="font-size: 10.67px;">Math</a> <a href="/tags/Matplotlib/" style="font-size: 10px;">Matplotlib</a> <a href="/tags/Matrix-Factorization/" style="font-size: 10px;">Matrix Factorization</a> <a href="/tags/Median/" style="font-size: 10px;">Median</a> <a href="/tags/Meta-Learning/" style="font-size: 10px;">Meta Learning</a> <a href="/tags/Metric/" style="font-size: 10px;">Metric</a> <a href="/tags/Minimum-Edit-Distance/" style="font-size: 10px;">Minimum Edit Distance</a> <a href="/tags/Minkowski/" style="font-size: 10px;">Minkowski</a> <a href="/tags/Model-Evaluation/" style="font-size: 10px;">Model Evaluation</a> <a href="/tags/Module/" style="font-size: 10px;">Module</a> <a href="/tags/Multi-Head-Attention/" style="font-size: 10px;">Multi-Head Attention</a> <a href="/tags/Multi-Modal/" style="font-size: 10px;">Multi-Modal</a> <a href="/tags/MultiModal/" style="font-size: 10px;">MultiModal</a> <a href="/tags/Multitask/" style="font-size: 10px;">Multitask</a> <a href="/tags/Multiway-Tree/" style="font-size: 10px;">Multiway Tree</a> <a href="/tags/NAT/" style="font-size: 10px;">NAT</a> <a href="/tags/NER/" style="font-size: 14px;">NER</a> <a href="/tags/NLG/" style="font-size: 11.33px;">NLG</a> <a href="/tags/NLM/" style="font-size: 10.67px;">NLM</a> <a href="/tags/NLP/" style="font-size: 20px;">NLP</a> <a href="/tags/NLU/" style="font-size: 10px;">NLU</a> <a href="/tags/NMT/" style="font-size: 10px;">NMT</a> <a href="/tags/NNW/" style="font-size: 11.33px;">NNW</a> <a href="/tags/NTP/" style="font-size: 10px;">NTP</a> <a href="/tags/Naive-Bayes/" style="font-size: 10px;">Naive Bayes</a> <a href="/tags/Neo4j/" style="font-size: 10px;">Neo4j</a> <a href="/tags/Network/" style="font-size: 10px;">Network</a> <a href="/tags/Ngram/" style="font-size: 10.67px;">Ngram</a> <a href="/tags/NodeJS/" style="font-size: 10px;">NodeJS</a> <a href="/tags/Normalizing-Flow/" style="font-size: 10px;">Normalizing Flow</a> <a href="/tags/NumPy/" style="font-size: 10px;">NumPy</a> <a href="/tags/Numba/" style="font-size: 10px;">Numba</a> <a href="/tags/Numpy/" style="font-size: 10px;">Numpy</a> <a href="/tags/OMNI/" style="font-size: 11.33px;">OMNI</a> <a href="/tags/ORZ/" style="font-size: 10px;">ORZ</a> <a href="/tags/Occupation/" style="font-size: 10px;">Occupation</a> <a href="/tags/One-Shot/" style="font-size: 10.67px;">One-Shot</a> <a href="/tags/Online-DPO-R1/" style="font-size: 10.67px;">Online-DPO-R1</a> <a href="/tags/OpenSource/" style="font-size: 10px;">OpenSource</a> <a href="/tags/Orientation/" style="font-size: 10px;">Orientation</a> <a href="/tags/P-R/" style="font-size: 10px;">P-R</a> <a href="/tags/PCCG/" style="font-size: 10px;">PCCG</a> <a href="/tags/PCFG/" style="font-size: 10px;">PCFG</a> <a href="/tags/PEGASUS/" style="font-size: 10px;">PEGASUS</a> <a href="/tags/PLM/" style="font-size: 10.67px;">PLM</a> <a href="/tags/PPMI/" style="font-size: 10px;">PPMI</a> <a href="/tags/PTM/" style="font-size: 10px;">PTM</a> <a href="/tags/PageRank/" style="font-size: 10px;">PageRank</a> <a href="/tags/Palindromic/" style="font-size: 10px;">Palindromic</a> <a href="/tags/Pandarallel/" style="font-size: 10px;">Pandarallel</a> <a href="/tags/Pandas/" style="font-size: 10.67px;">Pandas</a> <a href="/tags/Partial-Parsing/" style="font-size: 10px;">Partial Parsing</a> <a href="/tags/Passion/" style="font-size: 10px;">Passion</a> <a href="/tags/Pearson/" style="font-size: 10px;">Pearson</a> <a href="/tags/Philosophy/" style="font-size: 10.67px;">Philosophy</a> <a href="/tags/Phrase-Structure-Grammar/" style="font-size: 10px;">Phrase Structure Grammar</a> <a href="/tags/Phrase-Structure-Grammars/" style="font-size: 10px;">Phrase Structure Grammars</a> <a href="/tags/PoS/" style="font-size: 10px;">PoS</a> <a href="/tags/Polars/" style="font-size: 10px;">Polars</a> <a href="/tags/Pooling/" style="font-size: 10px;">Pooling</a> <a href="/tags/Position-Encoding/" style="font-size: 10px;">Position-Encoding</a> <a href="/tags/Post-training/" style="font-size: 16px;">Post-training</a> <a href="/tags/Postgres/" style="font-size: 10.67px;">Postgres</a> <a href="/tags/Pragmatic-Automatic-Processing/" style="font-size: 10px;">Pragmatic Automatic Processing</a> <a href="/tags/Pre-Trained/" style="font-size: 10px;">Pre-Trained</a> <a href="/tags/Pre-Training/" style="font-size: 10px;">Pre-Training</a> <a href="/tags/Pre-training/" style="font-size: 14.67px;">Pre-training</a> <a href="/tags/Precision/" style="font-size: 10px;">Precision</a> <a href="/tags/Pretrain/" style="font-size: 10.67px;">Pretrain</a> <a href="/tags/Pretrained/" style="font-size: 10px;">Pretrained</a> <a href="/tags/Pretraining/" style="font-size: 10.67px;">Pretraining</a> <a href="/tags/Probabilistic-Grammar/" style="font-size: 10px;">Probabilistic Grammar</a> <a href="/tags/Probabilistic-Model/" style="font-size: 10px;">Probabilistic Model</a> <a href="/tags/Promote/" style="font-size: 10px;">Promote</a> <a href="/tags/Prompt/" style="font-size: 12.67px;">Prompt</a> <a href="/tags/ProtoBERT/" style="font-size: 10px;">ProtoBERT</a> <a href="/tags/Pruning/" style="font-size: 10px;">Pruning</a> <a href="/tags/Psychology/" style="font-size: 10.67px;">Psychology</a> <a href="/tags/PyPI/" style="font-size: 10px;">PyPI</a> <a href="/tags/Python/" style="font-size: 18px;">Python</a> <a href="/tags/QA/" style="font-size: 10px;">QA</a> <a href="/tags/Quant/" style="font-size: 10px;">Quant</a> <a href="/tags/Quantization/" style="font-size: 10px;">Quantization</a> <a href="/tags/Query/" style="font-size: 10px;">Query</a> <a href="/tags/Queue/" style="font-size: 10px;">Queue</a> <a href="/tags/Qwen3/" style="font-size: 10px;">Qwen3</a> <a href="/tags/R-Drop/" style="font-size: 10.67px;">R-Drop</a> <a href="/tags/R1/" style="font-size: 11.33px;">R1</a> <a href="/tags/R1-Zero/" style="font-size: 13.33px;">R1-Zero</a> <a href="/tags/RAG/" style="font-size: 10px;">RAG</a> <a href="/tags/RELU/" style="font-size: 10px;">RELU</a> <a href="/tags/RFE/" style="font-size: 10px;">RFE</a> <a href="/tags/RHO/" style="font-size: 10px;">RHO</a> <a href="/tags/RHO-1/" style="font-size: 10px;">RHO-1</a> <a href="/tags/RL/" style="font-size: 12.67px;">RL</a> <a href="/tags/RLHF/" style="font-size: 10px;">RLHF</a> <a href="/tags/RM/" style="font-size: 10.67px;">RM</a> <a href="/tags/RM-R1/" style="font-size: 10px;">RM-R1</a> <a href="/tags/RMSE/" style="font-size: 10px;">RMSE</a> <a href="/tags/RNN/" style="font-size: 10px;">RNN</a> <a href="/tags/ROC/" style="font-size: 10px;">ROC</a> <a href="/tags/RWD/" style="font-size: 10px;">RWD</a> <a href="/tags/Rank/" style="font-size: 10px;">Rank</a> <a href="/tags/RaspberryPi/" style="font-size: 10.67px;">RaspberryPi</a> <a href="/tags/Raspberrypi/" style="font-size: 10px;">Raspberrypi</a> <a href="/tags/Recall/" style="font-size: 10px;">Recall</a> <a href="/tags/Recommendation/" style="font-size: 12.67px;">Recommendation</a> <a href="/tags/Recursion/" style="font-size: 10.67px;">Recursion</a> <a href="/tags/Reformer/" style="font-size: 10px;">Reformer</a> <a href="/tags/Regex/" style="font-size: 10px;">Regex</a> <a href="/tags/Regular-Expression/" style="font-size: 10px;">Regular Expression</a> <a href="/tags/Reinforcement-Learning/" style="font-size: 10px;">Reinforcement Learning</a> <a href="/tags/Relationship-Extraction/" style="font-size: 10px;">Relationship Extraction</a> <a href="/tags/Representation/" style="font-size: 10.67px;">Representation</a> <a href="/tags/Reqular-Expressions/" style="font-size: 10px;">Reqular Expressions</a> <a href="/tags/Retrieving/" style="font-size: 10px;">Retrieving</a> <a href="/tags/Reward/" style="font-size: 10px;">Reward</a> <a href="/tags/RoBERTa/" style="font-size: 10px;">RoBERTa</a> <a href="/tags/Rotated-Sorted-Array/" style="font-size: 10px;">Rotated Sorted Array</a> <a href="/tags/Rust/" style="font-size: 16px;">Rust</a> <a href="/tags/SCFG/" style="font-size: 10px;">SCFG</a> <a href="/tags/SGD/" style="font-size: 10px;">SGD</a> <a href="/tags/SLM/" style="font-size: 10.67px;">SLM</a> <a href="/tags/SMO/" style="font-size: 10px;">SMO</a> <a href="/tags/SQL/" style="font-size: 10.67px;">SQL</a> <a href="/tags/SRN/" style="font-size: 10px;">SRN</a> <a href="/tags/STaR/" style="font-size: 10px;">STaR</a> <a href="/tags/SVD/" style="font-size: 10px;">SVD++</a> <a href="/tags/SVM/" style="font-size: 10.67px;">SVM</a> <a href="/tags/Scaling/" style="font-size: 10px;">Scaling</a> <a href="/tags/Scaling-Law/" style="font-size: 10px;">Scaling Law</a> <a href="/tags/Seaborn/" style="font-size: 10px;">Seaborn</a> <a href="/tags/Search/" style="font-size: 10.67px;">Search</a> <a href="/tags/Seed-Thinking/" style="font-size: 10px;">Seed-Thinking</a> <a href="/tags/Segmentation/" style="font-size: 10px;">Segmentation</a> <a href="/tags/Selection-Inference/" style="font-size: 10px;">Selection-Inference</a> <a href="/tags/Self-Attention/" style="font-size: 11.33px;">Self-Attention</a> <a href="/tags/Semantic-Automatic-Processing/" style="font-size: 10px;">Semantic Automatic Processing</a> <a href="/tags/Semantic-Similarity/" style="font-size: 10px;">Semantic Similarity</a> <a href="/tags/Senta/" style="font-size: 10px;">Senta</a> <a href="/tags/Sentence-Representation/" style="font-size: 10px;">Sentence Representation</a> <a href="/tags/Sentence-Similarity/" style="font-size: 10px;">Sentence Similarity</a> <a href="/tags/Sentence-BERT/" style="font-size: 10px;">Sentence-BERT</a> <a href="/tags/Sentiment-Classification/" style="font-size: 10px;">Sentiment Classification</a> <a href="/tags/SentimentAnalysis/" style="font-size: 10px;">SentimentAnalysis</a> <a href="/tags/Siamese/" style="font-size: 10px;">Siamese</a> <a href="/tags/Sigmoid/" style="font-size: 10px;">Sigmoid</a> <a href="/tags/SimCSE/" style="font-size: 10.67px;">SimCSE</a> <a href="/tags/Similarity/" style="font-size: 10px;">Similarity</a> <a href="/tags/Simon/" style="font-size: 10px;">Simon</a> <a href="/tags/Simple-Zoo/" style="font-size: 10px;">Simple-Zoo</a> <a href="/tags/Simpson-Paradox/" style="font-size: 10px;">Simpson Paradox</a> <a href="/tags/Skill/" style="font-size: 10px;">Skill</a> <a href="/tags/Skywork-Reward/" style="font-size: 10px;">Skywork Reward</a> <a href="/tags/Slide/" style="font-size: 10px;">Slide</a> <a href="/tags/Smoothing/" style="font-size: 10.67px;">Smoothing</a> <a href="/tags/Soft-SVM/" style="font-size: 10px;">Soft-SVM</a> <a href="/tags/Softmax/" style="font-size: 10px;">Softmax</a> <a href="/tags/Sort/" style="font-size: 10.67px;">Sort</a> <a href="/tags/Span/" style="font-size: 11.33px;">Span</a> <a href="/tags/Spell-Check/" style="font-size: 10px;">Spell Check</a> <a href="/tags/Spurious-Reward/" style="font-size: 10px;">Spurious Reward</a> <a href="/tags/SqueezeBERT/" style="font-size: 10px;">SqueezeBERT</a> <a href="/tags/Stable-LM/" style="font-size: 10px;">Stable LM</a> <a href="/tags/Stack/" style="font-size: 10px;">Stack</a> <a href="/tags/Stacking/" style="font-size: 10px;">Stacking</a> <a href="/tags/Statistics/" style="font-size: 10px;">Statistics</a> <a href="/tags/Stirling/" style="font-size: 10px;">Stirling</a> <a href="/tags/Strategic/" style="font-size: 10px;">Strategic</a> <a href="/tags/StratifiedKFold/" style="font-size: 10px;">StratifiedKFold</a> <a href="/tags/String/" style="font-size: 10.67px;">String</a> <a href="/tags/Style/" style="font-size: 10px;">Style</a> <a href="/tags/Substring/" style="font-size: 10px;">Substring</a> <a href="/tags/Summarization/" style="font-size: 10.67px;">Summarization</a> <a href="/tags/Supertagging/" style="font-size: 10px;">Supertagging</a> <a href="/tags/Swap/" style="font-size: 10px;">Swap</a> <a href="/tags/System/" style="font-size: 10.67px;">System</a> <a href="/tags/T5/" style="font-size: 10.67px;">T5</a> <a href="/tags/TF-IDF/" style="font-size: 10px;">TF-IDF</a> <a href="/tags/THW/" style="font-size: 11.33px;">THW</a> <a href="/tags/TS3-Codec/" style="font-size: 10px;">TS3-Codec</a> <a href="/tags/TTRL/" style="font-size: 10px;">TTRL</a> <a href="/tags/TTS/" style="font-size: 14px;">TTS</a> <a href="/tags/Tagging/" style="font-size: 10px;">Tagging</a> <a href="/tags/TanH/" style="font-size: 10px;">TanH</a> <a href="/tags/TensorBay/" style="font-size: 10px;">TensorBay</a> <a href="/tags/Tensorflow/" style="font-size: 10px;">Tensorflow</a> <a href="/tags/Test/" style="font-size: 10px;">Test</a> <a href="/tags/Text-Classification/" style="font-size: 10px;">Text Classification</a> <a href="/tags/Text-Generation/" style="font-size: 10px;">Text Generation</a> <a href="/tags/Text-Normalization/" style="font-size: 10px;">Text Normalization</a> <a href="/tags/TextCNN/" style="font-size: 10.67px;">TextCNN</a> <a href="/tags/TextRank/" style="font-size: 10px;">TextRank</a> <a href="/tags/Thought/" style="font-size: 10.67px;">Thought</a> <a href="/tags/Transformer/" style="font-size: 17.33px;">Transformer</a> <a href="/tags/Transformer-XL/" style="font-size: 10px;">Transformer-XL</a> <a href="/tags/Tree/" style="font-size: 10px;">Tree</a> <a href="/tags/Treebank/" style="font-size: 10px;">Treebank</a> <a href="/tags/Tuning/" style="font-size: 10px;">Tuning</a> <a href="/tags/Tutorial/" style="font-size: 10px;">Tutorial</a> <a href="/tags/Ubuntu/" style="font-size: 10px;">Ubuntu</a> <a href="/tags/UniLM/" style="font-size: 10px;">UniLM</a> <a href="/tags/Unity-Operation/" style="font-size: 10px;">Unity Operation</a> <a href="/tags/Unix/" style="font-size: 10px;">Unix</a> <a href="/tags/Unsupervised-Elicitation/" style="font-size: 10px;">Unsupervised Elicitation</a> <a href="/tags/UserCF/" style="font-size: 10px;">UserCF</a> <a href="/tags/VAPO/" style="font-size: 10px;">VAPO</a> <a href="/tags/VITS/" style="font-size: 10px;">VITS</a> <a href="/tags/Vagrant/" style="font-size: 10px;">Vagrant</a> <a href="/tags/Valence/" style="font-size: 10px;">Valence</a> <a href="/tags/Vector-Semantics/" style="font-size: 10px;">Vector Semantics</a> <a href="/tags/Verifier/" style="font-size: 10px;">Verifier</a> <a href="/tags/Virtual-Network/" style="font-size: 10px;">Virtual Network</a> <a href="/tags/VirtualBox/" style="font-size: 10px;">VirtualBox</a> <a href="/tags/Visualization/" style="font-size: 10px;">Visualization</a> <a href="/tags/Viterbi/" style="font-size: 10.67px;">Viterbi</a> <a href="/tags/Vocabulary-Learning/" style="font-size: 10px;">Vocabulary Learning</a> <a href="/tags/VoiceAgent/" style="font-size: 10px;">VoiceAgent</a> <a href="/tags/Voila/" style="font-size: 10px;">Voila</a> <a href="/tags/Voting/" style="font-size: 10px;">Voting</a> <a href="/tags/W2NER/" style="font-size: 11.33px;">W2NER</a> <a href="/tags/WOE/" style="font-size: 10px;">WOE</a> <a href="/tags/Web-Server-Multithreaded-Server/" style="font-size: 10px;">Web Server Multithreaded Server</a> <a href="/tags/Wide/" style="font-size: 10px;">Wide</a> <a href="/tags/Word2vec/" style="font-size: 10px;">Word2vec</a> <a href="/tags/Work/" style="font-size: 10px;">Work</a> <a href="/tags/XLNet/" style="font-size: 10px;">XLNet</a> <a href="/tags/XTTS/" style="font-size: 10px;">XTTS</a> <a href="/tags/Z-Score/" style="font-size: 10px;">Z-Score</a> <a href="/tags/Zero-Short/" style="font-size: 10px;">Zero-Short</a> <a href="/tags/Zero-Shot/" style="font-size: 11.33px;">Zero-Shot</a> <a href="/tags/Zero-shot/" style="font-size: 10px;">Zero-shot</a> <a href="/tags/ZhouZhihua/" style="font-size: 10px;">ZhouZhihua</a> <a href="/tags/Zipf/" style="font-size: 10px;">Zipf</a> <a href="/tags/Ziya/" style="font-size: 10.67px;">Ziya</a> <a href="/tags/binning/" style="font-size: 10px;">binning</a> <a href="/tags/emacs/" style="font-size: 10px;">emacs</a> <a href="/tags/few-shot/" style="font-size: 10px;">few-shot</a> <a href="/tags/ffmpeg/" style="font-size: 10px;">ffmpeg</a> <a href="/tags/jpype/" style="font-size: 10px;">jpype</a> <a href="/tags/knowledge-Graph/" style="font-size: 10px;">knowledge Graph</a> <a href="/tags/motion/" style="font-size: 10px;">motion</a> <a href="/tags/node2vec/" style="font-size: 10px;">node2vec</a> <a href="/tags/oat-zero/" style="font-size: 10.67px;">oat-zero</a> <a href="/tags/orz/" style="font-size: 10px;">orz</a> <a href="/tags/s1/" style="font-size: 11.33px;">s1</a> <a href="/tags/ssh/" style="font-size: 10px;">ssh</a> <a href="/tags/str/" style="font-size: 10px;">str</a> <a href="/tags/vim/" style="font-size: 10px;">vim</a> <a href="/tags/vlc/" style="font-size: 10px;">vlc</a>
    </div>
  </aside>

  
</div>
      </div>
      <footer id="colophon" role="contentinfo">
    <p>&copy; 2025 hscspring
    All rights reserved.</p>
    <p>Powered by <a href="https://hexo.io/" target="_blank">Hexo</a></p>
    
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <!-- <span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_site_pv"></span>次</span> -->
    <!-- <span id="busuanzi_container_page_pv">本文总阅读量<span id="busuanzi_value_page_pv"></span>次</span> -->
    <!-- <span id="busuanzi_container_site_uv">本站访客数<span id="busuanzi_value_site_uv"></span>人次</span> -->

</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

<script src="/js/navigation.js"></script>

<div id="bg"></div>

  </div><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>